[path]
lang_pair: enja
train_data: wmt21_official_data/at_least_one_strategy/enja_atleastone_train.tsv
valid_data: wmt21_official_data/at_least_one_strategy/enja_atleastone_dev.tsv
test_data: wmt21_official_data/at_least_one_strategy/enja_atleastone_test_blind.tsv
output_dir: output/temp/

[model]
huggingface_model: xlm-roberta-base
max_sequence_length: 100
dropout: 0.1

[train]
num_epochs: 10
train_batch_size: 64
valid_batch_size: 16
lr: 2e-5
warmup_ratio: 0.3