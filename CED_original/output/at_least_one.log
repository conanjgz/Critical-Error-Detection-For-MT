| 2021-07-13 13:16:56 | INFO | 
==============================Start training==============================
| 2021-07-13 13:16:56 | INFO | Command Line Args:   --lr 2e-5 --warmup_ratio 0.2 -c config/enzh_at_least_one.conf
Config File (config/enzh_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/enzh_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/enzh_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 13:16:56 | INFO | 
lr: 2e-05

| 2021-07-13 13:17:08 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 13:17:08 | INFO | Start epoch 1:
| 2021-07-13 13:17:09 | INFO | Train Loss: 0.660, tp: 0, fn: 25, fp: 0, tn: 39, Acc: 0.609, Prec: 0.000, Rec: 0.000, F1: 0.379
| 2021-07-13 13:18:12 | INFO | Validation tp: 21, fn: 313, fp: 13, tn: 654
| 2021-07-13 13:18:12 | INFO | Validation loss: 0.605, acc: 0.674, F1: 0.457
| 2021-07-13 13:18:12 | INFO | Start epoch 2:
| 2021-07-13 13:18:13 | INFO | Train Loss: 0.591, tp: 1, fn: 18, fp: 1, tn: 44, Acc: 0.703, Prec: 0.500, Rec: 0.053, F1: 0.459
| 2021-07-13 13:19:16 | INFO | Validation tp: 75, fn: 259, fp: 35, tn: 632
| 2021-07-13 13:19:16 | INFO | Validation loss: 0.571, acc: 0.706, F1: 0.575
| 2021-07-13 13:19:16 | INFO | Start epoch 3:
| 2021-07-13 13:19:16 | INFO | Train Loss: 0.592, tp: 7, fn: 18, fp: 4, tn: 35, Acc: 0.656, Prec: 0.636, Rec: 0.280, F1: 0.575
| 2021-07-13 13:20:20 | INFO | Validation tp: 203, fn: 131, fp: 163, tn: 504
| 2021-07-13 13:20:20 | INFO | Validation loss: 0.559, acc: 0.706, F1: 0.677
| 2021-07-13 13:20:20 | INFO | Start epoch 4:
| 2021-07-13 13:20:21 | INFO | Train Loss: 0.465, tp: 16, fn: 7, fp: 4, tn: 37, Acc: 0.828, Prec: 0.800, Rec: 0.696, F1: 0.807
| 2021-07-13 13:21:24 | INFO | Validation tp: 110, fn: 224, fp: 62, tn: 605
| 2021-07-13 13:21:24 | INFO | Validation loss: 0.584, acc: 0.714, F1: 0.622
| 2021-07-13 13:21:24 | INFO | Start epoch 5:
| 2021-07-13 13:21:25 | INFO | Train Loss: 0.476, tp: 11, fn: 10, fp: 2, tn: 41, Acc: 0.812, Prec: 0.846, Rec: 0.524, F1: 0.760
| 2021-07-13 13:22:29 | INFO | Validation tp: 163, fn: 171, fp: 119, tn: 548
| 2021-07-13 13:22:29 | INFO | Validation loss: 0.600, acc: 0.710, F1: 0.660
| 2021-07-13 13:22:29 | INFO | Start epoch 6:
| 2021-07-13 13:22:29 | INFO | Train Loss: 0.326, tp: 19, fn: 3, fp: 6, tn: 36, Acc: 0.859, Prec: 0.760, Rec: 0.864, F1: 0.849
| 2021-07-13 13:23:33 | INFO | Validation tp: 186, fn: 148, fp: 136, tn: 531
| 2021-07-13 13:23:33 | INFO | Validation loss: 0.654, acc: 0.716, F1: 0.678
| 2021-07-13 13:23:33 | INFO | Start epoch 7:
| 2021-07-13 13:23:33 | INFO | Train Loss: 0.364, tp: 15, fn: 5, fp: 5, tn: 39, Acc: 0.844, Prec: 0.750, Rec: 0.750, F1: 0.818
| 2021-07-13 13:24:37 | INFO | Validation tp: 191, fn: 143, fp: 141, tn: 526
| 2021-07-13 13:24:37 | INFO | Validation loss: 0.711, acc: 0.716, F1: 0.680
| 2021-07-13 13:24:37 | INFO | Start epoch 8:
| 2021-07-13 13:24:37 | INFO | Train Loss: 0.312, tp: 27, fn: 3, fp: 4, tn: 30, Acc: 0.891, Prec: 0.871, Rec: 0.900, F1: 0.890
| 2021-07-13 13:25:41 | INFO | Validation tp: 161, fn: 173, fp: 122, tn: 545
| 2021-07-13 13:25:41 | INFO | Validation loss: 0.869, acc: 0.705, F1: 0.654
| 2021-07-13 13:25:41 | INFO | Start epoch 9:
| 2021-07-13 13:25:41 | INFO | Train Loss: 0.233, tp: 21, fn: 3, fp: 2, tn: 38, Acc: 0.922, Prec: 0.913, Rec: 0.875, F1: 0.916
| 2021-07-13 13:26:45 | INFO | Validation tp: 155, fn: 179, fp: 116, tn: 551
| 2021-07-13 13:26:45 | INFO | Validation loss: 0.979, acc: 0.705, F1: 0.651
| 2021-07-13 13:26:45 | INFO | Start epoch 10:
| 2021-07-13 13:26:46 | INFO | Train Loss: 0.139, tp: 16, fn: 1, fp: 1, tn: 46, Acc: 0.969, Prec: 0.941, Rec: 0.941, F1: 0.960
| 2021-07-13 13:27:49 | INFO | Validation tp: 153, fn: 181, fp: 119, tn: 548
| 2021-07-13 13:27:49 | INFO | Validation loss: 0.982, acc: 0.700, F1: 0.645
| 2021-07-13 13:27:51 | INFO | 
==============================Start training==============================
| 2021-07-13 13:27:51 | INFO | Command Line Args:   --lr 3e-5 --warmup_ratio 0.2 -c config/enzh_at_least_one.conf
Config File (config/enzh_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/enzh_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/enzh_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 13:27:51 | INFO | 
lr: 3e-05

| 2021-07-13 13:28:03 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 13:28:03 | INFO | Start epoch 1:
| 2021-07-13 13:28:04 | INFO | Train Loss: 0.660, tp: 0, fn: 25, fp: 0, tn: 39, Acc: 0.609, Prec: 0.000, Rec: 0.000, F1: 0.379
| 2021-07-13 13:29:07 | INFO | Validation tp: 13, fn: 321, fp: 4, tn: 663
| 2021-07-13 13:29:07 | INFO | Validation loss: 0.602, acc: 0.675, F1: 0.439
| 2021-07-13 13:29:07 | INFO | Start epoch 2:
| 2021-07-13 13:29:08 | INFO | Train Loss: 0.571, tp: 1, fn: 18, fp: 2, tn: 43, Acc: 0.688, Prec: 0.333, Rec: 0.053, F1: 0.451
| 2021-07-13 13:30:11 | INFO | Validation tp: 118, fn: 216, fp: 64, tn: 603
| 2021-07-13 13:30:11 | INFO | Validation loss: 0.555, acc: 0.720, F1: 0.634
| 2021-07-13 13:30:11 | INFO | Start epoch 3:
| 2021-07-13 13:30:12 | INFO | Train Loss: 0.581, tp: 12, fn: 13, fp: 5, tn: 34, Acc: 0.719, Prec: 0.706, Rec: 0.480, F1: 0.681
| 2021-07-13 13:31:15 | INFO | Validation tp: 221, fn: 113, fp: 205, tn: 462
| 2021-07-13 13:31:15 | INFO | Validation loss: 0.581, acc: 0.682, F1: 0.663
| 2021-07-13 13:31:15 | INFO | Start epoch 4:
| 2021-07-13 13:31:16 | INFO | Train Loss: 0.560, tp: 17, fn: 6, fp: 10, tn: 31, Acc: 0.750, Prec: 0.630, Rec: 0.739, F1: 0.737
| 2021-07-13 13:32:20 | INFO | Validation tp: 94, fn: 240, fp: 52, tn: 615
| 2021-07-13 13:32:20 | INFO | Validation loss: 0.617, acc: 0.708, F1: 0.600
| 2021-07-13 13:32:20 | INFO | Start epoch 5:
| 2021-07-13 13:32:20 | INFO | Train Loss: 0.482, tp: 9, fn: 12, fp: 0, tn: 43, Acc: 0.812, Prec: 1.000, Rec: 0.429, F1: 0.739
| 2021-07-13 13:33:24 | INFO | Validation tp: 136, fn: 198, fp: 86, tn: 581
| 2021-07-13 13:33:24 | INFO | Validation loss: 0.604, acc: 0.716, F1: 0.646
| 2021-07-13 13:33:24 | INFO | Start epoch 6:
| 2021-07-13 13:33:25 | INFO | Train Loss: 0.345, tp: 15, fn: 7, fp: 4, tn: 38, Acc: 0.828, Prec: 0.789, Rec: 0.682, F1: 0.803
| 2021-07-13 13:34:28 | INFO | Validation tp: 168, fn: 166, fp: 121, tn: 546
| 2021-07-13 13:34:28 | INFO | Validation loss: 0.654, acc: 0.713, F1: 0.666
| 2021-07-13 13:34:28 | INFO | Start epoch 7:
| 2021-07-13 13:34:29 | INFO | Train Loss: 0.346, tp: 15, fn: 5, fp: 3, tn: 41, Acc: 0.875, Prec: 0.833, Rec: 0.750, F1: 0.850
| 2021-07-13 13:35:33 | INFO | Validation tp: 160, fn: 174, fp: 126, tn: 541
| 2021-07-13 13:35:33 | INFO | Validation loss: 0.706, acc: 0.700, F1: 0.650
| 2021-07-13 13:35:33 | INFO | Start epoch 8:
| 2021-07-13 13:35:33 | INFO | Train Loss: 0.325, tp: 23, fn: 7, fp: 6, tn: 28, Acc: 0.797, Prec: 0.793, Rec: 0.767, F1: 0.796
| 2021-07-13 13:36:37 | INFO | Validation tp: 121, fn: 213, fp: 94, tn: 573
| 2021-07-13 13:36:37 | INFO | Validation loss: 0.801, acc: 0.693, F1: 0.615
| 2021-07-13 13:36:37 | INFO | Start epoch 9:
| 2021-07-13 13:36:37 | INFO | Train Loss: 0.319, tp: 17, fn: 7, fp: 5, tn: 35, Acc: 0.812, Prec: 0.773, Rec: 0.708, F1: 0.796
| 2021-07-13 13:37:41 | INFO | Validation tp: 140, fn: 194, fp: 97, tn: 570
| 2021-07-13 13:37:41 | INFO | Validation loss: 0.855, acc: 0.709, F1: 0.644
| 2021-07-13 13:37:41 | INFO | Start epoch 10:
| 2021-07-13 13:37:42 | INFO | Train Loss: 0.133, tp: 15, fn: 2, fp: 1, tn: 46, Acc: 0.953, Prec: 0.938, Rec: 0.882, F1: 0.939
| 2021-07-13 13:38:45 | INFO | Validation tp: 155, fn: 179, fp: 118, tn: 549
| 2021-07-13 13:38:45 | INFO | Validation loss: 0.889, acc: 0.703, F1: 0.649
| 2021-07-13 13:38:48 | INFO | 
==============================Start training==============================
| 2021-07-13 13:38:48 | INFO | Command Line Args:   --lr 4e-5 --warmup_ratio 0.2 -c config/enzh_at_least_one.conf
Config File (config/enzh_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/enzh_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/enzh_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 13:38:48 | INFO | 
lr: 4e-05

| 2021-07-13 13:38:59 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 13:38:59 | INFO | Start epoch 1:
| 2021-07-13 13:39:00 | INFO | Train Loss: 0.660, tp: 0, fn: 25, fp: 0, tn: 39, Acc: 0.609, Prec: 0.000, Rec: 0.000, F1: 0.379
| 2021-07-13 13:40:04 | INFO | Validation tp: 15, fn: 319, fp: 8, tn: 659
| 2021-07-13 13:40:04 | INFO | Validation loss: 0.610, acc: 0.673, F1: 0.443
| 2021-07-13 13:40:04 | INFO | Start epoch 2:
| 2021-07-13 13:40:04 | INFO | Train Loss: 0.595, tp: 1, fn: 18, fp: 2, tn: 43, Acc: 0.688, Prec: 0.333, Rec: 0.053, F1: 0.451
| 2021-07-13 13:41:08 | INFO | Validation tp: 53, fn: 281, fp: 37, tn: 630
| 2021-07-13 13:41:08 | INFO | Validation loss: 0.596, acc: 0.682, F1: 0.524
| 2021-07-13 13:41:08 | INFO | Start epoch 3:
| 2021-07-13 13:41:09 | INFO | Train Loss: 0.626, tp: 7, fn: 18, fp: 3, tn: 36, Acc: 0.672, Prec: 0.700, Rec: 0.280, F1: 0.587
| 2021-07-13 13:42:13 | INFO | Validation tp: 0, fn: 334, fp: 0, tn: 667
| 2021-07-13 13:42:13 | INFO | Validation loss: 0.641, acc: 0.666, F1: 0.400
| 2021-07-13 13:42:13 | INFO | Start epoch 4:
| 2021-07-13 13:42:13 | INFO | Train Loss: 0.649, tp: 0, fn: 23, fp: 0, tn: 41, Acc: 0.641, Prec: 0.000, Rec: 0.000, F1: 0.390
| 2021-07-13 13:43:17 | INFO | Validation tp: 0, fn: 334, fp: 0, tn: 667
| 2021-07-13 13:43:17 | INFO | Validation loss: 0.636, acc: 0.666, F1: 0.400
| 2021-07-13 13:43:17 | INFO | Start epoch 5:
| 2021-07-13 13:43:17 | INFO | Train Loss: 0.643, tp: 0, fn: 21, fp: 0, tn: 43, Acc: 0.672, Prec: 0.000, Rec: 0.000, F1: 0.402
| 2021-07-13 13:44:22 | INFO | Validation tp: 0, fn: 334, fp: 0, tn: 667
| 2021-07-13 13:44:22 | INFO | Validation loss: 0.636, acc: 0.666, F1: 0.400
| 2021-07-13 13:44:22 | INFO | Start epoch 6:
| 2021-07-13 13:44:22 | INFO | Train Loss: 0.653, tp: 0, fn: 22, fp: 0, tn: 42, Acc: 0.656, Prec: 0.000, Rec: 0.000, F1: 0.396
| 2021-07-13 13:45:26 | INFO | Validation tp: 0, fn: 334, fp: 0, tn: 667
| 2021-07-13 13:45:26 | INFO | Validation loss: 0.636, acc: 0.666, F1: 0.400
| 2021-07-13 13:45:26 | INFO | Start epoch 7:
| 2021-07-13 13:45:27 | INFO | Train Loss: 0.630, tp: 0, fn: 20, fp: 0, tn: 44, Acc: 0.688, Prec: 0.000, Rec: 0.000, F1: 0.407
| 2021-07-13 13:46:30 | INFO | Validation tp: 0, fn: 334, fp: 0, tn: 667
| 2021-07-13 13:46:30 | INFO | Validation loss: 0.636, acc: 0.666, F1: 0.400
| 2021-07-13 13:46:30 | INFO | Start epoch 8:
| 2021-07-13 13:46:31 | INFO | Train Loss: 0.739, tp: 0, fn: 30, fp: 0, tn: 34, Acc: 0.531, Prec: 0.000, Rec: 0.000, F1: 0.347
| 2021-07-13 13:47:35 | INFO | Validation tp: 0, fn: 334, fp: 0, tn: 667
| 2021-07-13 13:47:35 | INFO | Validation loss: 0.639, acc: 0.666, F1: 0.400
| 2021-07-13 13:47:35 | INFO | Start epoch 9:
| 2021-07-13 13:47:35 | INFO | Train Loss: 0.676, tp: 0, fn: 24, fp: 0, tn: 40, Acc: 0.625, Prec: 0.000, Rec: 0.000, F1: 0.385
| 2021-07-13 13:48:39 | INFO | Validation tp: 0, fn: 334, fp: 0, tn: 667
| 2021-07-13 13:48:39 | INFO | Validation loss: 0.636, acc: 0.666, F1: 0.400
| 2021-07-13 13:48:39 | INFO | Start epoch 10:
| 2021-07-13 13:48:40 | INFO | Train Loss: 0.599, tp: 0, fn: 17, fp: 0, tn: 47, Acc: 0.734, Prec: 0.000, Rec: 0.000, F1: 0.423
| 2021-07-13 13:49:43 | INFO | Validation tp: 0, fn: 334, fp: 0, tn: 667
| 2021-07-13 13:49:43 | INFO | Validation loss: 0.636, acc: 0.666, F1: 0.400
| 2021-07-13 13:49:46 | INFO | 
==============================Start training==============================
| 2021-07-13 13:49:46 | INFO | Command Line Args:   --lr 5e-5 --warmup_ratio 0.2 -c config/enzh_at_least_one.conf
Config File (config/enzh_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/enzh_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/enzh_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 13:49:46 | INFO | 
lr: 5e-05

| 2021-07-13 13:49:59 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 13:49:59 | INFO | Start epoch 1:
| 2021-07-13 13:49:59 | INFO | Train Loss: 0.660, tp: 0, fn: 25, fp: 0, tn: 39, Acc: 0.609, Prec: 0.000, Rec: 0.000, F1: 0.379
| 2021-07-13 13:51:02 | INFO | Validation tp: 0, fn: 334, fp: 0, tn: 667
| 2021-07-13 13:51:02 | INFO | Validation loss: 0.615, acc: 0.666, F1: 0.400
| 2021-07-13 13:51:02 | INFO | Start epoch 2:
| 2021-07-13 13:51:03 | INFO | Train Loss: 0.599, tp: 3, fn: 16, fp: 5, tn: 40, Acc: 0.672, Prec: 0.375, Rec: 0.158, F1: 0.507
| 2021-07-13 13:52:07 | INFO | Validation tp: 21, fn: 313, fp: 14, tn: 653
| 2021-07-13 13:52:07 | INFO | Validation loss: 0.574, acc: 0.673, F1: 0.457
| 2021-07-13 13:52:07 | INFO | Start epoch 3:
| 2021-07-13 13:52:07 | INFO | Train Loss: 0.611, tp: 5, fn: 20, fp: 3, tn: 36, Acc: 0.641, Prec: 0.625, Rec: 0.200, F1: 0.530
| 2021-07-13 13:53:11 | INFO | Validation tp: 227, fn: 107, fp: 252, tn: 415
| 2021-07-13 13:53:11 | INFO | Validation loss: 0.617, acc: 0.641, F1: 0.628
| 2021-07-13 13:53:11 | INFO | Start epoch 4:
| 2021-07-13 13:53:11 | INFO | Train Loss: 0.443, tp: 20, fn: 3, fp: 10, tn: 31, Acc: 0.797, Prec: 0.667, Rec: 0.870, F1: 0.791
| 2021-07-13 13:54:15 | INFO | Validation tp: 136, fn: 198, fp: 82, tn: 585
| 2021-07-13 13:54:15 | INFO | Validation loss: 0.575, acc: 0.720, F1: 0.650
| 2021-07-13 13:54:15 | INFO | Start epoch 5:
| 2021-07-13 13:54:15 | INFO | Train Loss: 0.466, tp: 10, fn: 11, fp: 2, tn: 41, Acc: 0.797, Prec: 0.833, Rec: 0.476, F1: 0.735
| 2021-07-13 13:55:19 | INFO | Validation tp: 179, fn: 155, fp: 151, tn: 516
| 2021-07-13 13:55:19 | INFO | Validation loss: 0.596, acc: 0.694, F1: 0.655
| 2021-07-13 13:55:19 | INFO | Start epoch 6:
| 2021-07-13 13:55:19 | INFO | Train Loss: 0.365, tp: 19, fn: 3, fp: 8, tn: 34, Acc: 0.828, Prec: 0.704, Rec: 0.864, F1: 0.818
| 2021-07-13 13:56:23 | INFO | Validation tp: 188, fn: 146, fp: 155, tn: 512
| 2021-07-13 13:56:23 | INFO | Validation loss: 0.661, acc: 0.699, F1: 0.664
| 2021-07-13 13:56:23 | INFO | Start epoch 7:
| 2021-07-13 13:56:23 | INFO | Train Loss: 0.261, tp: 18, fn: 2, fp: 4, tn: 40, Acc: 0.906, Prec: 0.818, Rec: 0.900, F1: 0.894
| 2021-07-13 13:57:27 | INFO | Validation tp: 140, fn: 194, fp: 111, tn: 556
| 2021-07-13 13:57:27 | INFO | Validation loss: 0.755, acc: 0.695, F1: 0.632
| 2021-07-13 13:57:27 | INFO | Start epoch 8:
| 2021-07-13 13:57:28 | INFO | Train Loss: 0.172, tp: 28, fn: 2, fp: 1, tn: 33, Acc: 0.953, Prec: 0.966, Rec: 0.933, F1: 0.953
| 2021-07-13 13:58:31 | INFO | Validation tp: 139, fn: 195, fp: 113, tn: 554
| 2021-07-13 13:58:31 | INFO | Validation loss: 0.952, acc: 0.692, F1: 0.628
| 2021-07-13 13:58:31 | INFO | Start epoch 9:
| 2021-07-13 13:58:32 | INFO | Train Loss: 0.094, tp: 24, fn: 0, fp: 0, tn: 40, Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000
| 2021-07-13 13:59:36 | INFO | Validation tp: 127, fn: 207, fp: 96, tn: 571
| 2021-07-13 13:59:36 | INFO | Validation loss: 1.072, acc: 0.697, F1: 0.623
| 2021-07-13 13:59:36 | INFO | Start epoch 10:
| 2021-07-13 13:59:36 | INFO | Train Loss: 0.048, tp: 17, fn: 0, fp: 1, tn: 46, Acc: 0.984, Prec: 0.944, Rec: 1.000, F1: 0.980
| 2021-07-13 14:00:40 | INFO | Validation tp: 149, fn: 185, fp: 116, tn: 551
| 2021-07-13 14:00:40 | INFO | Validation loss: 1.139, acc: 0.699, F1: 0.641
| 2021-07-13 14:00:42 | INFO | 
==============================Start training==============================
| 2021-07-13 14:00:42 | INFO | Command Line Args:   --lr 2e-5 --warmup_ratio 0.3 -c config/enzh_at_least_one.conf
Config File (config/enzh_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/enzh_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/enzh_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 14:00:42 | INFO | 
lr: 2e-05

| 2021-07-13 14:00:55 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 14:00:55 | INFO | Start epoch 1:
| 2021-07-13 14:00:55 | INFO | Train Loss: 0.660, tp: 0, fn: 25, fp: 0, tn: 39, Acc: 0.609, Prec: 0.000, Rec: 0.000, F1: 0.379
| 2021-07-13 14:01:58 | INFO | Validation tp: 0, fn: 334, fp: 0, tn: 667
| 2021-07-13 14:01:58 | INFO | Validation loss: 0.620, acc: 0.666, F1: 0.400
| 2021-07-13 14:01:58 | INFO | Start epoch 2:
| 2021-07-13 14:01:59 | INFO | Train Loss: 0.610, tp: 0, fn: 19, fp: 0, tn: 45, Acc: 0.703, Prec: 0.000, Rec: 0.000, F1: 0.413
| 2021-07-13 14:03:02 | INFO | Validation tp: 78, fn: 256, fp: 50, tn: 617
| 2021-07-13 14:03:02 | INFO | Validation loss: 0.590, acc: 0.694, F1: 0.569
| 2021-07-13 14:03:02 | INFO | Start epoch 3:
| 2021-07-13 14:03:03 | INFO | Train Loss: 0.603, tp: 12, fn: 13, fp: 8, tn: 31, Acc: 0.672, Prec: 0.600, Rec: 0.480, F1: 0.640
| 2021-07-13 14:04:07 | INFO | Validation tp: 162, fn: 172, fp: 116, tn: 551
| 2021-07-13 14:04:07 | INFO | Validation loss: 0.566, acc: 0.712, F1: 0.661
| 2021-07-13 14:04:07 | INFO | Start epoch 4:
| 2021-07-13 14:04:07 | INFO | Train Loss: 0.507, tp: 14, fn: 9, fp: 4, tn: 37, Acc: 0.797, Prec: 0.778, Rec: 0.609, F1: 0.767
| 2021-07-13 14:05:11 | INFO | Validation tp: 81, fn: 253, fp: 48, tn: 619
| 2021-07-13 14:05:11 | INFO | Validation loss: 0.599, acc: 0.699, F1: 0.577
| 2021-07-13 14:05:11 | INFO | Start epoch 5:
| 2021-07-13 14:05:12 | INFO | Train Loss: 0.514, tp: 5, fn: 16, fp: 0, tn: 43, Acc: 0.750, Prec: 1.000, Rec: 0.238, F1: 0.614
| 2021-07-13 14:06:16 | INFO | Validation tp: 161, fn: 173, fp: 124, tn: 543
| 2021-07-13 14:06:16 | INFO | Validation loss: 0.573, acc: 0.703, F1: 0.653
| 2021-07-13 14:06:16 | INFO | Start epoch 6:
| 2021-07-13 14:06:16 | INFO | Train Loss: 0.393, tp: 18, fn: 4, fp: 9, tn: 33, Acc: 0.797, Prec: 0.667, Rec: 0.818, F1: 0.785
| 2021-07-13 14:07:20 | INFO | Validation tp: 181, fn: 153, fp: 156, tn: 511
| 2021-07-13 14:07:20 | INFO | Validation loss: 0.636, acc: 0.691, F1: 0.654
| 2021-07-13 14:07:20 | INFO | Start epoch 7:
| 2021-07-13 14:07:21 | INFO | Train Loss: 0.318, tp: 16, fn: 4, fp: 5, tn: 39, Acc: 0.859, Prec: 0.762, Rec: 0.800, F1: 0.839
| 2021-07-13 14:08:25 | INFO | Validation tp: 136, fn: 198, fp: 95, tn: 572
| 2021-07-13 14:08:25 | INFO | Validation loss: 0.765, acc: 0.707, F1: 0.639
| 2021-07-13 14:08:25 | INFO | Start epoch 8:
| 2021-07-13 14:08:26 | INFO | Train Loss: 0.335, tp: 21, fn: 9, fp: 1, tn: 33, Acc: 0.844, Prec: 0.955, Rec: 0.700, F1: 0.838
| 2021-07-13 14:09:29 | INFO | Validation tp: 122, fn: 212, fp: 85, tn: 582
| 2021-07-13 14:09:29 | INFO | Validation loss: 0.931, acc: 0.703, F1: 0.624
| 2021-07-13 14:09:29 | INFO | Start epoch 9:
| 2021-07-13 14:09:30 | INFO | Train Loss: 0.173, tp: 22, fn: 2, fp: 2, tn: 38, Acc: 0.938, Prec: 0.917, Rec: 0.917, F1: 0.933
| 2021-07-13 14:10:33 | INFO | Validation tp: 151, fn: 183, fp: 115, tn: 552
| 2021-07-13 14:10:33 | INFO | Validation loss: 1.018, acc: 0.702, F1: 0.645
| 2021-07-13 14:10:33 | INFO | Start epoch 10:
| 2021-07-13 14:10:34 | INFO | Train Loss: 0.136, tp: 16, fn: 1, fp: 4, tn: 43, Acc: 0.922, Prec: 0.800, Rec: 0.941, F1: 0.905
| 2021-07-13 14:11:37 | INFO | Validation tp: 158, fn: 176, fp: 123, tn: 544
| 2021-07-13 14:11:37 | INFO | Validation loss: 1.045, acc: 0.701, F1: 0.649
| 2021-07-13 14:11:40 | INFO | 
==============================Start training==============================
| 2021-07-13 14:11:40 | INFO | Command Line Args:   --lr 3e-5 --warmup_ratio 0.3 -c config/enzh_at_least_one.conf
Config File (config/enzh_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/enzh_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/enzh_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 14:11:40 | INFO | 
lr: 3e-05

| 2021-07-13 14:11:52 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 14:11:52 | INFO | Start epoch 1:
| 2021-07-13 14:11:52 | INFO | Train Loss: 0.660, tp: 0, fn: 25, fp: 0, tn: 39, Acc: 0.609, Prec: 0.000, Rec: 0.000, F1: 0.379
| 2021-07-13 14:12:56 | INFO | Validation tp: 21, fn: 313, fp: 13, tn: 654
| 2021-07-13 14:12:56 | INFO | Validation loss: 0.605, acc: 0.674, F1: 0.457
| 2021-07-13 14:12:56 | INFO | Start epoch 2:
| 2021-07-13 14:12:57 | INFO | Train Loss: 0.591, tp: 1, fn: 18, fp: 1, tn: 44, Acc: 0.703, Prec: 0.500, Rec: 0.053, F1: 0.459
| 2021-07-13 14:14:01 | INFO | Validation tp: 75, fn: 259, fp: 35, tn: 632
| 2021-07-13 14:14:01 | INFO | Validation loss: 0.571, acc: 0.706, F1: 0.575
| 2021-07-13 14:14:01 | INFO | Start epoch 3:
| 2021-07-13 14:14:02 | INFO | Train Loss: 0.592, tp: 7, fn: 18, fp: 4, tn: 35, Acc: 0.656, Prec: 0.636, Rec: 0.280, F1: 0.575
| 2021-07-13 14:15:05 | INFO | Validation tp: 244, fn: 90, fp: 261, tn: 406
| 2021-07-13 14:15:05 | INFO | Validation loss: 0.596, acc: 0.649, F1: 0.640
| 2021-07-13 14:15:05 | INFO | Start epoch 4:
| 2021-07-13 14:15:06 | INFO | Train Loss: 0.485, tp: 19, fn: 4, fp: 8, tn: 33, Acc: 0.812, Prec: 0.704, Rec: 0.826, F1: 0.803
| 2021-07-13 14:16:10 | INFO | Validation tp: 112, fn: 222, fp: 76, tn: 591
| 2021-07-13 14:16:10 | INFO | Validation loss: 0.569, acc: 0.702, F1: 0.614
| 2021-07-13 14:16:10 | INFO | Start epoch 5:
| 2021-07-13 14:16:10 | INFO | Train Loss: 0.492, tp: 10, fn: 11, fp: 2, tn: 41, Acc: 0.797, Prec: 0.833, Rec: 0.476, F1: 0.735
| 2021-07-13 14:17:14 | INFO | Validation tp: 175, fn: 159, fp: 123, tn: 544
| 2021-07-13 14:17:14 | INFO | Validation loss: 0.609, acc: 0.718, F1: 0.674
| 2021-07-13 14:17:14 | INFO | Start epoch 6:
| 2021-07-13 14:17:14 | INFO | Train Loss: 0.329, tp: 19, fn: 3, fp: 7, tn: 35, Acc: 0.844, Prec: 0.731, Rec: 0.864, F1: 0.833
| 2021-07-13 14:18:18 | INFO | Validation tp: 199, fn: 135, fp: 162, tn: 505
| 2021-07-13 14:18:18 | INFO | Validation loss: 0.673, acc: 0.703, F1: 0.673
| 2021-07-13 14:18:18 | INFO | Start epoch 7:
| 2021-07-13 14:18:19 | INFO | Train Loss: 0.393, tp: 17, fn: 3, fp: 9, tn: 35, Acc: 0.812, Prec: 0.654, Rec: 0.850, F1: 0.796
| 2021-07-13 14:19:23 | INFO | Validation tp: 187, fn: 147, fp: 164, tn: 503
| 2021-07-13 14:19:23 | INFO | Validation loss: 0.796, acc: 0.689, F1: 0.655
| 2021-07-13 14:19:23 | INFO | Start epoch 8:
| 2021-07-13 14:19:24 | INFO | Train Loss: 0.169, tp: 30, fn: 0, fp: 4, tn: 30, Acc: 0.938, Prec: 0.882, Rec: 1.000, F1: 0.938
| 2021-07-13 14:20:28 | INFO | Validation tp: 145, fn: 189, fp: 101, tn: 566
| 2021-07-13 14:20:28 | INFO | Validation loss: 0.975, acc: 0.710, F1: 0.648
| 2021-07-13 14:20:28 | INFO | Start epoch 9:
| 2021-07-13 14:20:28 | INFO | Train Loss: 0.093, tp: 22, fn: 2, fp: 0, tn: 40, Acc: 0.969, Prec: 1.000, Rec: 0.917, F1: 0.966
| 2021-07-13 14:21:32 | INFO | Validation tp: 149, fn: 185, fp: 106, tn: 561
| 2021-07-13 14:21:32 | INFO | Validation loss: 1.084, acc: 0.709, F1: 0.650
| 2021-07-13 14:21:32 | INFO | Start epoch 10:
| 2021-07-13 14:21:33 | INFO | Train Loss: 0.053, tp: 17, fn: 0, fp: 2, tn: 45, Acc: 0.969, Prec: 0.895, Rec: 1.000, F1: 0.961
| 2021-07-13 14:22:37 | INFO | Validation tp: 158, fn: 176, fp: 118, tn: 549
| 2021-07-13 14:22:37 | INFO | Validation loss: 1.156, acc: 0.706, F1: 0.653
| 2021-07-13 14:22:39 | INFO | 
==============================Start training==============================
| 2021-07-13 14:22:39 | INFO | Command Line Args:   --lr 4e-5 --warmup_ratio 0.3 -c config/enzh_at_least_one.conf
Config File (config/enzh_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/enzh_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/enzh_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 14:22:39 | INFO | 
lr: 4e-05

| 2021-07-13 14:22:52 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 14:22:52 | INFO | Start epoch 1:
| 2021-07-13 14:22:52 | INFO | Train Loss: 0.660, tp: 0, fn: 25, fp: 0, tn: 39, Acc: 0.609, Prec: 0.000, Rec: 0.000, F1: 0.379
| 2021-07-13 14:23:56 | INFO | Validation tp: 0, fn: 334, fp: 0, tn: 667
| 2021-07-13 14:23:56 | INFO | Validation loss: 0.614, acc: 0.666, F1: 0.400
| 2021-07-13 14:23:56 | INFO | Start epoch 2:
| 2021-07-13 14:23:56 | INFO | Train Loss: 0.608, tp: 1, fn: 18, fp: 4, tn: 41, Acc: 0.656, Prec: 0.200, Rec: 0.053, F1: 0.436
| 2021-07-13 14:25:00 | INFO | Validation tp: 125, fn: 209, fp: 72, tn: 595
| 2021-07-13 14:25:00 | INFO | Validation loss: 0.556, acc: 0.719, F1: 0.640
| 2021-07-13 14:25:00 | INFO | Start epoch 3:
| 2021-07-13 14:25:00 | INFO | Train Loss: 0.602, tp: 14, fn: 11, fp: 6, tn: 33, Acc: 0.734, Prec: 0.700, Rec: 0.560, F1: 0.709
| 2021-07-13 14:26:04 | INFO | Validation tp: 212, fn: 122, fp: 170, tn: 497
| 2021-07-13 14:26:04 | INFO | Validation loss: 0.568, acc: 0.708, F1: 0.683
| 2021-07-13 14:26:04 | INFO | Start epoch 4:
| 2021-07-13 14:26:05 | INFO | Train Loss: 0.468, tp: 17, fn: 6, fp: 7, tn: 34, Acc: 0.797, Prec: 0.708, Rec: 0.739, F1: 0.781
| 2021-07-13 14:27:09 | INFO | Validation tp: 94, fn: 240, fp: 61, tn: 606
| 2021-07-13 14:27:09 | INFO | Validation loss: 0.564, acc: 0.699, F1: 0.593
| 2021-07-13 14:27:09 | INFO | Start epoch 5:
| 2021-07-13 14:27:09 | INFO | Train Loss: 0.530, tp: 5, fn: 16, fp: 1, tn: 42, Acc: 0.734, Prec: 0.833, Rec: 0.238, F1: 0.601
| 2021-07-13 14:28:13 | INFO | Validation tp: 173, fn: 161, fp: 139, tn: 528
| 2021-07-13 14:28:13 | INFO | Validation loss: 0.569, acc: 0.700, F1: 0.657
| 2021-07-13 14:28:13 | INFO | Start epoch 6:
| 2021-07-13 14:28:13 | INFO | Train Loss: 0.390, tp: 19, fn: 3, fp: 6, tn: 36, Acc: 0.859, Prec: 0.760, Rec: 0.864, F1: 0.849
| 2021-07-13 14:29:17 | INFO | Validation tp: 176, fn: 158, fp: 143, tn: 524
| 2021-07-13 14:29:17 | INFO | Validation loss: 0.622, acc: 0.699, F1: 0.658
| 2021-07-13 14:29:17 | INFO | Start epoch 7:
| 2021-07-13 14:29:18 | INFO | Train Loss: 0.351, tp: 17, fn: 3, fp: 5, tn: 39, Acc: 0.875, Prec: 0.773, Rec: 0.850, F1: 0.858
| 2021-07-13 14:30:21 | INFO | Validation tp: 204, fn: 130, fp: 154, tn: 513
| 2021-07-13 14:30:21 | INFO | Validation loss: 0.673, acc: 0.716, F1: 0.686
| 2021-07-13 14:30:21 | INFO | Start epoch 8:
| 2021-07-13 14:30:21 | INFO | Train Loss: 0.330, tp: 26, fn: 4, fp: 5, tn: 29, Acc: 0.859, Prec: 0.839, Rec: 0.867, F1: 0.859
| 2021-07-13 14:31:25 | INFO | Validation tp: 140, fn: 194, fp: 90, tn: 577
| 2021-07-13 14:31:25 | INFO | Validation loss: 0.850, acc: 0.716, F1: 0.649
| 2021-07-13 14:31:25 | INFO | Start epoch 9:
| 2021-07-13 14:31:26 | INFO | Train Loss: 0.171, tp: 19, fn: 5, fp: 0, tn: 40, Acc: 0.922, Prec: 1.000, Rec: 0.792, F1: 0.912
| 2021-07-13 14:32:30 | INFO | Validation tp: 144, fn: 190, fp: 97, tn: 570
| 2021-07-13 14:32:30 | INFO | Validation loss: 0.957, acc: 0.713, F1: 0.650
| 2021-07-13 14:32:30 | INFO | Start epoch 10:
| 2021-07-13 14:32:31 | INFO | Train Loss: 0.098, tp: 15, fn: 2, fp: 0, tn: 47, Acc: 0.969, Prec: 1.000, Rec: 0.882, F1: 0.958
| 2021-07-13 14:33:34 | INFO | Validation tp: 157, fn: 177, fp: 124, tn: 543
| 2021-07-13 14:33:34 | INFO | Validation loss: 1.048, acc: 0.699, F1: 0.647
| 2021-07-13 14:33:37 | INFO | 
==============================Start training==============================
| 2021-07-13 14:33:37 | INFO | Command Line Args:   --lr 5e-5 --warmup_ratio 0.3 -c config/enzh_at_least_one.conf
Config File (config/enzh_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/enzh_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/enzh_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 14:33:37 | INFO | 
lr: 5e-05

| 2021-07-13 14:33:50 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 14:33:50 | INFO | Start epoch 1:
| 2021-07-13 14:33:50 | INFO | Train Loss: 0.660, tp: 0, fn: 25, fp: 0, tn: 39, Acc: 0.609, Prec: 0.000, Rec: 0.000, F1: 0.379
| 2021-07-13 14:34:54 | INFO | Validation tp: 4, fn: 330, fp: 4, tn: 663
| 2021-07-13 14:34:54 | INFO | Validation loss: 0.597, acc: 0.666, F1: 0.411
| 2021-07-13 14:34:54 | INFO | Start epoch 2:
| 2021-07-13 14:34:54 | INFO | Train Loss: 0.560, tp: 2, fn: 17, fp: 5, tn: 40, Acc: 0.656, Prec: 0.286, Rec: 0.105, F1: 0.469
| 2021-07-13 14:35:58 | INFO | Validation tp: 86, fn: 248, fp: 41, tn: 626
| 2021-07-13 14:35:58 | INFO | Validation loss: 0.563, acc: 0.711, F1: 0.593
| 2021-07-13 14:35:58 | INFO | Start epoch 3:
| 2021-07-13 14:35:59 | INFO | Train Loss: 0.566, tp: 8, fn: 17, fp: 3, tn: 36, Acc: 0.688, Prec: 0.727, Rec: 0.320, F1: 0.614
| 2021-07-13 14:37:02 | INFO | Validation tp: 1, fn: 333, fp: 0, tn: 667
| 2021-07-13 14:37:02 | INFO | Validation loss: 0.641, acc: 0.667, F1: 0.403
| 2021-07-13 14:37:02 | INFO | Start epoch 4:
| 2021-07-13 14:37:03 | INFO | Train Loss: 0.648, tp: 1, fn: 22, fp: 1, tn: 40, Acc: 0.641, Prec: 0.500, Rec: 0.043, F1: 0.428
| 2021-07-13 14:38:06 | INFO | Validation tp: 0, fn: 334, fp: 0, tn: 667
| 2021-07-13 14:38:06 | INFO | Validation loss: 0.636, acc: 0.666, F1: 0.400
| 2021-07-13 14:38:06 | INFO | Start epoch 5:
| 2021-07-13 14:38:07 | INFO | Train Loss: 0.631, tp: 0, fn: 21, fp: 0, tn: 43, Acc: 0.672, Prec: 0.000, Rec: 0.000, F1: 0.402
| 2021-07-13 14:39:11 | INFO | Validation tp: 0, fn: 334, fp: 0, tn: 667
| 2021-07-13 14:39:11 | INFO | Validation loss: 0.636, acc: 0.666, F1: 0.400
| 2021-07-13 14:39:11 | INFO | Start epoch 6:
| 2021-07-13 14:39:11 | INFO | Train Loss: 0.657, tp: 0, fn: 22, fp: 0, tn: 42, Acc: 0.656, Prec: 0.000, Rec: 0.000, F1: 0.396
| 2021-07-13 14:40:16 | INFO | Validation tp: 0, fn: 334, fp: 0, tn: 667
| 2021-07-13 14:40:16 | INFO | Validation loss: 0.636, acc: 0.666, F1: 0.400
| 2021-07-13 14:40:16 | INFO | Start epoch 7:
| 2021-07-13 14:40:16 | INFO | Train Loss: 0.633, tp: 0, fn: 20, fp: 0, tn: 44, Acc: 0.688, Prec: 0.000, Rec: 0.000, F1: 0.407
| 2021-07-13 14:41:20 | INFO | Validation tp: 0, fn: 334, fp: 0, tn: 667
| 2021-07-13 14:41:20 | INFO | Validation loss: 0.637, acc: 0.666, F1: 0.400
| 2021-07-13 14:41:20 | INFO | Start epoch 8:
| 2021-07-13 14:41:21 | INFO | Train Loss: 0.719, tp: 0, fn: 30, fp: 0, tn: 34, Acc: 0.531, Prec: 0.000, Rec: 0.000, F1: 0.347
| 2021-07-13 14:42:25 | INFO | Validation tp: 0, fn: 334, fp: 0, tn: 667
| 2021-07-13 14:42:25 | INFO | Validation loss: 0.639, acc: 0.666, F1: 0.400
| 2021-07-13 14:42:25 | INFO | Start epoch 9:
| 2021-07-13 14:42:25 | INFO | Train Loss: 0.675, tp: 0, fn: 24, fp: 0, tn: 40, Acc: 0.625, Prec: 0.000, Rec: 0.000, F1: 0.385
| 2021-07-13 14:43:29 | INFO | Validation tp: 0, fn: 334, fp: 0, tn: 667
| 2021-07-13 14:43:29 | INFO | Validation loss: 0.636, acc: 0.666, F1: 0.400
| 2021-07-13 14:43:29 | INFO | Start epoch 10:
| 2021-07-13 14:43:30 | INFO | Train Loss: 0.599, tp: 0, fn: 17, fp: 0, tn: 47, Acc: 0.734, Prec: 0.000, Rec: 0.000, F1: 0.423
| 2021-07-13 14:44:33 | INFO | Validation tp: 0, fn: 334, fp: 0, tn: 667
| 2021-07-13 14:44:33 | INFO | Validation loss: 0.637, acc: 0.666, F1: 0.400
| 2021-07-13 14:44:36 | INFO | 
==============================Start training==============================
| 2021-07-13 14:44:36 | INFO | Command Line Args:   --lr 2e-5 --warmup_ratio 0.2 -c config/enja_at_least_one.conf
Config File (config/enja_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/enja_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/enja_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 14:44:36 | INFO | 
lr: 2e-05

| 2021-07-13 14:44:47 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 14:44:47 | INFO | Start epoch 1:
| 2021-07-13 14:44:48 | INFO | Train Loss: 0.532, tp: 0, fn: 8, fp: 0, tn: 56, Acc: 0.875, Prec: 0.000, Rec: 0.000, F1: 0.467
| 2021-07-13 14:45:59 | INFO | Validation tp: 0, fn: 233, fp: 0, tn: 768
| 2021-07-13 14:45:59 | INFO | Validation loss: 0.523, acc: 0.767, F1: 0.434
| 2021-07-13 14:45:59 | INFO | Start epoch 2:
| 2021-07-13 14:46:00 | INFO | Train Loss: 0.631, tp: 0, fn: 18, fp: 0, tn: 46, Acc: 0.719, Prec: 0.000, Rec: 0.000, F1: 0.418
| 2021-07-13 14:47:11 | INFO | Validation tp: 0, fn: 233, fp: 0, tn: 768
| 2021-07-13 14:47:11 | INFO | Validation loss: 0.515, acc: 0.767, F1: 0.434
| 2021-07-13 14:47:11 | INFO | Start epoch 3:
| 2021-07-13 14:47:12 | INFO | Train Loss: 0.581, tp: 0, fn: 16, fp: 0, tn: 48, Acc: 0.750, Prec: 0.000, Rec: 0.000, F1: 0.429
| 2021-07-13 14:48:23 | INFO | Validation tp: 41, fn: 192, fp: 25, tn: 743
| 2021-07-13 14:48:23 | INFO | Validation loss: 0.512, acc: 0.783, F1: 0.573
| 2021-07-13 14:48:23 | INFO | Start epoch 4:
| 2021-07-13 14:48:23 | INFO | Train Loss: 0.539, tp: 0, fn: 13, fp: 1, tn: 50, Acc: 0.781, Prec: 0.000, Rec: 0.000, F1: 0.439
| 2021-07-13 14:49:35 | INFO | Validation tp: 73, fn: 160, fp: 58, tn: 710
| 2021-07-13 14:49:35 | INFO | Validation loss: 0.499, acc: 0.782, F1: 0.634
| 2021-07-13 14:49:35 | INFO | Start epoch 5:
| 2021-07-13 14:49:35 | INFO | Train Loss: 0.329, tp: 7, fn: 3, fp: 3, tn: 51, Acc: 0.906, Prec: 0.700, Rec: 0.700, F1: 0.822
| 2021-07-13 14:50:46 | INFO | Validation tp: 91, fn: 142, fp: 123, tn: 645
| 2021-07-13 14:50:46 | INFO | Validation loss: 0.525, acc: 0.735, F1: 0.618
| 2021-07-13 14:50:46 | INFO | Start epoch 6:
| 2021-07-13 14:50:47 | INFO | Train Loss: 0.417, tp: 4, fn: 7, fp: 3, tn: 50, Acc: 0.844, Prec: 0.571, Rec: 0.364, F1: 0.677
| 2021-07-13 14:51:58 | INFO | Validation tp: 44, fn: 189, fp: 32, tn: 736
| 2021-07-13 14:51:58 | INFO | Validation loss: 0.557, acc: 0.779, F1: 0.577
| 2021-07-13 14:51:58 | INFO | Start epoch 7:
| 2021-07-13 14:51:59 | INFO | Train Loss: 0.321, tp: 6, fn: 8, fp: 1, tn: 49, Acc: 0.859, Prec: 0.857, Rec: 0.429, F1: 0.744
| 2021-07-13 14:53:10 | INFO | Validation tp: 87, fn: 146, fp: 113, tn: 655
| 2021-07-13 14:53:10 | INFO | Validation loss: 0.667, acc: 0.741, F1: 0.618
| 2021-07-13 14:53:10 | INFO | Start epoch 8:
| 2021-07-13 14:53:11 | INFO | Train Loss: 0.329, tp: 16, fn: 5, fp: 3, tn: 40, Acc: 0.875, Prec: 0.842, Rec: 0.762, F1: 0.855
| 2021-07-13 14:54:22 | INFO | Validation tp: 84, fn: 149, fp: 125, tn: 643
| 2021-07-13 14:54:22 | INFO | Validation loss: 0.766, acc: 0.726, F1: 0.602
| 2021-07-13 14:54:22 | INFO | Start epoch 9:
| 2021-07-13 14:54:22 | INFO | Train Loss: 0.329, tp: 13, fn: 3, fp: 4, tn: 44, Acc: 0.891, Prec: 0.765, Rec: 0.812, F1: 0.857
| 2021-07-13 14:55:33 | INFO | Validation tp: 62, fn: 171, fp: 95, tn: 673
| 2021-07-13 14:55:33 | INFO | Validation loss: 0.867, acc: 0.734, F1: 0.576
| 2021-07-13 14:55:33 | INFO | Start epoch 10:
| 2021-07-13 14:55:34 | INFO | Train Loss: 0.209, tp: 14, fn: 4, fp: 2, tn: 44, Acc: 0.906, Prec: 0.875, Rec: 0.778, F1: 0.880
| 2021-07-13 14:56:45 | INFO | Validation tp: 61, fn: 172, fp: 76, tn: 692
| 2021-07-13 14:56:45 | INFO | Validation loss: 0.904, acc: 0.752, F1: 0.589
| 2021-07-13 14:56:48 | INFO | 
==============================Start training==============================
| 2021-07-13 14:56:48 | INFO | Command Line Args:   --lr 3e-5 --warmup_ratio 0.2 -c config/enja_at_least_one.conf
Config File (config/enja_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/enja_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/enja_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 14:56:48 | INFO | 
lr: 3e-05

| 2021-07-13 14:57:00 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 14:57:00 | INFO | Start epoch 1:
| 2021-07-13 14:57:01 | INFO | Train Loss: 0.532, tp: 0, fn: 8, fp: 0, tn: 56, Acc: 0.875, Prec: 0.000, Rec: 0.000, F1: 0.467
| 2021-07-13 14:58:12 | INFO | Validation tp: 0, fn: 233, fp: 0, tn: 768
| 2021-07-13 14:58:12 | INFO | Validation loss: 0.519, acc: 0.767, F1: 0.434
| 2021-07-13 14:58:12 | INFO | Start epoch 2:
| 2021-07-13 14:58:12 | INFO | Train Loss: 0.672, tp: 0, fn: 18, fp: 0, tn: 46, Acc: 0.719, Prec: 0.000, Rec: 0.000, F1: 0.418
| 2021-07-13 14:59:24 | INFO | Validation tp: 0, fn: 233, fp: 0, tn: 768
| 2021-07-13 14:59:24 | INFO | Validation loss: 0.504, acc: 0.767, F1: 0.434
| 2021-07-13 14:59:24 | INFO | Start epoch 3:
| 2021-07-13 14:59:24 | INFO | Train Loss: 0.571, tp: 0, fn: 16, fp: 1, tn: 47, Acc: 0.734, Prec: 0.000, Rec: 0.000, F1: 0.423
| 2021-07-13 15:00:36 | INFO | Validation tp: 52, fn: 181, fp: 38, tn: 730
| 2021-07-13 15:00:36 | INFO | Validation loss: 0.513, acc: 0.781, F1: 0.596
| 2021-07-13 15:00:36 | INFO | Start epoch 4:
| 2021-07-13 15:00:36 | INFO | Train Loss: 0.530, tp: 0, fn: 13, fp: 3, tn: 48, Acc: 0.750, Prec: 0.000, Rec: 0.000, F1: 0.429
| 2021-07-13 15:01:48 | INFO | Validation tp: 58, fn: 175, fp: 49, tn: 719
| 2021-07-13 15:01:48 | INFO | Validation loss: 0.494, acc: 0.776, F1: 0.603
| 2021-07-13 15:01:48 | INFO | Start epoch 5:
| 2021-07-13 15:01:48 | INFO | Train Loss: 0.344, tp: 7, fn: 3, fp: 4, tn: 50, Acc: 0.891, Prec: 0.636, Rec: 0.700, F1: 0.801
| 2021-07-13 15:03:00 | INFO | Validation tp: 82, fn: 151, fp: 107, tn: 661
| 2021-07-13 15:03:00 | INFO | Validation loss: 0.534, acc: 0.742, F1: 0.613
| 2021-07-13 15:03:00 | INFO | Start epoch 6:
| 2021-07-13 15:03:00 | INFO | Train Loss: 0.450, tp: 2, fn: 9, fp: 2, tn: 51, Acc: 0.828, Prec: 0.500, Rec: 0.182, F1: 0.585
| 2021-07-13 15:04:12 | INFO | Validation tp: 60, fn: 173, fp: 62, tn: 706
| 2021-07-13 15:04:12 | INFO | Validation loss: 0.536, acc: 0.765, F1: 0.598
| 2021-07-13 15:04:12 | INFO | Start epoch 7:
| 2021-07-13 15:04:12 | INFO | Train Loss: 0.301, tp: 9, fn: 5, fp: 1, tn: 49, Acc: 0.906, Prec: 0.900, Rec: 0.643, F1: 0.846
| 2021-07-13 15:05:24 | INFO | Validation tp: 83, fn: 150, fp: 139, tn: 629
| 2021-07-13 15:05:24 | INFO | Validation loss: 0.658, acc: 0.711, F1: 0.589
| 2021-07-13 15:05:24 | INFO | Start epoch 8:
| 2021-07-13 15:05:24 | INFO | Train Loss: 0.344, tp: 15, fn: 6, fp: 4, tn: 39, Acc: 0.844, Prec: 0.789, Rec: 0.714, F1: 0.818
| 2021-07-13 15:06:35 | INFO | Validation tp: 72, fn: 161, fp: 112, tn: 656
| 2021-07-13 15:06:35 | INFO | Validation loss: 0.716, acc: 0.727, F1: 0.587
| 2021-07-13 15:06:35 | INFO | Start epoch 9:
| 2021-07-13 15:06:36 | INFO | Train Loss: 0.198, tp: 14, fn: 2, fp: 1, tn: 47, Acc: 0.953, Prec: 0.933, Rec: 0.875, F1: 0.936
| 2021-07-13 15:07:47 | INFO | Validation tp: 80, fn: 153, fp: 126, tn: 642
| 2021-07-13 15:07:47 | INFO | Validation loss: 0.893, acc: 0.721, F1: 0.593
| 2021-07-13 15:07:47 | INFO | Start epoch 10:
| 2021-07-13 15:07:48 | INFO | Train Loss: 0.167, tp: 16, fn: 2, fp: 1, tn: 45, Acc: 0.953, Prec: 0.941, Rec: 0.889, F1: 0.941
| 2021-07-13 15:08:59 | INFO | Validation tp: 70, fn: 163, fp: 96, tn: 672
| 2021-07-13 15:08:59 | INFO | Validation loss: 0.916, acc: 0.741, F1: 0.595
| 2021-07-13 15:09:01 | INFO | 
==============================Start training==============================
| 2021-07-13 15:09:01 | INFO | Command Line Args:   --lr 4e-5 --warmup_ratio 0.2 -c config/enja_at_least_one.conf
Config File (config/enja_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/enja_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/enja_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 15:09:01 | INFO | 
lr: 4e-05

| 2021-07-13 15:09:13 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 15:09:13 | INFO | Start epoch 1:
| 2021-07-13 15:09:14 | INFO | Train Loss: 0.532, tp: 0, fn: 8, fp: 0, tn: 56, Acc: 0.875, Prec: 0.000, Rec: 0.000, F1: 0.467
| 2021-07-13 15:10:25 | INFO | Validation tp: 0, fn: 233, fp: 0, tn: 768
| 2021-07-13 15:10:25 | INFO | Validation loss: 0.527, acc: 0.767, F1: 0.434
| 2021-07-13 15:10:25 | INFO | Start epoch 2:
| 2021-07-13 15:10:25 | INFO | Train Loss: 0.626, tp: 0, fn: 18, fp: 0, tn: 46, Acc: 0.719, Prec: 0.000, Rec: 0.000, F1: 0.418
| 2021-07-13 15:11:37 | INFO | Validation tp: 25, fn: 208, fp: 15, tn: 753
| 2021-07-13 15:11:37 | INFO | Validation loss: 0.506, acc: 0.777, F1: 0.527
| 2021-07-13 15:11:37 | INFO | Start epoch 3:
| 2021-07-13 15:11:38 | INFO | Train Loss: 0.556, tp: 1, fn: 15, fp: 1, tn: 47, Acc: 0.750, Prec: 0.500, Rec: 0.062, F1: 0.483
| 2021-07-13 15:12:49 | INFO | Validation tp: 52, fn: 181, fp: 39, tn: 729
| 2021-07-13 15:12:49 | INFO | Validation loss: 0.494, acc: 0.780, F1: 0.595
| 2021-07-13 15:12:49 | INFO | Start epoch 4:
| 2021-07-13 15:12:49 | INFO | Train Loss: 0.512, tp: 0, fn: 13, fp: 4, tn: 47, Acc: 0.734, Prec: 0.000, Rec: 0.000, F1: 0.423
| 2021-07-13 15:14:01 | INFO | Validation tp: 78, fn: 155, fp: 86, tn: 682
| 2021-07-13 15:14:01 | INFO | Validation loss: 0.516, acc: 0.759, F1: 0.621
| 2021-07-13 15:14:01 | INFO | Start epoch 5:
| 2021-07-13 15:14:01 | INFO | Train Loss: 0.314, tp: 8, fn: 2, fp: 6, tn: 48, Acc: 0.875, Prec: 0.571, Rec: 0.800, F1: 0.795
| 2021-07-13 15:15:13 | INFO | Validation tp: 67, fn: 166, fp: 89, tn: 679
| 2021-07-13 15:15:13 | INFO | Validation loss: 0.536, acc: 0.745, F1: 0.593
| 2021-07-13 15:15:13 | INFO | Start epoch 6:
| 2021-07-13 15:15:14 | INFO | Train Loss: 0.362, tp: 1, fn: 10, fp: 1, tn: 52, Acc: 0.828, Prec: 0.500, Rec: 0.091, F1: 0.529
| 2021-07-13 15:16:25 | INFO | Validation tp: 73, fn: 160, fp: 97, tn: 671
| 2021-07-13 15:16:25 | INFO | Validation loss: 0.598, acc: 0.743, F1: 0.601
| 2021-07-13 15:16:25 | INFO | Start epoch 7:
| 2021-07-13 15:16:25 | INFO | Train Loss: 0.211, tp: 11, fn: 3, fp: 1, tn: 49, Acc: 0.938, Prec: 0.917, Rec: 0.786, F1: 0.903
| 2021-07-13 15:17:36 | INFO | Validation tp: 84, fn: 149, fp: 109, tn: 659
| 2021-07-13 15:17:36 | INFO | Validation loss: 0.778, acc: 0.742, F1: 0.615
| 2021-07-13 15:17:36 | INFO | Start epoch 8:
| 2021-07-13 15:17:37 | INFO | Train Loss: 0.127, tp: 20, fn: 1, fp: 1, tn: 42, Acc: 0.969, Prec: 0.952, Rec: 0.952, F1: 0.965
| 2021-07-13 15:18:48 | INFO | Validation tp: 53, fn: 180, fp: 77, tn: 691
| 2021-07-13 15:18:48 | INFO | Validation loss: 0.920, acc: 0.743, F1: 0.568
| 2021-07-13 15:18:48 | INFO | Start epoch 9:
| 2021-07-13 15:18:49 | INFO | Train Loss: 0.077, tp: 15, fn: 1, fp: 1, tn: 47, Acc: 0.969, Prec: 0.938, Rec: 0.938, F1: 0.958
| 2021-07-13 15:20:00 | INFO | Validation tp: 73, fn: 160, fp: 105, tn: 663
| 2021-07-13 15:20:00 | INFO | Validation loss: 1.093, acc: 0.735, F1: 0.594
| 2021-07-13 15:20:00 | INFO | Start epoch 10:
| 2021-07-13 15:20:01 | INFO | Train Loss: 0.037, tp: 17, fn: 1, fp: 0, tn: 46, Acc: 0.984, Prec: 1.000, Rec: 0.944, F1: 0.980
| 2021-07-13 15:21:12 | INFO | Validation tp: 71, fn: 162, fp: 108, tn: 660
| 2021-07-13 15:21:12 | INFO | Validation loss: 1.200, acc: 0.730, F1: 0.587
| 2021-07-13 15:21:14 | INFO | 
==============================Start training==============================
| 2021-07-13 15:21:14 | INFO | Command Line Args:   --lr 5e-5 --warmup_ratio 0.2 -c config/enja_at_least_one.conf
Config File (config/enja_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/enja_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/enja_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 15:21:14 | INFO | 
lr: 5e-05

| 2021-07-13 15:21:27 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 15:21:27 | INFO | Start epoch 1:
| 2021-07-13 15:21:28 | INFO | Train Loss: 0.532, tp: 0, fn: 8, fp: 0, tn: 56, Acc: 0.875, Prec: 0.000, Rec: 0.000, F1: 0.467
| 2021-07-13 15:22:38 | INFO | Validation tp: 0, fn: 233, fp: 0, tn: 768
| 2021-07-13 15:22:38 | INFO | Validation loss: 0.520, acc: 0.767, F1: 0.434
| 2021-07-13 15:22:38 | INFO | Start epoch 2:
| 2021-07-13 15:22:39 | INFO | Train Loss: 0.624, tp: 0, fn: 18, fp: 0, tn: 46, Acc: 0.719, Prec: 0.000, Rec: 0.000, F1: 0.418
| 2021-07-13 15:23:51 | INFO | Validation tp: 1, fn: 232, fp: 0, tn: 768
| 2021-07-13 15:23:51 | INFO | Validation loss: 0.500, acc: 0.768, F1: 0.439
| 2021-07-13 15:23:51 | INFO | Start epoch 3:
| 2021-07-13 15:23:51 | INFO | Train Loss: 0.559, tp: 0, fn: 16, fp: 1, tn: 47, Acc: 0.734, Prec: 0.000, Rec: 0.000, F1: 0.423
| 2021-07-13 15:25:02 | INFO | Validation tp: 42, fn: 191, fp: 27, tn: 741
| 2021-07-13 15:25:02 | INFO | Validation loss: 0.500, acc: 0.782, F1: 0.575
| 2021-07-13 15:25:02 | INFO | Start epoch 4:
| 2021-07-13 15:25:03 | INFO | Train Loss: 0.501, tp: 0, fn: 13, fp: 3, tn: 48, Acc: 0.750, Prec: 0.000, Rec: 0.000, F1: 0.429
| 2021-07-13 15:26:14 | INFO | Validation tp: 70, fn: 163, fp: 69, tn: 699
| 2021-07-13 15:26:14 | INFO | Validation loss: 0.518, acc: 0.768, F1: 0.617
| 2021-07-13 15:26:14 | INFO | Start epoch 5:
| 2021-07-13 15:26:15 | INFO | Train Loss: 0.257, tp: 7, fn: 3, fp: 4, tn: 50, Acc: 0.891, Prec: 0.636, Rec: 0.700, F1: 0.801
| 2021-07-13 15:27:26 | INFO | Validation tp: 56, fn: 177, fp: 61, tn: 707
| 2021-07-13 15:27:26 | INFO | Validation loss: 0.578, acc: 0.762, F1: 0.588
| 2021-07-13 15:27:26 | INFO | Start epoch 6:
| 2021-07-13 15:27:27 | INFO | Train Loss: 0.354, tp: 4, fn: 7, fp: 1, tn: 52, Acc: 0.875, Prec: 0.800, Rec: 0.364, F1: 0.714
| 2021-07-13 15:28:38 | INFO | Validation tp: 73, fn: 160, fp: 102, tn: 666
| 2021-07-13 15:28:38 | INFO | Validation loss: 0.619, acc: 0.738, F1: 0.597
| 2021-07-13 15:28:38 | INFO | Start epoch 7:
| 2021-07-13 15:28:39 | INFO | Train Loss: 0.177, tp: 10, fn: 4, fp: 1, tn: 49, Acc: 0.922, Prec: 0.909, Rec: 0.714, F1: 0.876
| 2021-07-13 15:29:50 | INFO | Validation tp: 81, fn: 152, fp: 110, tn: 658
| 2021-07-13 15:29:50 | INFO | Validation loss: 0.743, acc: 0.738, F1: 0.608
| 2021-07-13 15:29:50 | INFO | Start epoch 8:
| 2021-07-13 15:29:51 | INFO | Train Loss: 0.151, tp: 18, fn: 3, fp: 0, tn: 43, Acc: 0.953, Prec: 1.000, Rec: 0.857, F1: 0.945
| 2021-07-13 15:31:02 | INFO | Validation tp: 73, fn: 160, fp: 106, tn: 662
| 2021-07-13 15:31:02 | INFO | Validation loss: 0.900, acc: 0.734, F1: 0.594
| 2021-07-13 15:31:02 | INFO | Start epoch 9:
| 2021-07-13 15:31:02 | INFO | Train Loss: 0.130, tp: 16, fn: 0, fp: 2, tn: 46, Acc: 0.969, Prec: 0.889, Rec: 1.000, F1: 0.960
| 2021-07-13 15:32:13 | INFO | Validation tp: 75, fn: 158, fp: 99, tn: 669
| 2021-07-13 15:32:13 | INFO | Validation loss: 1.068, acc: 0.743, F1: 0.604
| 2021-07-13 15:32:13 | INFO | Start epoch 10:
| 2021-07-13 15:32:14 | INFO | Train Loss: 0.032, tp: 18, fn: 0, fp: 1, tn: 45, Acc: 0.984, Prec: 0.947, Rec: 1.000, F1: 0.981
| 2021-07-13 15:33:25 | INFO | Validation tp: 70, fn: 163, fp: 94, tn: 674
| 2021-07-13 15:33:25 | INFO | Validation loss: 1.106, acc: 0.743, F1: 0.596
| 2021-07-13 15:33:27 | INFO | 
==============================Start training==============================
| 2021-07-13 15:33:27 | INFO | Command Line Args:   --lr 2e-5 --warmup_ratio 0.3 -c config/enja_at_least_one.conf
Config File (config/enja_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/enja_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/enja_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 15:33:27 | INFO | 
lr: 2e-05

| 2021-07-13 15:33:40 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 15:33:40 | INFO | Start epoch 1:
| 2021-07-13 15:33:40 | INFO | Train Loss: 0.532, tp: 0, fn: 8, fp: 0, tn: 56, Acc: 0.875, Prec: 0.000, Rec: 0.000, F1: 0.467
| 2021-07-13 15:34:51 | INFO | Validation tp: 0, fn: 233, fp: 0, tn: 768
| 2021-07-13 15:34:51 | INFO | Validation loss: 0.546, acc: 0.767, F1: 0.434
| 2021-07-13 15:34:51 | INFO | Start epoch 2:
| 2021-07-13 15:34:52 | INFO | Train Loss: 0.602, tp: 0, fn: 18, fp: 0, tn: 46, Acc: 0.719, Prec: 0.000, Rec: 0.000, F1: 0.418
| 2021-07-13 15:36:03 | INFO | Validation tp: 9, fn: 224, fp: 4, tn: 764
| 2021-07-13 15:36:03 | INFO | Validation loss: 0.512, acc: 0.772, F1: 0.472
| 2021-07-13 15:36:03 | INFO | Start epoch 3:
| 2021-07-13 15:36:04 | INFO | Train Loss: 0.574, tp: 1, fn: 15, fp: 0, tn: 48, Acc: 0.766, Prec: 1.000, Rec: 0.062, F1: 0.491
| 2021-07-13 15:37:15 | INFO | Validation tp: 24, fn: 209, fp: 14, tn: 754
| 2021-07-13 15:37:15 | INFO | Validation loss: 0.517, acc: 0.777, F1: 0.524
| 2021-07-13 15:37:15 | INFO | Start epoch 4:
| 2021-07-13 15:37:15 | INFO | Train Loss: 0.514, tp: 0, fn: 13, fp: 1, tn: 50, Acc: 0.781, Prec: 0.000, Rec: 0.000, F1: 0.439
| 2021-07-13 15:38:27 | INFO | Validation tp: 74, fn: 159, fp: 72, tn: 696
| 2021-07-13 15:38:27 | INFO | Validation loss: 0.507, acc: 0.769, F1: 0.624
| 2021-07-13 15:38:27 | INFO | Start epoch 5:
| 2021-07-13 15:38:27 | INFO | Train Loss: 0.339, tp: 7, fn: 3, fp: 3, tn: 51, Acc: 0.906, Prec: 0.700, Rec: 0.700, F1: 0.822
| 2021-07-13 15:39:38 | INFO | Validation tp: 93, fn: 140, fp: 115, tn: 653
| 2021-07-13 15:39:38 | INFO | Validation loss: 0.533, acc: 0.745, F1: 0.629
| 2021-07-13 15:39:38 | INFO | Start epoch 6:
| 2021-07-13 15:39:39 | INFO | Train Loss: 0.483, tp: 1, fn: 10, fp: 3, tn: 50, Acc: 0.797, Prec: 0.250, Rec: 0.091, F1: 0.509
| 2021-07-13 15:40:50 | INFO | Validation tp: 36, fn: 197, fp: 23, tn: 745
| 2021-07-13 15:40:50 | INFO | Validation loss: 0.513, acc: 0.780, F1: 0.559
| 2021-07-13 15:40:50 | INFO | Start epoch 7:
| 2021-07-13 15:40:51 | INFO | Train Loss: 0.417, tp: 2, fn: 12, fp: 0, tn: 50, Acc: 0.812, Prec: 1.000, Rec: 0.143, F1: 0.571
| 2021-07-13 15:42:02 | INFO | Validation tp: 76, fn: 157, fp: 100, tn: 668
| 2021-07-13 15:42:02 | INFO | Validation loss: 0.593, acc: 0.743, F1: 0.605
| 2021-07-13 15:42:02 | INFO | Start epoch 8:
| 2021-07-13 15:42:03 | INFO | Train Loss: 0.345, tp: 16, fn: 5, fp: 3, tn: 40, Acc: 0.875, Prec: 0.842, Rec: 0.762, F1: 0.855
| 2021-07-13 15:43:14 | INFO | Validation tp: 64, fn: 169, fp: 72, tn: 696
| 2021-07-13 15:43:14 | INFO | Validation loss: 0.632, acc: 0.759, F1: 0.600
| 2021-07-13 15:43:14 | INFO | Start epoch 9:
| 2021-07-13 15:43:15 | INFO | Train Loss: 0.442, tp: 9, fn: 7, fp: 1, tn: 47, Acc: 0.875, Prec: 0.900, Rec: 0.562, F1: 0.807
| 2021-07-13 15:44:26 | INFO | Validation tp: 73, fn: 160, fp: 104, tn: 664
| 2021-07-13 15:44:26 | INFO | Validation loss: 0.724, acc: 0.736, F1: 0.595
| 2021-07-13 15:44:26 | INFO | Start epoch 10:
| 2021-07-13 15:44:27 | INFO | Train Loss: 0.289, tp: 13, fn: 5, fp: 1, tn: 45, Acc: 0.906, Prec: 0.929, Rec: 0.722, F1: 0.875
| 2021-07-13 15:45:38 | INFO | Validation tp: 75, fn: 158, fp: 101, tn: 667
| 2021-07-13 15:45:38 | INFO | Validation loss: 0.772, acc: 0.741, F1: 0.602
| 2021-07-13 15:45:41 | INFO | 
==============================Start training==============================
| 2021-07-13 15:45:41 | INFO | Command Line Args:   --lr 3e-5 --warmup_ratio 0.3 -c config/enja_at_least_one.conf
Config File (config/enja_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/enja_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/enja_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 15:45:41 | INFO | 
lr: 3e-05

| 2021-07-13 15:45:53 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 15:45:53 | INFO | Start epoch 1:
| 2021-07-13 15:45:53 | INFO | Train Loss: 0.532, tp: 0, fn: 8, fp: 0, tn: 56, Acc: 0.875, Prec: 0.000, Rec: 0.000, F1: 0.467
| 2021-07-13 15:47:05 | INFO | Validation tp: 0, fn: 233, fp: 0, tn: 768
| 2021-07-13 15:47:05 | INFO | Validation loss: 0.523, acc: 0.767, F1: 0.434
| 2021-07-13 15:47:05 | INFO | Start epoch 2:
| 2021-07-13 15:47:05 | INFO | Train Loss: 0.631, tp: 0, fn: 18, fp: 0, tn: 46, Acc: 0.719, Prec: 0.000, Rec: 0.000, F1: 0.418
| 2021-07-13 15:48:17 | INFO | Validation tp: 0, fn: 233, fp: 0, tn: 768
| 2021-07-13 15:48:17 | INFO | Validation loss: 0.515, acc: 0.767, F1: 0.434
| 2021-07-13 15:48:17 | INFO | Start epoch 3:
| 2021-07-13 15:48:17 | INFO | Train Loss: 0.581, tp: 0, fn: 16, fp: 0, tn: 48, Acc: 0.750, Prec: 0.000, Rec: 0.000, F1: 0.429
| 2021-07-13 15:49:29 | INFO | Validation tp: 70, fn: 163, fp: 49, tn: 719
| 2021-07-13 15:49:29 | INFO | Validation loss: 0.499, acc: 0.788, F1: 0.635
| 2021-07-13 15:49:29 | INFO | Start epoch 4:
| 2021-07-13 15:49:29 | INFO | Train Loss: 0.539, tp: 0, fn: 13, fp: 3, tn: 48, Acc: 0.750, Prec: 0.000, Rec: 0.000, F1: 0.429
| 2021-07-13 15:50:40 | INFO | Validation tp: 61, fn: 172, fp: 54, tn: 714
| 2021-07-13 15:50:40 | INFO | Validation loss: 0.496, acc: 0.774, F1: 0.607
| 2021-07-13 15:50:40 | INFO | Start epoch 5:
| 2021-07-13 15:50:41 | INFO | Train Loss: 0.323, tp: 7, fn: 3, fp: 3, tn: 51, Acc: 0.906, Prec: 0.700, Rec: 0.700, F1: 0.822
| 2021-07-13 15:51:52 | INFO | Validation tp: 84, fn: 149, fp: 97, tn: 671
| 2021-07-13 15:51:52 | INFO | Validation loss: 0.521, acc: 0.754, F1: 0.625
| 2021-07-13 15:51:52 | INFO | Start epoch 6:
| 2021-07-13 15:51:53 | INFO | Train Loss: 0.466, tp: 3, fn: 8, fp: 1, tn: 52, Acc: 0.859, Prec: 0.750, Rec: 0.273, F1: 0.660
| 2021-07-13 15:53:04 | INFO | Validation tp: 54, fn: 179, fp: 60, tn: 708
| 2021-07-13 15:53:04 | INFO | Validation loss: 0.548, acc: 0.761, F1: 0.583
| 2021-07-13 15:53:04 | INFO | Start epoch 7:
| 2021-07-13 15:53:05 | INFO | Train Loss: 0.290, tp: 11, fn: 3, fp: 0, tn: 50, Acc: 0.953, Prec: 1.000, Rec: 0.786, F1: 0.925
| 2021-07-13 15:54:16 | INFO | Validation tp: 59, fn: 174, fp: 74, tn: 694
| 2021-07-13 15:54:16 | INFO | Validation loss: 0.683, acc: 0.752, F1: 0.585
| 2021-07-13 15:54:16 | INFO | Start epoch 8:
| 2021-07-13 15:54:17 | INFO | Train Loss: 0.224, tp: 18, fn: 3, fp: 1, tn: 42, Acc: 0.938, Prec: 0.947, Rec: 0.857, F1: 0.927
| 2021-07-13 15:55:28 | INFO | Validation tp: 83, fn: 150, fp: 105, tn: 663
| 2021-07-13 15:55:28 | INFO | Validation loss: 0.747, acc: 0.745, F1: 0.617
| 2021-07-13 15:55:28 | INFO | Start epoch 9:
| 2021-07-13 15:55:28 | INFO | Train Loss: 0.168, tp: 14, fn: 2, fp: 1, tn: 47, Acc: 0.953, Prec: 0.933, Rec: 0.875, F1: 0.936
| 2021-07-13 15:56:40 | INFO | Validation tp: 72, fn: 161, fp: 95, tn: 673
| 2021-07-13 15:56:40 | INFO | Validation loss: 0.970, acc: 0.744, F1: 0.600
| 2021-07-13 15:56:40 | INFO | Start epoch 10:
| 2021-07-13 15:56:40 | INFO | Train Loss: 0.062, tp: 17, fn: 1, fp: 0, tn: 46, Acc: 0.984, Prec: 1.000, Rec: 0.944, F1: 0.980
| 2021-07-13 15:57:51 | INFO | Validation tp: 61, fn: 172, fp: 73, tn: 695
| 2021-07-13 15:57:51 | INFO | Validation loss: 1.015, acc: 0.755, F1: 0.591
| 2021-07-13 15:57:54 | INFO | 
==============================Start training==============================
| 2021-07-13 15:57:54 | INFO | Command Line Args:   --lr 4e-5 --warmup_ratio 0.3 -c config/enja_at_least_one.conf
Config File (config/enja_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/enja_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/enja_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 15:57:54 | INFO | 
lr: 4e-05

| 2021-07-13 15:58:06 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 15:58:06 | INFO | Start epoch 1:
| 2021-07-13 15:58:07 | INFO | Train Loss: 0.532, tp: 0, fn: 8, fp: 0, tn: 56, Acc: 0.875, Prec: 0.000, Rec: 0.000, F1: 0.467
| 2021-07-13 15:59:18 | INFO | Validation tp: 0, fn: 233, fp: 0, tn: 768
| 2021-07-13 15:59:18 | INFO | Validation loss: 0.518, acc: 0.767, F1: 0.434
| 2021-07-13 15:59:18 | INFO | Start epoch 2:
| 2021-07-13 15:59:18 | INFO | Train Loss: 0.642, tp: 0, fn: 18, fp: 0, tn: 46, Acc: 0.719, Prec: 0.000, Rec: 0.000, F1: 0.418
| 2021-07-13 16:00:29 | INFO | Validation tp: 0, fn: 233, fp: 0, tn: 768
| 2021-07-13 16:00:29 | INFO | Validation loss: 0.508, acc: 0.767, F1: 0.434
| 2021-07-13 16:00:29 | INFO | Start epoch 3:
| 2021-07-13 16:00:30 | INFO | Train Loss: 0.583, tp: 0, fn: 16, fp: 0, tn: 48, Acc: 0.750, Prec: 0.000, Rec: 0.000, F1: 0.429
| 2021-07-13 16:01:41 | INFO | Validation tp: 28, fn: 205, fp: 13, tn: 755
| 2021-07-13 16:01:41 | INFO | Validation loss: 0.494, acc: 0.782, F1: 0.539
| 2021-07-13 16:01:41 | INFO | Start epoch 4:
| 2021-07-13 16:01:42 | INFO | Train Loss: 0.499, tp: 0, fn: 13, fp: 1, tn: 50, Acc: 0.781, Prec: 0.000, Rec: 0.000, F1: 0.439
| 2021-07-13 16:02:53 | INFO | Validation tp: 0, fn: 233, fp: 0, tn: 768
| 2021-07-13 16:02:53 | INFO | Validation loss: 0.544, acc: 0.767, F1: 0.434
| 2021-07-13 16:02:53 | INFO | Start epoch 5:
| 2021-07-13 16:02:54 | INFO | Train Loss: 0.449, tp: 0, fn: 10, fp: 0, tn: 54, Acc: 0.844, Prec: 0.000, Rec: 0.000, F1: 0.458
| 2021-07-13 16:04:05 | INFO | Validation tp: 0, fn: 233, fp: 0, tn: 768
| 2021-07-13 16:04:05 | INFO | Validation loss: 0.543, acc: 0.767, F1: 0.434
| 2021-07-13 16:04:05 | INFO | Start epoch 6:
| 2021-07-13 16:04:06 | INFO | Train Loss: 0.481, tp: 0, fn: 11, fp: 0, tn: 53, Acc: 0.828, Prec: 0.000, Rec: 0.000, F1: 0.453
| 2021-07-13 16:05:17 | INFO | Validation tp: 0, fn: 233, fp: 0, tn: 768
| 2021-07-13 16:05:17 | INFO | Validation loss: 0.543, acc: 0.767, F1: 0.434
| 2021-07-13 16:05:17 | INFO | Start epoch 7:
| 2021-07-13 16:05:18 | INFO | Train Loss: 0.540, tp: 0, fn: 14, fp: 0, tn: 50, Acc: 0.781, Prec: 0.000, Rec: 0.000, F1: 0.439
| 2021-07-13 16:06:29 | INFO | Validation tp: 0, fn: 233, fp: 0, tn: 768
| 2021-07-13 16:06:29 | INFO | Validation loss: 0.543, acc: 0.767, F1: 0.434
| 2021-07-13 16:06:29 | INFO | Start epoch 8:
| 2021-07-13 16:06:29 | INFO | Train Loss: 0.665, tp: 0, fn: 21, fp: 0, tn: 43, Acc: 0.672, Prec: 0.000, Rec: 0.000, F1: 0.402
| 2021-07-13 16:07:40 | INFO | Validation tp: 0, fn: 233, fp: 0, tn: 768
| 2021-07-13 16:07:40 | INFO | Validation loss: 0.543, acc: 0.767, F1: 0.434
| 2021-07-13 16:07:40 | INFO | Start epoch 9:
| 2021-07-13 16:07:41 | INFO | Train Loss: 0.559, tp: 0, fn: 16, fp: 0, tn: 48, Acc: 0.750, Prec: 0.000, Rec: 0.000, F1: 0.429
| 2021-07-13 16:08:52 | INFO | Validation tp: 0, fn: 233, fp: 0, tn: 768
| 2021-07-13 16:08:52 | INFO | Validation loss: 0.543, acc: 0.767, F1: 0.434
| 2021-07-13 16:08:52 | INFO | Start epoch 10:
| 2021-07-13 16:08:53 | INFO | Train Loss: 0.601, tp: 0, fn: 18, fp: 0, tn: 46, Acc: 0.719, Prec: 0.000, Rec: 0.000, F1: 0.418
| 2021-07-13 16:10:04 | INFO | Validation tp: 0, fn: 233, fp: 0, tn: 768
| 2021-07-13 16:10:04 | INFO | Validation loss: 0.543, acc: 0.767, F1: 0.434
| 2021-07-13 16:10:07 | INFO | 
==============================Start training==============================
| 2021-07-13 16:10:07 | INFO | Command Line Args:   --lr 5e-5 --warmup_ratio 0.3 -c config/enja_at_least_one.conf
Config File (config/enja_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/enja_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/enja_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 16:10:07 | INFO | 
lr: 5e-05

| 2021-07-13 16:10:19 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 16:10:19 | INFO | Start epoch 1:
| 2021-07-13 16:10:20 | INFO | Train Loss: 0.532, tp: 0, fn: 8, fp: 0, tn: 56, Acc: 0.875, Prec: 0.000, Rec: 0.000, F1: 0.467
| 2021-07-13 16:11:31 | INFO | Validation tp: 0, fn: 233, fp: 0, tn: 768
| 2021-07-13 16:11:31 | INFO | Validation loss: 0.541, acc: 0.767, F1: 0.434
| 2021-07-13 16:11:31 | INFO | Start epoch 2:
| 2021-07-13 16:11:32 | INFO | Train Loss: 0.607, tp: 0, fn: 18, fp: 0, tn: 46, Acc: 0.719, Prec: 0.000, Rec: 0.000, F1: 0.418
| 2021-07-13 16:12:43 | INFO | Validation tp: 22, fn: 211, fp: 25, tn: 743
| 2021-07-13 16:12:43 | INFO | Validation loss: 0.520, acc: 0.764, F1: 0.510
| 2021-07-13 16:12:43 | INFO | Start epoch 3:
| 2021-07-13 16:12:43 | INFO | Train Loss: 0.551, tp: 2, fn: 14, fp: 1, tn: 47, Acc: 0.766, Prec: 0.667, Rec: 0.125, F1: 0.536
| 2021-07-13 16:13:55 | INFO | Validation tp: 58, fn: 175, fp: 51, tn: 717
| 2021-07-13 16:13:55 | INFO | Validation loss: 0.513, acc: 0.774, F1: 0.602
| 2021-07-13 16:13:55 | INFO | Start epoch 4:
| 2021-07-13 16:13:55 | INFO | Train Loss: 0.527, tp: 2, fn: 11, fp: 2, tn: 49, Acc: 0.797, Prec: 0.500, Rec: 0.154, F1: 0.559
| 2021-07-13 16:15:07 | INFO | Validation tp: 84, fn: 149, fp: 87, tn: 681
| 2021-07-13 16:15:07 | INFO | Validation loss: 0.549, acc: 0.764, F1: 0.634
| 2021-07-13 16:15:07 | INFO | Start epoch 5:
| 2021-07-13 16:15:07 | INFO | Train Loss: 0.328, tp: 8, fn: 2, fp: 6, tn: 48, Acc: 0.875, Prec: 0.571, Rec: 0.800, F1: 0.795
| 2021-07-13 16:16:18 | INFO | Validation tp: 88, fn: 145, fp: 128, tn: 640
| 2021-07-13 16:16:18 | INFO | Validation loss: 0.527, acc: 0.727, F1: 0.608
| 2021-07-13 16:16:18 | INFO | Start epoch 6:
| 2021-07-13 16:16:19 | INFO | Train Loss: 0.404, tp: 3, fn: 8, fp: 3, tn: 50, Acc: 0.828, Prec: 0.500, Rec: 0.273, F1: 0.627
| 2021-07-13 16:17:30 | INFO | Validation tp: 58, fn: 175, fp: 62, tn: 706
| 2021-07-13 16:17:30 | INFO | Validation loss: 0.537, acc: 0.763, F1: 0.592
| 2021-07-13 16:17:30 | INFO | Start epoch 7:
| 2021-07-13 16:17:31 | INFO | Train Loss: 0.338, tp: 7, fn: 7, fp: 3, tn: 47, Acc: 0.844, Prec: 0.700, Rec: 0.500, F1: 0.744
| 2021-07-13 16:18:42 | INFO | Validation tp: 73, fn: 160, fp: 131, tn: 637
| 2021-07-13 16:18:42 | INFO | Validation loss: 0.725, acc: 0.709, F1: 0.574
| 2021-07-13 16:18:42 | INFO | Start epoch 8:
| 2021-07-13 16:18:43 | INFO | Train Loss: 0.248, tp: 18, fn: 3, fp: 0, tn: 43, Acc: 0.953, Prec: 1.000, Rec: 0.857, F1: 0.945
| 2021-07-13 16:19:54 | INFO | Validation tp: 91, fn: 142, fp: 168, tn: 600
| 2021-07-13 16:19:54 | INFO | Validation loss: 0.837, acc: 0.690, F1: 0.582
| 2021-07-13 16:19:54 | INFO | Start epoch 9:
| 2021-07-13 16:19:55 | INFO | Train Loss: 0.233, tp: 12, fn: 4, fp: 2, tn: 46, Acc: 0.906, Prec: 0.857, Rec: 0.750, F1: 0.869
| 2021-07-13 16:21:06 | INFO | Validation tp: 88, fn: 145, fp: 151, tn: 617
| 2021-07-13 16:21:06 | INFO | Validation loss: 0.996, acc: 0.704, F1: 0.590
| 2021-07-13 16:21:06 | INFO | Start epoch 10:
| 2021-07-13 16:21:07 | INFO | Train Loss: 0.186, tp: 16, fn: 2, fp: 2, tn: 44, Acc: 0.938, Prec: 0.889, Rec: 0.889, F1: 0.923
| 2021-07-13 16:22:18 | INFO | Validation tp: 73, fn: 160, fp: 122, tn: 646
| 2021-07-13 16:22:18 | INFO | Validation loss: 1.057, acc: 0.718, F1: 0.581
| 2021-07-13 16:22:20 | INFO | 
==============================Start training==============================
| 2021-07-13 16:22:20 | INFO | Command Line Args:   --lr 2e-5 --warmup_ratio 0.2 -c config/encs_at_least_one.conf
Config File (config/encs_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/encs_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/encs_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 16:22:20 | INFO | 
lr: 2e-05

| 2021-07-13 16:22:32 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 16:22:32 | INFO | Start epoch 1:
| 2021-07-13 16:22:33 | INFO | Train Loss: 0.656, tp: 0, fn: 21, fp: 0, tn: 43, Acc: 0.672, Prec: 0.000, Rec: 0.000, F1: 0.402
| 2021-07-13 16:23:41 | INFO | Validation tp: 5, fn: 317, fp: 11, tn: 668
| 2021-07-13 16:23:41 | INFO | Validation loss: 0.616, acc: 0.672, F1: 0.416
| 2021-07-13 16:23:41 | INFO | Start epoch 2:
| 2021-07-13 16:23:42 | INFO | Train Loss: 0.671, tp: 1, fn: 21, fp: 4, tn: 38, Acc: 0.609, Prec: 0.200, Rec: 0.045, F1: 0.413
| 2021-07-13 16:24:51 | INFO | Validation tp: 135, fn: 187, fp: 84, tn: 595
| 2021-07-13 16:24:51 | INFO | Validation loss: 0.551, acc: 0.729, F1: 0.657
| 2021-07-13 16:24:51 | INFO | Start epoch 3:
| 2021-07-13 16:24:52 | INFO | Train Loss: 0.553, tp: 8, fn: 11, fp: 6, tn: 39, Acc: 0.734, Prec: 0.571, Rec: 0.421, F1: 0.653
| 2021-07-13 16:26:00 | INFO | Validation tp: 112, fn: 210, fp: 42, tn: 637
| 2021-07-13 16:26:00 | INFO | Validation loss: 0.546, acc: 0.748, F1: 0.653
| 2021-07-13 16:26:00 | INFO | Start epoch 4:
| 2021-07-13 16:26:01 | INFO | Train Loss: 0.547, tp: 8, fn: 12, fp: 2, tn: 42, Acc: 0.781, Prec: 0.800, Rec: 0.400, F1: 0.695
| 2021-07-13 16:27:10 | INFO | Validation tp: 113, fn: 209, fp: 47, tn: 632
| 2021-07-13 16:27:10 | INFO | Validation loss: 0.585, acc: 0.744, F1: 0.650
| 2021-07-13 16:27:10 | INFO | Start epoch 5:
| 2021-07-13 16:27:11 | INFO | Train Loss: 0.454, tp: 13, fn: 12, fp: 3, tn: 36, Acc: 0.766, Prec: 0.812, Rec: 0.520, F1: 0.731
| 2021-07-13 16:28:20 | INFO | Validation tp: 110, fn: 212, fp: 41, tn: 638
| 2021-07-13 16:28:20 | INFO | Validation loss: 0.681, acc: 0.747, F1: 0.650
| 2021-07-13 16:28:20 | INFO | Start epoch 6:
| 2021-07-13 16:28:20 | INFO | Train Loss: 0.321, tp: 10, fn: 5, fp: 2, tn: 47, Acc: 0.891, Prec: 0.833, Rec: 0.667, F1: 0.836
| 2021-07-13 16:29:30 | INFO | Validation tp: 151, fn: 171, fp: 90, tn: 589
| 2021-07-13 16:29:30 | INFO | Validation loss: 0.712, acc: 0.739, F1: 0.678
| 2021-07-13 16:29:30 | INFO | Start epoch 7:
| 2021-07-13 16:29:31 | INFO | Train Loss: 0.175, tp: 20, fn: 2, fp: 1, tn: 41, Acc: 0.953, Prec: 0.952, Rec: 0.909, F1: 0.947
| 2021-07-13 16:30:39 | INFO | Validation tp: 126, fn: 196, fp: 76, tn: 603
| 2021-07-13 16:30:39 | INFO | Validation loss: 0.784, acc: 0.728, F1: 0.648
| 2021-07-13 16:30:39 | INFO | Start epoch 8:
| 2021-07-13 16:30:40 | INFO | Train Loss: 0.106, tp: 15, fn: 0, fp: 2, tn: 47, Acc: 0.969, Prec: 0.882, Rec: 1.000, F1: 0.958
| 2021-07-13 16:31:49 | INFO | Validation tp: 153, fn: 169, fp: 92, tn: 587
| 2021-07-13 16:31:49 | INFO | Validation loss: 0.953, acc: 0.739, F1: 0.679
| 2021-07-13 16:31:49 | INFO | Start epoch 9:
| 2021-07-13 16:31:50 | INFO | Train Loss: 0.179, tp: 17, fn: 2, fp: 3, tn: 42, Acc: 0.922, Prec: 0.850, Rec: 0.895, F1: 0.908
| 2021-07-13 16:33:00 | INFO | Validation tp: 139, fn: 183, fp: 84, tn: 595
| 2021-07-13 16:33:00 | INFO | Validation loss: 1.024, acc: 0.733, F1: 0.663
| 2021-07-13 16:33:00 | INFO | Start epoch 10:
| 2021-07-13 16:33:00 | INFO | Train Loss: 0.196, tp: 21, fn: 2, fp: 1, tn: 40, Acc: 0.953, Prec: 0.955, Rec: 0.913, F1: 0.949
| 2021-07-13 16:34:10 | INFO | Validation tp: 143, fn: 179, fp: 89, tn: 590
| 2021-07-13 16:34:10 | INFO | Validation loss: 1.031, acc: 0.732, F1: 0.666
| 2021-07-13 16:34:13 | INFO | 
==============================Start training==============================
| 2021-07-13 16:34:13 | INFO | Command Line Args:   --lr 3e-5 --warmup_ratio 0.2 -c config/encs_at_least_one.conf
Config File (config/encs_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/encs_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/encs_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 16:34:13 | INFO | 
lr: 3e-05

| 2021-07-13 16:34:25 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 16:34:25 | INFO | Start epoch 1:
| 2021-07-13 16:34:26 | INFO | Train Loss: 0.656, tp: 0, fn: 21, fp: 0, tn: 43, Acc: 0.672, Prec: 0.000, Rec: 0.000, F1: 0.402
| 2021-07-13 16:35:35 | INFO | Validation tp: 0, fn: 322, fp: 0, tn: 679
| 2021-07-13 16:35:35 | INFO | Validation loss: 0.617, acc: 0.678, F1: 0.404
| 2021-07-13 16:35:35 | INFO | Start epoch 2:
| 2021-07-13 16:35:35 | INFO | Train Loss: 0.637, tp: 0, fn: 22, fp: 1, tn: 41, Acc: 0.641, Prec: 0.000, Rec: 0.000, F1: 0.390
| 2021-07-13 16:36:45 | INFO | Validation tp: 117, fn: 205, fp: 61, tn: 618
| 2021-07-13 16:36:45 | INFO | Validation loss: 0.554, acc: 0.734, F1: 0.645
| 2021-07-13 16:36:45 | INFO | Start epoch 3:
| 2021-07-13 16:36:46 | INFO | Train Loss: 0.560, tp: 10, fn: 9, fp: 6, tn: 39, Acc: 0.766, Prec: 0.625, Rec: 0.526, F1: 0.705
| 2021-07-13 16:37:55 | INFO | Validation tp: 176, fn: 146, fp: 126, tn: 553
| 2021-07-13 16:37:55 | INFO | Validation loss: 0.553, acc: 0.728, F1: 0.683
| 2021-07-13 16:37:55 | INFO | Start epoch 4:
| 2021-07-13 16:37:56 | INFO | Train Loss: 0.530, tp: 16, fn: 4, fp: 10, tn: 34, Acc: 0.781, Prec: 0.615, Rec: 0.800, F1: 0.762
| 2021-07-13 16:39:06 | INFO | Validation tp: 113, fn: 209, fp: 49, tn: 630
| 2021-07-13 16:39:06 | INFO | Validation loss: 0.617, acc: 0.742, F1: 0.648
| 2021-07-13 16:39:06 | INFO | Start epoch 5:
| 2021-07-13 16:39:06 | INFO | Train Loss: 0.432, tp: 14, fn: 11, fp: 3, tn: 36, Acc: 0.781, Prec: 0.824, Rec: 0.560, F1: 0.752
| 2021-07-13 16:40:16 | INFO | Validation tp: 116, fn: 206, fp: 63, tn: 616
| 2021-07-13 16:40:16 | INFO | Validation loss: 0.698, acc: 0.731, F1: 0.642
| 2021-07-13 16:40:16 | INFO | Start epoch 6:
| 2021-07-13 16:40:16 | INFO | Train Loss: 0.225, tp: 10, fn: 5, fp: 1, tn: 48, Acc: 0.906, Prec: 0.909, Rec: 0.667, F1: 0.855
| 2021-07-13 16:41:26 | INFO | Validation tp: 150, fn: 172, fp: 99, tn: 580
| 2021-07-13 16:41:26 | INFO | Validation loss: 0.702, acc: 0.729, F1: 0.668
| 2021-07-13 16:41:26 | INFO | Start epoch 7:
| 2021-07-13 16:41:27 | INFO | Train Loss: 0.197, tp: 19, fn: 3, fp: 2, tn: 40, Acc: 0.922, Prec: 0.905, Rec: 0.864, F1: 0.912
| 2021-07-13 16:42:36 | INFO | Validation tp: 118, fn: 204, fp: 78, tn: 601
| 2021-07-13 16:42:36 | INFO | Validation loss: 0.991, acc: 0.718, F1: 0.633
| 2021-07-13 16:42:36 | INFO | Start epoch 8:
| 2021-07-13 16:42:37 | INFO | Train Loss: 0.036, tp: 15, fn: 0, fp: 0, tn: 49, Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000
| 2021-07-13 16:43:47 | INFO | Validation tp: 132, fn: 190, fp: 94, tn: 585
| 2021-07-13 16:43:47 | INFO | Validation loss: 1.063, acc: 0.716, F1: 0.643
| 2021-07-13 16:43:47 | INFO | Start epoch 9:
| 2021-07-13 16:43:48 | INFO | Train Loss: 0.054, tp: 18, fn: 1, fp: 0, tn: 45, Acc: 0.984, Prec: 1.000, Rec: 0.947, F1: 0.981
| 2021-07-13 16:44:57 | INFO | Validation tp: 145, fn: 177, fp: 100, tn: 579
| 2021-07-13 16:44:57 | INFO | Validation loss: 1.186, acc: 0.723, F1: 0.659
| 2021-07-13 16:44:57 | INFO | Start epoch 10:
| 2021-07-13 16:44:58 | INFO | Train Loss: 0.117, tp: 22, fn: 1, fp: 1, tn: 40, Acc: 0.969, Prec: 0.957, Rec: 0.957, F1: 0.966
| 2021-07-13 16:46:08 | INFO | Validation tp: 140, fn: 182, fp: 96, tn: 583
| 2021-07-13 16:46:08 | INFO | Validation loss: 1.226, acc: 0.722, F1: 0.655
| 2021-07-13 16:46:10 | INFO | 
==============================Start training==============================
| 2021-07-13 16:46:10 | INFO | Command Line Args:   --lr 4e-5 --warmup_ratio 0.2 -c config/encs_at_least_one.conf
Config File (config/encs_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/encs_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/encs_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 16:46:10 | INFO | 
lr: 4e-05

| 2021-07-13 16:46:21 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 16:46:21 | INFO | Start epoch 1:
| 2021-07-13 16:46:22 | INFO | Train Loss: 0.656, tp: 0, fn: 21, fp: 0, tn: 43, Acc: 0.672, Prec: 0.000, Rec: 0.000, F1: 0.402
| 2021-07-13 16:47:31 | INFO | Validation tp: 0, fn: 322, fp: 0, tn: 679
| 2021-07-13 16:47:31 | INFO | Validation loss: 0.586, acc: 0.678, F1: 0.404
| 2021-07-13 16:47:31 | INFO | Start epoch 2:
| 2021-07-13 16:47:32 | INFO | Train Loss: 0.624, tp: 0, fn: 22, fp: 0, tn: 42, Acc: 0.656, Prec: 0.000, Rec: 0.000, F1: 0.396
| 2021-07-13 16:48:42 | INFO | Validation tp: 82, fn: 240, fp: 27, tn: 652
| 2021-07-13 16:48:42 | INFO | Validation loss: 0.588, acc: 0.733, F1: 0.605
| 2021-07-13 16:48:42 | INFO | Start epoch 3:
| 2021-07-13 16:48:42 | INFO | Train Loss: 0.589, tp: 4, fn: 15, fp: 6, tn: 39, Acc: 0.672, Prec: 0.400, Rec: 0.211, F1: 0.532
| 2021-07-13 16:49:52 | INFO | Validation tp: 0, fn: 322, fp: 0, tn: 679
| 2021-07-13 16:49:52 | INFO | Validation loss: 0.628, acc: 0.678, F1: 0.404
| 2021-07-13 16:49:52 | INFO | Start epoch 4:
| 2021-07-13 16:49:52 | INFO | Train Loss: 0.617, tp: 0, fn: 20, fp: 0, tn: 44, Acc: 0.688, Prec: 0.000, Rec: 0.000, F1: 0.407
| 2021-07-13 16:51:01 | INFO | Validation tp: 0, fn: 322, fp: 0, tn: 679
| 2021-07-13 16:51:01 | INFO | Validation loss: 0.627, acc: 0.678, F1: 0.404
| 2021-07-13 16:51:01 | INFO | Start epoch 5:
| 2021-07-13 16:51:02 | INFO | Train Loss: 0.694, tp: 0, fn: 25, fp: 0, tn: 39, Acc: 0.609, Prec: 0.000, Rec: 0.000, F1: 0.379
| 2021-07-13 16:52:11 | INFO | Validation tp: 0, fn: 322, fp: 0, tn: 679
| 2021-07-13 16:52:11 | INFO | Validation loss: 0.627, acc: 0.678, F1: 0.404
| 2021-07-13 16:52:11 | INFO | Start epoch 6:
| 2021-07-13 16:52:12 | INFO | Train Loss: 0.568, tp: 0, fn: 15, fp: 0, tn: 49, Acc: 0.766, Prec: 0.000, Rec: 0.000, F1: 0.434
| 2021-07-13 16:53:22 | INFO | Validation tp: 0, fn: 322, fp: 0, tn: 679
| 2021-07-13 16:53:22 | INFO | Validation loss: 0.627, acc: 0.678, F1: 0.404
| 2021-07-13 16:53:22 | INFO | Start epoch 7:
| 2021-07-13 16:53:23 | INFO | Train Loss: 0.658, tp: 0, fn: 22, fp: 0, tn: 42, Acc: 0.656, Prec: 0.000, Rec: 0.000, F1: 0.396
| 2021-07-13 16:54:33 | INFO | Validation tp: 0, fn: 322, fp: 0, tn: 679
| 2021-07-13 16:54:33 | INFO | Validation loss: 0.628, acc: 0.678, F1: 0.404
| 2021-07-13 16:54:33 | INFO | Start epoch 8:
| 2021-07-13 16:54:34 | INFO | Train Loss: 0.571, tp: 0, fn: 15, fp: 0, tn: 49, Acc: 0.766, Prec: 0.000, Rec: 0.000, F1: 0.434
| 2021-07-13 16:55:44 | INFO | Validation tp: 0, fn: 322, fp: 0, tn: 679
| 2021-07-13 16:55:44 | INFO | Validation loss: 0.628, acc: 0.678, F1: 0.404
| 2021-07-13 16:55:44 | INFO | Start epoch 9:
| 2021-07-13 16:55:45 | INFO | Train Loss: 0.604, tp: 0, fn: 19, fp: 0, tn: 45, Acc: 0.703, Prec: 0.000, Rec: 0.000, F1: 0.413
| 2021-07-13 16:56:55 | INFO | Validation tp: 0, fn: 322, fp: 0, tn: 679
| 2021-07-13 16:56:55 | INFO | Validation loss: 0.627, acc: 0.678, F1: 0.404
| 2021-07-13 16:56:55 | INFO | Start epoch 10:
| 2021-07-13 16:56:56 | INFO | Train Loss: 0.649, tp: 0, fn: 23, fp: 0, tn: 41, Acc: 0.641, Prec: 0.000, Rec: 0.000, F1: 0.390
| 2021-07-13 16:58:06 | INFO | Validation tp: 0, fn: 322, fp: 0, tn: 679
| 2021-07-13 16:58:06 | INFO | Validation loss: 0.627, acc: 0.678, F1: 0.404
| 2021-07-13 16:58:09 | INFO | 
==============================Start training==============================
| 2021-07-13 16:58:09 | INFO | Command Line Args:   --lr 5e-5 --warmup_ratio 0.2 -c config/encs_at_least_one.conf
Config File (config/encs_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/encs_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/encs_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 16:58:09 | INFO | 
lr: 5e-05

| 2021-07-13 16:58:21 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 16:58:21 | INFO | Start epoch 1:
| 2021-07-13 16:58:22 | INFO | Train Loss: 0.656, tp: 0, fn: 21, fp: 0, tn: 43, Acc: 0.672, Prec: 0.000, Rec: 0.000, F1: 0.402
| 2021-07-13 16:59:32 | INFO | Validation tp: 0, fn: 322, fp: 0, tn: 679
| 2021-07-13 16:59:32 | INFO | Validation loss: 0.580, acc: 0.678, F1: 0.404
| 2021-07-13 16:59:32 | INFO | Start epoch 2:
| 2021-07-13 16:59:33 | INFO | Train Loss: 0.628, tp: 1, fn: 21, fp: 3, tn: 39, Acc: 0.625, Prec: 0.250, Rec: 0.045, F1: 0.421
| 2021-07-13 17:00:41 | INFO | Validation tp: 106, fn: 216, fp: 37, tn: 642
| 2021-07-13 17:00:41 | INFO | Validation loss: 0.547, acc: 0.747, F1: 0.646
| 2021-07-13 17:00:41 | INFO | Start epoch 3:
| 2021-07-13 17:00:42 | INFO | Train Loss: 0.586, tp: 5, fn: 14, fp: 5, tn: 40, Acc: 0.703, Prec: 0.500, Rec: 0.263, F1: 0.576
| 2021-07-13 17:01:50 | INFO | Validation tp: 125, fn: 197, fp: 61, tn: 618
| 2021-07-13 17:01:50 | INFO | Validation loss: 0.536, acc: 0.742, F1: 0.660
| 2021-07-13 17:01:50 | INFO | Start epoch 4:
| 2021-07-13 17:01:51 | INFO | Train Loss: 0.400, tp: 15, fn: 5, fp: 1, tn: 43, Acc: 0.906, Prec: 0.938, Rec: 0.750, F1: 0.884
| 2021-07-13 17:03:00 | INFO | Validation tp: 146, fn: 176, fp: 89, tn: 590
| 2021-07-13 17:03:00 | INFO | Validation loss: 0.632, acc: 0.735, F1: 0.670
| 2021-07-13 17:03:00 | INFO | Start epoch 5:
| 2021-07-13 17:03:00 | INFO | Train Loss: 0.349, tp: 18, fn: 7, fp: 3, tn: 36, Acc: 0.844, Prec: 0.857, Rec: 0.720, F1: 0.830
| 2021-07-13 17:04:09 | INFO | Validation tp: 141, fn: 181, fp: 76, tn: 603
| 2021-07-13 17:04:09 | INFO | Validation loss: 0.700, acc: 0.743, F1: 0.674
| 2021-07-13 17:04:09 | INFO | Start epoch 6:
| 2021-07-13 17:04:09 | INFO | Train Loss: 0.218, tp: 11, fn: 4, fp: 3, tn: 46, Acc: 0.891, Prec: 0.786, Rec: 0.733, F1: 0.844
| 2021-07-13 17:05:18 | INFO | Validation tp: 170, fn: 152, fp: 109, tn: 570
| 2021-07-13 17:05:18 | INFO | Validation loss: 0.834, acc: 0.739, F1: 0.690
| 2021-07-13 17:05:18 | INFO | Start epoch 7:
| 2021-07-13 17:05:18 | INFO | Train Loss: 0.142, tp: 21, fn: 1, fp: 2, tn: 40, Acc: 0.953, Prec: 0.913, Rec: 0.955, F1: 0.949
| 2021-07-13 17:06:27 | INFO | Validation tp: 154, fn: 168, fp: 115, tn: 564
| 2021-07-13 17:06:27 | INFO | Validation loss: 0.994, acc: 0.717, F1: 0.660
| 2021-07-13 17:06:27 | INFO | Start epoch 8:
| 2021-07-13 17:06:27 | INFO | Train Loss: 0.048, tp: 15, fn: 0, fp: 1, tn: 48, Acc: 0.984, Prec: 0.938, Rec: 1.000, F1: 0.979
| 2021-07-13 17:07:36 | INFO | Validation tp: 144, fn: 178, fp: 113, tn: 566
| 2021-07-13 17:07:36 | INFO | Validation loss: 1.167, acc: 0.709, F1: 0.646
| 2021-07-13 17:07:36 | INFO | Start epoch 9:
| 2021-07-13 17:07:37 | INFO | Train Loss: 0.027, tp: 19, fn: 0, fp: 0, tn: 45, Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000
| 2021-07-13 17:08:45 | INFO | Validation tp: 137, fn: 185, fp: 97, tn: 582
| 2021-07-13 17:08:45 | INFO | Validation loss: 1.273, acc: 0.718, F1: 0.649
| 2021-07-13 17:08:45 | INFO | Start epoch 10:
| 2021-07-13 17:08:46 | INFO | Train Loss: 0.025, tp: 23, fn: 0, fp: 1, tn: 40, Acc: 0.984, Prec: 0.958, Rec: 1.000, F1: 0.983
| 2021-07-13 17:09:54 | INFO | Validation tp: 138, fn: 184, fp: 90, tn: 589
| 2021-07-13 17:09:54 | INFO | Validation loss: 1.325, acc: 0.726, F1: 0.657
| 2021-07-13 17:09:57 | INFO | 
==============================Start training==============================
| 2021-07-13 17:09:57 | INFO | Command Line Args:   --lr 2e-5 --warmup_ratio 0.3 -c config/encs_at_least_one.conf
Config File (config/encs_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/encs_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/encs_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 17:09:57 | INFO | 
lr: 2e-05

| 2021-07-13 17:10:05 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 17:10:05 | INFO | Start epoch 1:
| 2021-07-13 17:10:05 | INFO | Train Loss: 0.656, tp: 0, fn: 21, fp: 0, tn: 43, Acc: 0.672, Prec: 0.000, Rec: 0.000, F1: 0.402
| 2021-07-13 17:11:14 | INFO | Validation tp: 0, fn: 322, fp: 0, tn: 679
| 2021-07-13 17:11:14 | INFO | Validation loss: 0.610, acc: 0.678, F1: 0.404
| 2021-07-13 17:11:14 | INFO | Start epoch 2:
| 2021-07-13 17:11:14 | INFO | Train Loss: 0.644, tp: 0, fn: 22, fp: 0, tn: 42, Acc: 0.656, Prec: 0.000, Rec: 0.000, F1: 0.396
| 2021-07-13 17:12:23 | INFO | Validation tp: 122, fn: 200, fp: 76, tn: 603
| 2021-07-13 17:12:23 | INFO | Validation loss: 0.549, acc: 0.724, F1: 0.641
| 2021-07-13 17:12:23 | INFO | Start epoch 3:
| 2021-07-13 17:12:23 | INFO | Train Loss: 0.551, tp: 7, fn: 12, fp: 7, tn: 38, Acc: 0.703, Prec: 0.500, Rec: 0.368, F1: 0.612
| 2021-07-13 17:13:32 | INFO | Validation tp: 128, fn: 194, fp: 69, tn: 610
| 2021-07-13 17:13:32 | INFO | Validation loss: 0.537, acc: 0.737, F1: 0.658
| 2021-07-13 17:13:32 | INFO | Start epoch 4:
| 2021-07-13 17:13:33 | INFO | Train Loss: 0.546, tp: 9, fn: 11, fp: 3, tn: 41, Acc: 0.781, Prec: 0.750, Rec: 0.450, F1: 0.708
| 2021-07-13 17:14:41 | INFO | Validation tp: 141, fn: 181, fp: 75, tn: 604
| 2021-07-13 17:14:41 | INFO | Validation loss: 0.539, acc: 0.744, F1: 0.675
| 2021-07-13 17:14:41 | INFO | Start epoch 5:
| 2021-07-13 17:14:42 | INFO | Train Loss: 0.437, tp: 15, fn: 10, fp: 5, tn: 34, Acc: 0.766, Prec: 0.750, Rec: 0.600, F1: 0.743
| 2021-07-13 17:15:50 | INFO | Validation tp: 121, fn: 201, fp: 53, tn: 626
| 2021-07-13 17:15:50 | INFO | Validation loss: 0.614, acc: 0.746, F1: 0.660
| 2021-07-13 17:15:50 | INFO | Start epoch 6:
| 2021-07-13 17:15:51 | INFO | Train Loss: 0.287, tp: 10, fn: 5, fp: 1, tn: 48, Acc: 0.906, Prec: 0.909, Rec: 0.667, F1: 0.855
| 2021-07-13 17:16:59 | INFO | Validation tp: 159, fn: 163, fp: 102, tn: 577
| 2021-07-13 17:16:59 | INFO | Validation loss: 0.660, acc: 0.735, F1: 0.679
| 2021-07-13 17:16:59 | INFO | Start epoch 7:
| 2021-07-13 17:17:00 | INFO | Train Loss: 0.291, tp: 19, fn: 3, fp: 3, tn: 39, Acc: 0.906, Prec: 0.864, Rec: 0.864, F1: 0.896
| 2021-07-13 17:18:09 | INFO | Validation tp: 132, fn: 190, fp: 68, tn: 611
| 2021-07-13 17:18:09 | INFO | Validation loss: 0.785, acc: 0.742, F1: 0.666
| 2021-07-13 17:18:09 | INFO | Start epoch 8:
| 2021-07-13 17:18:09 | INFO | Train Loss: 0.129, tp: 15, fn: 0, fp: 1, tn: 48, Acc: 0.984, Prec: 0.938, Rec: 1.000, F1: 0.979
| 2021-07-13 17:19:18 | INFO | Validation tp: 157, fn: 165, fp: 96, tn: 583
| 2021-07-13 17:19:18 | INFO | Validation loss: 0.861, acc: 0.739, F1: 0.682
| 2021-07-13 17:19:18 | INFO | Start epoch 9:
| 2021-07-13 17:19:19 | INFO | Train Loss: 0.147, tp: 18, fn: 1, fp: 2, tn: 43, Acc: 0.953, Prec: 0.900, Rec: 0.947, F1: 0.945
| 2021-07-13 17:20:28 | INFO | Validation tp: 151, fn: 171, fp: 85, tn: 594
| 2021-07-13 17:20:28 | INFO | Validation loss: 0.980, acc: 0.744, F1: 0.682
| 2021-07-13 17:20:28 | INFO | Start epoch 10:
| 2021-07-13 17:20:28 | INFO | Train Loss: 0.190, tp: 23, fn: 0, fp: 4, tn: 37, Acc: 0.938, Prec: 0.852, Rec: 1.000, F1: 0.934
| 2021-07-13 17:21:38 | INFO | Validation tp: 141, fn: 181, fp: 77, tn: 602
| 2021-07-13 17:21:38 | INFO | Validation loss: 1.016, acc: 0.742, F1: 0.673
| 2021-07-13 17:21:40 | INFO | 
==============================Start training==============================
| 2021-07-13 17:21:40 | INFO | Command Line Args:   --lr 3e-5 --warmup_ratio 0.3 -c config/encs_at_least_one.conf
Config File (config/encs_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/encs_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/encs_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 17:21:40 | INFO | 
lr: 3e-05

| 2021-07-13 17:21:51 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 17:21:51 | INFO | Start epoch 1:
| 2021-07-13 17:21:51 | INFO | Train Loss: 0.656, tp: 0, fn: 21, fp: 0, tn: 43, Acc: 0.672, Prec: 0.000, Rec: 0.000, F1: 0.402
| 2021-07-13 17:23:00 | INFO | Validation tp: 5, fn: 317, fp: 11, tn: 668
| 2021-07-13 17:23:00 | INFO | Validation loss: 0.616, acc: 0.672, F1: 0.416
| 2021-07-13 17:23:00 | INFO | Start epoch 2:
| 2021-07-13 17:23:01 | INFO | Train Loss: 0.671, tp: 1, fn: 21, fp: 4, tn: 38, Acc: 0.609, Prec: 0.200, Rec: 0.045, F1: 0.413
| 2021-07-13 17:24:10 | INFO | Validation tp: 135, fn: 187, fp: 84, tn: 595
| 2021-07-13 17:24:10 | INFO | Validation loss: 0.551, acc: 0.729, F1: 0.657
| 2021-07-13 17:24:10 | INFO | Start epoch 3:
| 2021-07-13 17:24:11 | INFO | Train Loss: 0.553, tp: 8, fn: 11, fp: 6, tn: 39, Acc: 0.734, Prec: 0.571, Rec: 0.421, F1: 0.653
| 2021-07-13 17:25:20 | INFO | Validation tp: 68, fn: 254, fp: 23, tn: 656
| 2021-07-13 17:25:20 | INFO | Validation loss: 0.564, acc: 0.723, F1: 0.577
| 2021-07-13 17:25:20 | INFO | Start epoch 4:
| 2021-07-13 17:25:21 | INFO | Train Loss: 0.549, tp: 7, fn: 13, fp: 3, tn: 41, Acc: 0.750, Prec: 0.700, Rec: 0.350, F1: 0.652
| 2021-07-13 17:26:30 | INFO | Validation tp: 117, fn: 205, fp: 47, tn: 632
| 2021-07-13 17:26:30 | INFO | Validation loss: 0.592, acc: 0.748, F1: 0.658
| 2021-07-13 17:26:30 | INFO | Start epoch 5:
| 2021-07-13 17:26:31 | INFO | Train Loss: 0.414, tp: 14, fn: 11, fp: 4, tn: 35, Acc: 0.766, Prec: 0.778, Rec: 0.560, F1: 0.737
| 2021-07-13 17:27:40 | INFO | Validation tp: 126, fn: 196, fp: 50, tn: 629
| 2021-07-13 17:27:40 | INFO | Validation loss: 0.625, acc: 0.754, F1: 0.671
| 2021-07-13 17:27:40 | INFO | Start epoch 6:
| 2021-07-13 17:27:40 | INFO | Train Loss: 0.272, tp: 11, fn: 4, fp: 3, tn: 46, Acc: 0.891, Prec: 0.786, Rec: 0.733, F1: 0.844
| 2021-07-13 17:28:49 | INFO | Validation tp: 150, fn: 172, fp: 85, tn: 594
| 2021-07-13 17:28:49 | INFO | Validation loss: 0.644, acc: 0.743, F1: 0.680
| 2021-07-13 17:28:49 | INFO | Start epoch 7:
| 2021-07-13 17:28:50 | INFO | Train Loss: 0.171, tp: 20, fn: 2, fp: 0, tn: 42, Acc: 0.969, Prec: 1.000, Rec: 0.909, F1: 0.965
| 2021-07-13 17:29:59 | INFO | Validation tp: 137, fn: 185, fp: 80, tn: 599
| 2021-07-13 17:29:59 | INFO | Validation loss: 0.818, acc: 0.735, F1: 0.664
| 2021-07-13 17:29:59 | INFO | Start epoch 8:
| 2021-07-13 17:29:59 | INFO | Train Loss: 0.082, tp: 14, fn: 1, fp: 0, tn: 49, Acc: 0.984, Prec: 1.000, Rec: 0.933, F1: 0.978
| 2021-07-13 17:31:08 | INFO | Validation tp: 133, fn: 189, fp: 78, tn: 601
| 2021-07-13 17:31:08 | INFO | Validation loss: 1.002, acc: 0.733, F1: 0.659
| 2021-07-13 17:31:08 | INFO | Start epoch 9:
| 2021-07-13 17:31:08 | INFO | Train Loss: 0.087, tp: 17, fn: 2, fp: 0, tn: 45, Acc: 0.969, Prec: 1.000, Rec: 0.895, F1: 0.961
| 2021-07-13 17:32:17 | INFO | Validation tp: 138, fn: 184, fp: 84, tn: 595
| 2021-07-13 17:32:17 | INFO | Validation loss: 1.121, acc: 0.732, F1: 0.662
| 2021-07-13 17:32:17 | INFO | Start epoch 10:
| 2021-07-13 17:32:18 | INFO | Train Loss: 0.039, tp: 23, fn: 0, fp: 1, tn: 40, Acc: 0.984, Prec: 0.958, Rec: 1.000, F1: 0.983
| 2021-07-13 17:33:26 | INFO | Validation tp: 141, fn: 181, fp: 85, tn: 594
| 2021-07-13 17:33:26 | INFO | Validation loss: 1.181, acc: 0.734, F1: 0.666
| 2021-07-13 17:33:28 | INFO | 
==============================Start training==============================
| 2021-07-13 17:33:28 | INFO | Command Line Args:   --lr 4e-5 --warmup_ratio 0.3 -c config/encs_at_least_one.conf
Config File (config/encs_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/encs_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/encs_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 17:33:28 | INFO | 
lr: 4e-05

| 2021-07-13 17:33:37 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 17:33:37 | INFO | Start epoch 1:
| 2021-07-13 17:33:38 | INFO | Train Loss: 0.656, tp: 0, fn: 21, fp: 0, tn: 43, Acc: 0.672, Prec: 0.000, Rec: 0.000, F1: 0.402
| 2021-07-13 17:34:46 | INFO | Validation tp: 28, fn: 294, fp: 13, tn: 666
| 2021-07-13 17:34:46 | INFO | Validation loss: 0.577, acc: 0.693, F1: 0.483
| 2021-07-13 17:34:46 | INFO | Start epoch 2:
| 2021-07-13 17:34:47 | INFO | Train Loss: 0.683, tp: 3, fn: 19, fp: 7, tn: 35, Acc: 0.594, Prec: 0.300, Rec: 0.136, F1: 0.458
| 2021-07-13 17:35:55 | INFO | Validation tp: 120, fn: 202, fp: 65, tn: 614
| 2021-07-13 17:35:55 | INFO | Validation loss: 0.542, acc: 0.733, F1: 0.647
| 2021-07-13 17:35:55 | INFO | Start epoch 3:
| 2021-07-13 17:35:56 | INFO | Train Loss: 0.552, tp: 7, fn: 12, fp: 8, tn: 37, Acc: 0.688, Prec: 0.467, Rec: 0.368, F1: 0.599
| 2021-07-13 17:37:04 | INFO | Validation tp: 101, fn: 221, fp: 48, tn: 631
| 2021-07-13 17:37:04 | INFO | Validation loss: 0.546, acc: 0.731, F1: 0.627
| 2021-07-13 17:37:04 | INFO | Start epoch 4:
| 2021-07-13 17:37:05 | INFO | Train Loss: 0.471, tp: 8, fn: 12, fp: 4, tn: 40, Acc: 0.750, Prec: 0.667, Rec: 0.400, F1: 0.667
| 2021-07-13 17:38:14 | INFO | Validation tp: 116, fn: 206, fp: 58, tn: 621
| 2021-07-13 17:38:14 | INFO | Validation loss: 0.591, acc: 0.736, F1: 0.646
| 2021-07-13 17:38:14 | INFO | Start epoch 5:
| 2021-07-13 17:38:14 | INFO | Train Loss: 0.456, tp: 12, fn: 13, fp: 3, tn: 36, Acc: 0.750, Prec: 0.800, Rec: 0.480, F1: 0.709
| 2021-07-13 17:39:23 | INFO | Validation tp: 149, fn: 173, fp: 89, tn: 590
| 2021-07-13 17:39:23 | INFO | Validation loss: 0.607, acc: 0.738, F1: 0.675
| 2021-07-13 17:39:23 | INFO | Start epoch 6:
| 2021-07-13 17:39:23 | INFO | Train Loss: 0.254, tp: 12, fn: 3, fp: 3, tn: 46, Acc: 0.906, Prec: 0.800, Rec: 0.800, F1: 0.869
| 2021-07-13 17:40:32 | INFO | Validation tp: 171, fn: 151, fp: 126, tn: 553
| 2021-07-13 17:40:32 | INFO | Validation loss: 0.669, acc: 0.723, F1: 0.676
| 2021-07-13 17:40:32 | INFO | Start epoch 7:
| 2021-07-13 17:40:33 | INFO | Train Loss: 0.210, tp: 21, fn: 1, fp: 1, tn: 41, Acc: 0.969, Prec: 0.955, Rec: 0.955, F1: 0.965
| 2021-07-13 17:41:41 | INFO | Validation tp: 160, fn: 162, fp: 101, tn: 578
| 2021-07-13 17:41:41 | INFO | Validation loss: 0.800, acc: 0.737, F1: 0.682
| 2021-07-13 17:41:41 | INFO | Start epoch 8:
| 2021-07-13 17:41:42 | INFO | Train Loss: 0.127, tp: 15, fn: 0, fp: 3, tn: 46, Acc: 0.953, Prec: 0.833, Rec: 1.000, F1: 0.939
| 2021-07-13 17:42:50 | INFO | Validation tp: 159, fn: 163, fp: 110, tn: 569
| 2021-07-13 17:42:50 | INFO | Validation loss: 0.924, acc: 0.727, F1: 0.672
| 2021-07-13 17:42:50 | INFO | Start epoch 9:
| 2021-07-13 17:42:51 | INFO | Train Loss: 0.103, tp: 18, fn: 1, fp: 2, tn: 43, Acc: 0.953, Prec: 0.900, Rec: 0.947, F1: 0.945
| 2021-07-13 17:44:00 | INFO | Validation tp: 136, fn: 186, fp: 84, tn: 595
| 2021-07-13 17:44:00 | INFO | Validation loss: 1.149, acc: 0.730, F1: 0.658
| 2021-07-13 17:44:00 | INFO | Start epoch 10:
| 2021-07-13 17:44:00 | INFO | Train Loss: 0.074, tp: 22, fn: 1, fp: 0, tn: 41, Acc: 0.984, Prec: 1.000, Rec: 0.957, F1: 0.983
| 2021-07-13 17:45:09 | INFO | Validation tp: 150, fn: 172, fp: 105, tn: 574
| 2021-07-13 17:45:09 | INFO | Validation loss: 1.190, acc: 0.723, F1: 0.663
| 2021-07-13 17:45:11 | INFO | 
==============================Start training==============================
| 2021-07-13 17:45:11 | INFO | Command Line Args:   --lr 5e-5 --warmup_ratio 0.3 -c config/encs_at_least_one.conf
Config File (config/encs_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/encs_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/encs_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 17:45:11 | INFO | 
lr: 5e-05

| 2021-07-13 17:45:20 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 17:45:20 | INFO | Start epoch 1:
| 2021-07-13 17:45:20 | INFO | Train Loss: 0.656, tp: 0, fn: 21, fp: 0, tn: 43, Acc: 0.672, Prec: 0.000, Rec: 0.000, F1: 0.402
| 2021-07-13 17:46:29 | INFO | Validation tp: 2, fn: 320, fp: 1, tn: 678
| 2021-07-13 17:46:29 | INFO | Validation loss: 0.610, acc: 0.679, F1: 0.410
| 2021-07-13 17:46:29 | INFO | Start epoch 2:
| 2021-07-13 17:46:29 | INFO | Train Loss: 0.646, tp: 1, fn: 21, fp: 2, tn: 40, Acc: 0.641, Prec: 0.333, Rec: 0.045, F1: 0.428
| 2021-07-13 17:47:38 | INFO | Validation tp: 155, fn: 167, fp: 117, tn: 562
| 2021-07-13 17:47:38 | INFO | Validation loss: 0.549, acc: 0.716, F1: 0.660
| 2021-07-13 17:47:38 | INFO | Start epoch 3:
| 2021-07-13 17:47:39 | INFO | Train Loss: 0.547, tp: 8, fn: 11, fp: 9, tn: 36, Acc: 0.688, Prec: 0.471, Rec: 0.421, F1: 0.614
| 2021-07-13 17:48:47 | INFO | Validation tp: 187, fn: 135, fp: 164, tn: 515
| 2021-07-13 17:48:47 | INFO | Validation loss: 0.558, acc: 0.701, F1: 0.665
| 2021-07-13 17:48:47 | INFO | Start epoch 4:
| 2021-07-13 17:48:48 | INFO | Train Loss: 0.527, tp: 15, fn: 5, fp: 11, tn: 33, Acc: 0.750, Prec: 0.577, Rec: 0.750, F1: 0.729
| 2021-07-13 17:49:56 | INFO | Validation tp: 148, fn: 174, fp: 95, tn: 584
| 2021-07-13 17:49:56 | INFO | Validation loss: 0.590, acc: 0.731, F1: 0.668
| 2021-07-13 17:49:56 | INFO | Start epoch 5:
| 2021-07-13 17:49:57 | INFO | Train Loss: 0.447, tp: 16, fn: 9, fp: 4, tn: 35, Acc: 0.797, Prec: 0.800, Rec: 0.640, F1: 0.777
| 2021-07-13 17:51:05 | INFO | Validation tp: 117, fn: 205, fp: 56, tn: 623
| 2021-07-13 17:51:05 | INFO | Validation loss: 0.637, acc: 0.739, F1: 0.650
| 2021-07-13 17:51:05 | INFO | Start epoch 6:
| 2021-07-13 17:51:06 | INFO | Train Loss: 0.346, tp: 7, fn: 8, fp: 2, tn: 47, Acc: 0.844, Prec: 0.778, Rec: 0.467, F1: 0.744
| 2021-07-13 17:52:15 | INFO | Validation tp: 157, fn: 165, fp: 134, tn: 545
| 2021-07-13 17:52:15 | INFO | Validation loss: 0.686, acc: 0.701, F1: 0.648
| 2021-07-13 17:52:15 | INFO | Start epoch 7:
| 2021-07-13 17:52:15 | INFO | Train Loss: 0.225, tp: 21, fn: 1, fp: 3, tn: 39, Acc: 0.938, Prec: 0.875, Rec: 0.955, F1: 0.932
| 2021-07-13 17:53:24 | INFO | Validation tp: 122, fn: 200, fp: 85, tn: 594
| 2021-07-13 17:53:24 | INFO | Validation loss: 0.868, acc: 0.715, F1: 0.634
| 2021-07-13 17:53:24 | INFO | Start epoch 8:
| 2021-07-13 17:53:25 | INFO | Train Loss: 0.112, tp: 14, fn: 1, fp: 1, tn: 48, Acc: 0.969, Prec: 0.933, Rec: 0.933, F1: 0.956
| 2021-07-13 17:54:33 | INFO | Validation tp: 139, fn: 183, fp: 103, tn: 576
| 2021-07-13 17:54:33 | INFO | Validation loss: 1.021, acc: 0.714, F1: 0.647
| 2021-07-13 17:54:33 | INFO | Start epoch 9:
| 2021-07-13 17:54:34 | INFO | Train Loss: 0.102, tp: 16, fn: 3, fp: 0, tn: 45, Acc: 0.953, Prec: 1.000, Rec: 0.842, F1: 0.941
| 2021-07-13 17:55:42 | INFO | Validation tp: 149, fn: 173, fp: 115, tn: 564
| 2021-07-13 17:55:42 | INFO | Validation loss: 1.239, acc: 0.712, F1: 0.653
| 2021-07-13 17:55:42 | INFO | Start epoch 10:
| 2021-07-13 17:55:43 | INFO | Train Loss: 0.190, tp: 21, fn: 2, fp: 1, tn: 40, Acc: 0.953, Prec: 0.955, Rec: 0.913, F1: 0.949
| 2021-07-13 17:56:52 | INFO | Validation tp: 139, fn: 183, fp: 108, tn: 571
| 2021-07-13 17:56:52 | INFO | Validation loss: 1.294, acc: 0.709, F1: 0.643
| 2021-07-13 17:56:53 | INFO | 
==============================Start training==============================
| 2021-07-13 17:56:53 | INFO | Command Line Args:   --lr 2e-5 --warmup_ratio 0.2 -c config/ende_at_least_one.conf
Config File (config/ende_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/ende_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/ende_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 17:56:53 | INFO | 
lr: 2e-05

| 2021-07-13 17:57:01 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 17:57:01 | INFO | Start epoch 1:
| 2021-07-13 17:57:02 | INFO | Train Loss: 0.637, tp: 0, fn: 21, fp: 0, tn: 43, Acc: 0.672, Prec: 0.000, Rec: 0.000, F1: 0.402
| 2021-07-13 17:58:14 | INFO | Validation tp: 127, fn: 239, fp: 59, tn: 576
| 2021-07-13 17:58:14 | INFO | Validation loss: 0.584, acc: 0.702, F1: 0.627
| 2021-07-13 17:58:14 | INFO | Start epoch 2:
| 2021-07-13 17:58:14 | INFO | Train Loss: 0.642, tp: 9, fn: 17, fp: 8, tn: 30, Acc: 0.609, Prec: 0.529, Rec: 0.346, F1: 0.562
| 2021-07-13 17:59:27 | INFO | Validation tp: 109, fn: 257, fp: 40, tn: 595
| 2021-07-13 17:59:27 | INFO | Validation loss: 0.597, acc: 0.703, F1: 0.612
| 2021-07-13 17:59:27 | INFO | Start epoch 3:
| 2021-07-13 17:59:27 | INFO | Train Loss: 0.619, tp: 6, fn: 11, fp: 6, tn: 41, Acc: 0.734, Prec: 0.500, Rec: 0.353, F1: 0.621
| 2021-07-13 18:00:40 | INFO | Validation tp: 212, fn: 154, fp: 114, tn: 521
| 2021-07-13 18:00:40 | INFO | Validation loss: 0.540, acc: 0.732, F1: 0.704
| 2021-07-13 18:00:40 | INFO | Start epoch 4:
| 2021-07-13 18:00:40 | INFO | Train Loss: 0.500, tp: 19, fn: 6, fp: 11, tn: 28, Acc: 0.734, Prec: 0.633, Rec: 0.760, F1: 0.729
| 2021-07-13 18:01:53 | INFO | Validation tp: 181, fn: 185, fp: 81, tn: 554
| 2021-07-13 18:01:53 | INFO | Validation loss: 0.577, acc: 0.734, F1: 0.691
| 2021-07-13 18:01:53 | INFO | Start epoch 5:
| 2021-07-13 18:01:53 | INFO | Train Loss: 0.440, tp: 15, fn: 8, fp: 5, tn: 36, Acc: 0.797, Prec: 0.750, Rec: 0.652, F1: 0.772
| 2021-07-13 18:03:06 | INFO | Validation tp: 120, fn: 246, fp: 26, tn: 609
| 2021-07-13 18:03:06 | INFO | Validation loss: 0.644, acc: 0.728, F1: 0.643
| 2021-07-13 18:03:06 | INFO | Start epoch 6:
| 2021-07-13 18:03:06 | INFO | Train Loss: 0.366, tp: 15, fn: 8, fp: 1, tn: 40, Acc: 0.859, Prec: 0.938, Rec: 0.652, F1: 0.834
| 2021-07-13 18:04:19 | INFO | Validation tp: 183, fn: 183, fp: 83, tn: 552
| 2021-07-13 18:04:19 | INFO | Validation loss: 0.779, acc: 0.734, F1: 0.692
| 2021-07-13 18:04:19 | INFO | Start epoch 7:
| 2021-07-13 18:04:19 | INFO | Train Loss: 0.122, tp: 26, fn: 1, fp: 0, tn: 37, Acc: 0.984, Prec: 1.000, Rec: 0.963, F1: 0.984
| 2021-07-13 18:05:32 | INFO | Validation tp: 182, fn: 184, fp: 88, tn: 547
| 2021-07-13 18:05:32 | INFO | Validation loss: 0.900, acc: 0.728, F1: 0.687
| 2021-07-13 18:05:32 | INFO | Start epoch 8:
| 2021-07-13 18:05:32 | INFO | Train Loss: 0.182, tp: 23, fn: 1, fp: 1, tn: 39, Acc: 0.969, Prec: 0.958, Rec: 0.958, F1: 0.967
| 2021-07-13 18:06:44 | INFO | Validation tp: 180, fn: 186, fp: 94, tn: 541
| 2021-07-13 18:06:44 | INFO | Validation loss: 0.984, acc: 0.720, F1: 0.678
| 2021-07-13 18:06:44 | INFO | Start epoch 9:
| 2021-07-13 18:06:45 | INFO | Train Loss: 0.064, tp: 21, fn: 1, fp: 1, tn: 41, Acc: 0.969, Prec: 0.955, Rec: 0.955, F1: 0.965
| 2021-07-13 18:07:58 | INFO | Validation tp: 173, fn: 193, fp: 82, tn: 553
| 2021-07-13 18:07:58 | INFO | Validation loss: 1.119, acc: 0.725, F1: 0.679
| 2021-07-13 18:07:58 | INFO | Start epoch 10:
| 2021-07-13 18:07:58 | INFO | Train Loss: 0.036, tp: 18, fn: 0, fp: 0, tn: 46, Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000
| 2021-07-13 18:09:11 | INFO | Validation tp: 166, fn: 200, fp: 75, tn: 560
| 2021-07-13 18:09:11 | INFO | Validation loss: 1.136, acc: 0.725, F1: 0.675
| 2021-07-13 18:09:13 | INFO | 
==============================Start training==============================
| 2021-07-13 18:09:13 | INFO | Command Line Args:   --lr 3e-5 --warmup_ratio 0.2 -c config/ende_at_least_one.conf
Config File (config/ende_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/ende_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/ende_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 18:09:13 | INFO | 
lr: 3e-05

| 2021-07-13 18:09:21 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 18:09:21 | INFO | Start epoch 1:
| 2021-07-13 18:09:22 | INFO | Train Loss: 0.637, tp: 0, fn: 21, fp: 0, tn: 43, Acc: 0.672, Prec: 0.000, Rec: 0.000, F1: 0.402
| 2021-07-13 18:10:34 | INFO | Validation tp: 118, fn: 248, fp: 46, tn: 589
| 2021-07-13 18:10:34 | INFO | Validation loss: 0.584, acc: 0.706, F1: 0.623
| 2021-07-13 18:10:34 | INFO | Start epoch 2:
| 2021-07-13 18:10:34 | INFO | Train Loss: 0.646, tp: 4, fn: 22, fp: 1, tn: 37, Acc: 0.641, Prec: 0.800, Rec: 0.154, F1: 0.510
| 2021-07-13 18:11:46 | INFO | Validation tp: 236, fn: 130, fp: 160, tn: 475
| 2021-07-13 18:11:46 | INFO | Validation loss: 0.584, acc: 0.710, F1: 0.693
| 2021-07-13 18:11:46 | INFO | Start epoch 3:
| 2021-07-13 18:11:47 | INFO | Train Loss: 0.543, tp: 12, fn: 5, fp: 12, tn: 35, Acc: 0.734, Prec: 0.500, Rec: 0.706, F1: 0.695
| 2021-07-13 18:12:59 | INFO | Validation tp: 223, fn: 143, fp: 133, tn: 502
| 2021-07-13 18:12:59 | INFO | Validation loss: 0.564, acc: 0.724, F1: 0.701
| 2021-07-13 18:12:59 | INFO | Start epoch 4:
| 2021-07-13 18:13:00 | INFO | Train Loss: 0.527, tp: 20, fn: 5, fp: 8, tn: 31, Acc: 0.797, Prec: 0.714, Rec: 0.800, F1: 0.791
| 2021-07-13 18:14:12 | INFO | Validation tp: 193, fn: 173, fp: 103, tn: 532
| 2021-07-13 18:14:12 | INFO | Validation loss: 0.570, acc: 0.724, F1: 0.689
| 2021-07-13 18:14:12 | INFO | Start epoch 5:
| 2021-07-13 18:14:13 | INFO | Train Loss: 0.437, tp: 17, fn: 6, fp: 7, tn: 34, Acc: 0.797, Prec: 0.708, Rec: 0.739, F1: 0.781
| 2021-07-13 18:15:25 | INFO | Validation tp: 137, fn: 229, fp: 44, tn: 591
| 2021-07-13 18:15:25 | INFO | Validation loss: 0.703, acc: 0.727, F1: 0.657
| 2021-07-13 18:15:25 | INFO | Start epoch 6:
| 2021-07-13 18:15:25 | INFO | Train Loss: 0.287, tp: 17, fn: 6, fp: 2, tn: 39, Acc: 0.875, Prec: 0.895, Rec: 0.739, F1: 0.858
| 2021-07-13 18:16:37 | INFO | Validation tp: 164, fn: 202, fp: 91, tn: 544
| 2021-07-13 18:16:37 | INFO | Validation loss: 0.887, acc: 0.707, F1: 0.658
| 2021-07-13 18:16:37 | INFO | Start epoch 7:
| 2021-07-13 18:16:38 | INFO | Train Loss: 0.143, tp: 25, fn: 2, fp: 0, tn: 37, Acc: 0.969, Prec: 1.000, Rec: 0.926, F1: 0.968
| 2021-07-13 18:17:50 | INFO | Validation tp: 152, fn: 214, fp: 68, tn: 567
| 2021-07-13 18:17:50 | INFO | Validation loss: 1.091, acc: 0.718, F1: 0.660
| 2021-07-13 18:17:50 | INFO | Start epoch 8:
| 2021-07-13 18:17:51 | INFO | Train Loss: 0.128, tp: 21, fn: 3, fp: 0, tn: 40, Acc: 0.953, Prec: 1.000, Rec: 0.875, F1: 0.949
| 2021-07-13 18:19:03 | INFO | Validation tp: 151, fn: 215, fp: 73, tn: 562
| 2021-07-13 18:19:03 | INFO | Validation loss: 1.153, acc: 0.712, F1: 0.654
| 2021-07-13 18:19:03 | INFO | Start epoch 9:
| 2021-07-13 18:19:04 | INFO | Train Loss: 0.127, tp: 22, fn: 0, fp: 2, tn: 40, Acc: 0.969, Prec: 0.917, Rec: 1.000, F1: 0.966
| 2021-07-13 18:20:16 | INFO | Validation tp: 160, fn: 206, fp: 81, tn: 554
| 2021-07-13 18:20:16 | INFO | Validation loss: 1.283, acc: 0.713, F1: 0.661
| 2021-07-13 18:20:16 | INFO | Start epoch 10:
| 2021-07-13 18:20:16 | INFO | Train Loss: 0.023, tp: 18, fn: 0, fp: 0, tn: 46, Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000
| 2021-07-13 18:21:28 | INFO | Validation tp: 158, fn: 208, fp: 81, tn: 554
| 2021-07-13 18:21:28 | INFO | Validation loss: 1.312, acc: 0.711, F1: 0.658
| 2021-07-13 18:21:30 | INFO | 
==============================Start training==============================
| 2021-07-13 18:21:30 | INFO | Command Line Args:   --lr 4e-5 --warmup_ratio 0.2 -c config/ende_at_least_one.conf
Config File (config/ende_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/ende_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/ende_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 18:21:30 | INFO | 
lr: 4e-05

| 2021-07-13 18:21:39 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 18:21:39 | INFO | Start epoch 1:
| 2021-07-13 18:21:39 | INFO | Train Loss: 0.637, tp: 0, fn: 21, fp: 0, tn: 43, Acc: 0.672, Prec: 0.000, Rec: 0.000, F1: 0.402
| 2021-07-13 18:22:51 | INFO | Validation tp: 1, fn: 365, fp: 0, tn: 635
| 2021-07-13 18:22:51 | INFO | Validation loss: 0.617, acc: 0.635, F1: 0.391
| 2021-07-13 18:22:51 | INFO | Start epoch 2:
| 2021-07-13 18:22:52 | INFO | Train Loss: 0.629, tp: 2, fn: 24, fp: 0, tn: 38, Acc: 0.625, Prec: 1.000, Rec: 0.077, F1: 0.451
| 2021-07-13 18:24:04 | INFO | Validation tp: 214, fn: 152, fp: 117, tn: 518
| 2021-07-13 18:24:04 | INFO | Validation loss: 0.562, acc: 0.731, F1: 0.704
| 2021-07-13 18:24:04 | INFO | Start epoch 3:
| 2021-07-13 18:24:05 | INFO | Train Loss: 0.586, tp: 12, fn: 5, fp: 14, tn: 33, Acc: 0.703, Prec: 0.462, Rec: 0.706, F1: 0.667
| 2021-07-13 18:25:17 | INFO | Validation tp: 224, fn: 142, fp: 126, tn: 509
| 2021-07-13 18:25:17 | INFO | Validation loss: 0.560, acc: 0.732, F1: 0.709
| 2021-07-13 18:25:17 | INFO | Start epoch 4:
| 2021-07-13 18:25:18 | INFO | Train Loss: 0.535, tp: 18, fn: 7, fp: 10, tn: 29, Acc: 0.734, Prec: 0.643, Rec: 0.720, F1: 0.726
| 2021-07-13 18:26:30 | INFO | Validation tp: 0, fn: 366, fp: 0, tn: 635
| 2021-07-13 18:26:30 | INFO | Validation loss: 0.657, acc: 0.634, F1: 0.388
| 2021-07-13 18:26:30 | INFO | Start epoch 5:
| 2021-07-13 18:26:30 | INFO | Train Loss: 0.654, tp: 0, fn: 23, fp: 0, tn: 41, Acc: 0.641, Prec: 0.000, Rec: 0.000, F1: 0.390
| 2021-07-13 18:27:43 | INFO | Validation tp: 0, fn: 366, fp: 0, tn: 635
| 2021-07-13 18:27:43 | INFO | Validation loss: 0.657, acc: 0.634, F1: 0.388
| 2021-07-13 18:27:43 | INFO | Start epoch 6:
| 2021-07-13 18:27:43 | INFO | Train Loss: 0.645, tp: 0, fn: 23, fp: 0, tn: 41, Acc: 0.641, Prec: 0.000, Rec: 0.000, F1: 0.390
| 2021-07-13 18:28:55 | INFO | Validation tp: 0, fn: 366, fp: 0, tn: 635
| 2021-07-13 18:28:55 | INFO | Validation loss: 0.656, acc: 0.634, F1: 0.388
| 2021-07-13 18:28:55 | INFO | Start epoch 7:
| 2021-07-13 18:28:56 | INFO | Train Loss: 0.703, tp: 0, fn: 27, fp: 0, tn: 37, Acc: 0.578, Prec: 0.000, Rec: 0.000, F1: 0.366
| 2021-07-13 18:30:08 | INFO | Validation tp: 0, fn: 366, fp: 0, tn: 635
| 2021-07-13 18:30:08 | INFO | Validation loss: 0.657, acc: 0.634, F1: 0.388
| 2021-07-13 18:30:08 | INFO | Start epoch 8:
| 2021-07-13 18:30:09 | INFO | Train Loss: 0.654, tp: 0, fn: 24, fp: 0, tn: 40, Acc: 0.625, Prec: 0.000, Rec: 0.000, F1: 0.385
| 2021-07-13 18:31:21 | INFO | Validation tp: 0, fn: 366, fp: 0, tn: 635
| 2021-07-13 18:31:21 | INFO | Validation loss: 0.656, acc: 0.634, F1: 0.388
| 2021-07-13 18:31:21 | INFO | Start epoch 9:
| 2021-07-13 18:31:21 | INFO | Train Loss: 0.649, tp: 0, fn: 22, fp: 0, tn: 42, Acc: 0.656, Prec: 0.000, Rec: 0.000, F1: 0.396
| 2021-07-13 18:32:34 | INFO | Validation tp: 0, fn: 366, fp: 0, tn: 635
| 2021-07-13 18:32:34 | INFO | Validation loss: 0.656, acc: 0.634, F1: 0.388
| 2021-07-13 18:32:34 | INFO | Start epoch 10:
| 2021-07-13 18:32:34 | INFO | Train Loss: 0.607, tp: 0, fn: 18, fp: 0, tn: 46, Acc: 0.719, Prec: 0.000, Rec: 0.000, F1: 0.418
| 2021-07-13 18:33:46 | INFO | Validation tp: 0, fn: 366, fp: 0, tn: 635
| 2021-07-13 18:33:46 | INFO | Validation loss: 0.656, acc: 0.634, F1: 0.388
| 2021-07-13 18:33:48 | INFO | 
==============================Start training==============================
| 2021-07-13 18:33:48 | INFO | Command Line Args:   --lr 5e-5 --warmup_ratio 0.2 -c config/ende_at_least_one.conf
Config File (config/ende_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/ende_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/ende_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 18:33:48 | INFO | 
lr: 5e-05

| 2021-07-13 18:33:57 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 18:33:57 | INFO | Start epoch 1:
| 2021-07-13 18:33:58 | INFO | Train Loss: 0.637, tp: 0, fn: 21, fp: 0, tn: 43, Acc: 0.672, Prec: 0.000, Rec: 0.000, F1: 0.402
| 2021-07-13 18:35:10 | INFO | Validation tp: 205, fn: 161, fp: 108, tn: 527
| 2021-07-13 18:35:10 | INFO | Validation loss: 0.566, acc: 0.731, F1: 0.700
| 2021-07-13 18:35:10 | INFO | Start epoch 2:
| 2021-07-13 18:35:11 | INFO | Train Loss: 0.630, tp: 11, fn: 15, fp: 9, tn: 29, Acc: 0.625, Prec: 0.550, Rec: 0.423, F1: 0.593
| 2021-07-13 18:36:23 | INFO | Validation tp: 162, fn: 204, fp: 70, tn: 565
| 2021-07-13 18:36:23 | INFO | Validation loss: 0.567, acc: 0.726, F1: 0.673
| 2021-07-13 18:36:23 | INFO | Start epoch 3:
| 2021-07-13 18:36:23 | INFO | Train Loss: 0.562, tp: 6, fn: 11, fp: 7, tn: 40, Acc: 0.719, Prec: 0.462, Rec: 0.353, F1: 0.608
| 2021-07-13 18:37:36 | INFO | Validation tp: 232, fn: 134, fp: 132, tn: 503
| 2021-07-13 18:37:36 | INFO | Validation loss: 0.561, acc: 0.734, F1: 0.713
| 2021-07-13 18:37:36 | INFO | Start epoch 4:
| 2021-07-13 18:37:36 | INFO | Train Loss: 0.504, tp: 21, fn: 4, fp: 10, tn: 29, Acc: 0.781, Prec: 0.677, Rec: 0.840, F1: 0.778
| 2021-07-13 18:38:49 | INFO | Validation tp: 169, fn: 197, fp: 72, tn: 563
| 2021-07-13 18:38:49 | INFO | Validation loss: 0.601, acc: 0.731, F1: 0.682
| 2021-07-13 18:38:49 | INFO | Start epoch 5:
| 2021-07-13 18:38:49 | INFO | Train Loss: 0.338, tp: 18, fn: 5, fp: 2, tn: 39, Acc: 0.891, Prec: 0.900, Rec: 0.783, F1: 0.877
| 2021-07-13 18:40:02 | INFO | Validation tp: 168, fn: 198, fp: 67, tn: 568
| 2021-07-13 18:40:02 | INFO | Validation loss: 0.644, acc: 0.735, F1: 0.685
| 2021-07-13 18:40:02 | INFO | Start epoch 6:
| 2021-07-13 18:40:02 | INFO | Train Loss: 0.345, tp: 17, fn: 6, fp: 2, tn: 39, Acc: 0.875, Prec: 0.895, Rec: 0.739, F1: 0.858
| 2021-07-13 18:41:15 | INFO | Validation tp: 167, fn: 199, fp: 69, tn: 566
| 2021-07-13 18:41:15 | INFO | Validation loss: 0.899, acc: 0.732, F1: 0.682
| 2021-07-13 18:41:15 | INFO | Start epoch 7:
| 2021-07-13 18:41:15 | INFO | Train Loss: 0.169, tp: 22, fn: 5, fp: 0, tn: 37, Acc: 0.922, Prec: 1.000, Rec: 0.815, F1: 0.917
| 2021-07-13 18:42:27 | INFO | Validation tp: 176, fn: 190, fp: 84, tn: 551
| 2021-07-13 18:42:27 | INFO | Validation loss: 1.077, acc: 0.726, F1: 0.682
| 2021-07-13 18:42:27 | INFO | Start epoch 8:
| 2021-07-13 18:42:28 | INFO | Train Loss: 0.097, tp: 23, fn: 1, fp: 1, tn: 39, Acc: 0.969, Prec: 0.958, Rec: 0.958, F1: 0.967
| 2021-07-13 18:43:40 | INFO | Validation tp: 174, fn: 192, fp: 74, tn: 561
| 2021-07-13 18:43:40 | INFO | Validation loss: 1.185, acc: 0.734, F1: 0.688
| 2021-07-13 18:43:40 | INFO | Start epoch 9:
| 2021-07-13 18:43:41 | INFO | Train Loss: 0.038, tp: 22, fn: 0, fp: 1, tn: 41, Acc: 0.984, Prec: 0.957, Rec: 1.000, F1: 0.983
| 2021-07-13 18:44:53 | INFO | Validation tp: 167, fn: 199, fp: 67, tn: 568
| 2021-07-13 18:44:53 | INFO | Validation loss: 1.393, acc: 0.734, F1: 0.683
| 2021-07-13 18:44:53 | INFO | Start epoch 10:
| 2021-07-13 18:44:54 | INFO | Train Loss: 0.017, tp: 18, fn: 0, fp: 0, tn: 46, Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000
| 2021-07-13 18:46:06 | INFO | Validation tp: 172, fn: 194, fp: 70, tn: 565
| 2021-07-13 18:46:06 | INFO | Validation loss: 1.413, acc: 0.736, F1: 0.688
| 2021-07-13 18:46:08 | INFO | 
==============================Start training==============================
| 2021-07-13 18:46:08 | INFO | Command Line Args:   --lr 2e-5 --warmup_ratio 0.3 -c config/ende_at_least_one.conf
Config File (config/ende_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/ende_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/ende_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 18:46:08 | INFO | 
lr: 2e-05

| 2021-07-13 18:46:17 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 18:46:17 | INFO | Start epoch 1:
| 2021-07-13 18:46:17 | INFO | Train Loss: 0.637, tp: 0, fn: 21, fp: 0, tn: 43, Acc: 0.672, Prec: 0.000, Rec: 0.000, F1: 0.402
| 2021-07-13 18:47:29 | INFO | Validation tp: 0, fn: 366, fp: 0, tn: 635
| 2021-07-13 18:47:29 | INFO | Validation loss: 0.645, acc: 0.634, F1: 0.388
| 2021-07-13 18:47:29 | INFO | Start epoch 2:
| 2021-07-13 18:47:30 | INFO | Train Loss: 0.662, tp: 0, fn: 26, fp: 0, tn: 38, Acc: 0.594, Prec: 0.000, Rec: 0.000, F1: 0.373
| 2021-07-13 18:48:42 | INFO | Validation tp: 171, fn: 195, fp: 78, tn: 557
| 2021-07-13 18:48:42 | INFO | Validation loss: 0.561, acc: 0.727, F1: 0.680
| 2021-07-13 18:48:42 | INFO | Start epoch 3:
| 2021-07-13 18:48:42 | INFO | Train Loss: 0.553, tp: 9, fn: 8, fp: 5, tn: 42, Acc: 0.797, Prec: 0.643, Rec: 0.529, F1: 0.723
| 2021-07-13 18:49:55 | INFO | Validation tp: 222, fn: 144, fp: 129, tn: 506
| 2021-07-13 18:49:55 | INFO | Validation loss: 0.552, acc: 0.727, F1: 0.703
| 2021-07-13 18:49:55 | INFO | Start epoch 4:
| 2021-07-13 18:49:55 | INFO | Train Loss: 0.523, tp: 18, fn: 7, fp: 10, tn: 29, Acc: 0.734, Prec: 0.643, Rec: 0.720, F1: 0.726
| 2021-07-13 18:51:07 | INFO | Validation tp: 200, fn: 166, fp: 96, tn: 539
| 2021-07-13 18:51:07 | INFO | Validation loss: 0.564, acc: 0.738, F1: 0.704
| 2021-07-13 18:51:07 | INFO | Start epoch 5:
| 2021-07-13 18:51:08 | INFO | Train Loss: 0.499, tp: 13, fn: 10, fp: 8, tn: 33, Acc: 0.719, Prec: 0.619, Rec: 0.565, F1: 0.688
| 2021-07-13 18:52:20 | INFO | Validation tp: 152, fn: 214, fp: 58, tn: 577
| 2021-07-13 18:52:20 | INFO | Validation loss: 0.637, acc: 0.728, F1: 0.669
| 2021-07-13 18:52:20 | INFO | Start epoch 6:
| 2021-07-13 18:52:20 | INFO | Train Loss: 0.362, tp: 16, fn: 7, fp: 1, tn: 40, Acc: 0.875, Prec: 0.941, Rec: 0.696, F1: 0.855
| 2021-07-13 18:53:33 | INFO | Validation tp: 179, fn: 187, fp: 82, tn: 553
| 2021-07-13 18:53:33 | INFO | Validation loss: 0.712, acc: 0.731, F1: 0.688
| 2021-07-13 18:53:33 | INFO | Start epoch 7:
| 2021-07-13 18:53:33 | INFO | Train Loss: 0.223, tp: 23, fn: 4, fp: 2, tn: 35, Acc: 0.906, Prec: 0.920, Rec: 0.852, F1: 0.903
| 2021-07-13 18:54:45 | INFO | Validation tp: 166, fn: 200, fp: 65, tn: 570
| 2021-07-13 18:54:45 | INFO | Validation loss: 0.883, acc: 0.735, F1: 0.684
| 2021-07-13 18:54:45 | INFO | Start epoch 8:
| 2021-07-13 18:54:46 | INFO | Train Loss: 0.309, tp: 18, fn: 6, fp: 4, tn: 36, Acc: 0.844, Prec: 0.818, Rec: 0.750, F1: 0.830
| 2021-07-13 18:55:58 | INFO | Validation tp: 166, fn: 200, fp: 76, tn: 559
| 2021-07-13 18:55:58 | INFO | Validation loss: 0.963, acc: 0.724, F1: 0.674
| 2021-07-13 18:55:58 | INFO | Start epoch 9:
| 2021-07-13 18:55:59 | INFO | Train Loss: 0.086, tp: 21, fn: 1, fp: 0, tn: 42, Acc: 0.984, Prec: 1.000, Rec: 0.955, F1: 0.982
| 2021-07-13 18:57:11 | INFO | Validation tp: 182, fn: 184, fp: 83, tn: 552
| 2021-07-13 18:57:11 | INFO | Validation loss: 1.081, acc: 0.733, F1: 0.691
| 2021-07-13 18:57:11 | INFO | Start epoch 10:
| 2021-07-13 18:57:11 | INFO | Train Loss: 0.081, tp: 17, fn: 1, fp: 0, tn: 46, Acc: 0.984, Prec: 1.000, Rec: 0.944, F1: 0.980
| 2021-07-13 18:58:24 | INFO | Validation tp: 168, fn: 198, fp: 68, tn: 567
| 2021-07-13 18:58:24 | INFO | Validation loss: 1.068, acc: 0.734, F1: 0.684
| 2021-07-13 18:58:26 | INFO | 
==============================Start training==============================
| 2021-07-13 18:58:26 | INFO | Command Line Args:   --lr 3e-5 --warmup_ratio 0.3 -c config/ende_at_least_one.conf
Config File (config/ende_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/ende_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/ende_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 18:58:26 | INFO | 
lr: 3e-05

| 2021-07-13 18:58:34 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 18:58:34 | INFO | Start epoch 1:
| 2021-07-13 18:58:35 | INFO | Train Loss: 0.637, tp: 0, fn: 21, fp: 0, tn: 43, Acc: 0.672, Prec: 0.000, Rec: 0.000, F1: 0.402
| 2021-07-13 18:59:47 | INFO | Validation tp: 127, fn: 239, fp: 59, tn: 576
| 2021-07-13 18:59:47 | INFO | Validation loss: 0.584, acc: 0.702, F1: 0.627
| 2021-07-13 18:59:47 | INFO | Start epoch 2:
| 2021-07-13 18:59:47 | INFO | Train Loss: 0.642, tp: 9, fn: 17, fp: 8, tn: 30, Acc: 0.609, Prec: 0.529, Rec: 0.346, F1: 0.562
| 2021-07-13 19:00:59 | INFO | Validation tp: 109, fn: 257, fp: 40, tn: 595
| 2021-07-13 19:00:59 | INFO | Validation loss: 0.597, acc: 0.703, F1: 0.612
| 2021-07-13 19:00:59 | INFO | Start epoch 3:
| 2021-07-13 19:01:00 | INFO | Train Loss: 0.619, tp: 6, fn: 11, fp: 6, tn: 41, Acc: 0.734, Prec: 0.500, Rec: 0.353, F1: 0.621
| 2021-07-13 19:02:12 | INFO | Validation tp: 196, fn: 170, fp: 96, tn: 539
| 2021-07-13 19:02:12 | INFO | Validation loss: 0.553, acc: 0.734, F1: 0.699
| 2021-07-13 19:02:12 | INFO | Start epoch 4:
| 2021-07-13 19:02:13 | INFO | Train Loss: 0.508, tp: 17, fn: 8, fp: 9, tn: 30, Acc: 0.734, Prec: 0.654, Rec: 0.680, F1: 0.723
| 2021-07-13 19:03:25 | INFO | Validation tp: 185, fn: 181, fp: 81, tn: 554
| 2021-07-13 19:03:25 | INFO | Validation loss: 0.569, acc: 0.738, F1: 0.697
| 2021-07-13 19:03:25 | INFO | Start epoch 5:
| 2021-07-13 19:03:25 | INFO | Train Loss: 0.440, tp: 18, fn: 5, fp: 5, tn: 36, Acc: 0.844, Prec: 0.783, Rec: 0.783, F1: 0.830
| 2021-07-13 19:04:37 | INFO | Validation tp: 140, fn: 226, fp: 35, tn: 600
| 2021-07-13 19:04:37 | INFO | Validation loss: 0.638, acc: 0.739, F1: 0.669
| 2021-07-13 19:04:37 | INFO | Start epoch 6:
| 2021-07-13 19:04:38 | INFO | Train Loss: 0.313, tp: 17, fn: 6, fp: 2, tn: 39, Acc: 0.875, Prec: 0.895, Rec: 0.739, F1: 0.858
| 2021-07-13 19:05:50 | INFO | Validation tp: 172, fn: 194, fp: 88, tn: 547
| 2021-07-13 19:05:50 | INFO | Validation loss: 0.825, acc: 0.718, F1: 0.672
| 2021-07-13 19:05:50 | INFO | Start epoch 7:
| 2021-07-13 19:05:51 | INFO | Train Loss: 0.120, tp: 26, fn: 1, fp: 1, tn: 36, Acc: 0.969, Prec: 0.963, Rec: 0.963, F1: 0.968
| 2021-07-13 19:07:03 | INFO | Validation tp: 172, fn: 194, fp: 79, tn: 556
| 2021-07-13 19:07:03 | INFO | Validation loss: 0.973, acc: 0.727, F1: 0.680
| 2021-07-13 19:07:03 | INFO | Start epoch 8:
| 2021-07-13 19:07:03 | INFO | Train Loss: 0.074, tp: 24, fn: 0, fp: 1, tn: 39, Acc: 0.984, Prec: 0.960, Rec: 1.000, F1: 0.983
| 2021-07-13 19:08:16 | INFO | Validation tp: 167, fn: 199, fp: 78, tn: 557
| 2021-07-13 19:08:16 | INFO | Validation loss: 1.130, acc: 0.723, F1: 0.674
| 2021-07-13 19:08:16 | INFO | Start epoch 9:
| 2021-07-13 19:08:16 | INFO | Train Loss: 0.165, tp: 21, fn: 1, fp: 3, tn: 39, Acc: 0.938, Prec: 0.875, Rec: 0.955, F1: 0.932
| 2021-07-13 19:09:28 | INFO | Validation tp: 163, fn: 203, fp: 71, tn: 564
| 2021-07-13 19:09:28 | INFO | Validation loss: 1.293, acc: 0.726, F1: 0.674
| 2021-07-13 19:09:28 | INFO | Start epoch 10:
| 2021-07-13 19:09:29 | INFO | Train Loss: 0.011, tp: 18, fn: 0, fp: 0, tn: 46, Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000
| 2021-07-13 19:10:41 | INFO | Validation tp: 171, fn: 195, fp: 72, tn: 563
| 2021-07-13 19:10:41 | INFO | Validation loss: 1.343, acc: 0.733, F1: 0.685
| 2021-07-13 19:10:43 | INFO | 
==============================Start training==============================
| 2021-07-13 19:10:43 | INFO | Command Line Args:   --lr 4e-5 --warmup_ratio 0.3 -c config/ende_at_least_one.conf
Config File (config/ende_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/ende_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/ende_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 19:10:43 | INFO | 
lr: 4e-05

| 2021-07-13 19:10:51 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 19:10:51 | INFO | Start epoch 1:
| 2021-07-13 19:10:52 | INFO | Train Loss: 0.637, tp: 0, fn: 21, fp: 0, tn: 43, Acc: 0.672, Prec: 0.000, Rec: 0.000, F1: 0.402
| 2021-07-13 19:12:04 | INFO | Validation tp: 131, fn: 235, fp: 59, tn: 576
| 2021-07-13 19:12:04 | INFO | Validation loss: 0.587, acc: 0.706, F1: 0.634
| 2021-07-13 19:12:04 | INFO | Start epoch 2:
| 2021-07-13 19:12:04 | INFO | Train Loss: 0.650, tp: 6, fn: 20, fp: 5, tn: 33, Acc: 0.609, Prec: 0.545, Rec: 0.231, F1: 0.525
| 2021-07-13 19:13:17 | INFO | Validation tp: 181, fn: 185, fp: 92, tn: 543
| 2021-07-13 19:13:17 | INFO | Validation loss: 0.562, acc: 0.723, F1: 0.682
| 2021-07-13 19:13:17 | INFO | Start epoch 3:
| 2021-07-13 19:13:17 | INFO | Train Loss: 0.545, tp: 9, fn: 8, fp: 7, tn: 40, Acc: 0.766, Prec: 0.562, Rec: 0.529, F1: 0.694
| 2021-07-13 19:14:30 | INFO | Validation tp: 213, fn: 153, fp: 120, tn: 515
| 2021-07-13 19:14:30 | INFO | Validation loss: 0.556, acc: 0.727, F1: 0.700
| 2021-07-13 19:14:30 | INFO | Start epoch 4:
| 2021-07-13 19:14:30 | INFO | Train Loss: 0.488, tp: 19, fn: 6, fp: 6, tn: 33, Acc: 0.812, Prec: 0.760, Rec: 0.760, F1: 0.803
| 2021-07-13 19:15:42 | INFO | Validation tp: 148, fn: 218, fp: 54, tn: 581
| 2021-07-13 19:15:42 | INFO | Validation loss: 0.589, acc: 0.728, F1: 0.666
| 2021-07-13 19:15:42 | INFO | Start epoch 5:
| 2021-07-13 19:15:43 | INFO | Train Loss: 0.422, tp: 13, fn: 10, fp: 6, tn: 35, Acc: 0.750, Prec: 0.684, Rec: 0.565, F1: 0.717
| 2021-07-13 19:16:55 | INFO | Validation tp: 172, fn: 194, fp: 76, tn: 559
| 2021-07-13 19:16:55 | INFO | Validation loss: 0.591, acc: 0.730, F1: 0.683
| 2021-07-13 19:16:55 | INFO | Start epoch 6:
| 2021-07-13 19:16:56 | INFO | Train Loss: 0.267, tp: 22, fn: 1, fp: 2, tn: 39, Acc: 0.953, Prec: 0.917, Rec: 0.957, F1: 0.950
| 2021-07-13 19:18:08 | INFO | Validation tp: 146, fn: 220, fp: 69, tn: 566
| 2021-07-13 19:18:08 | INFO | Validation loss: 0.799, acc: 0.711, F1: 0.650
| 2021-07-13 19:18:08 | INFO | Start epoch 7:
| 2021-07-13 19:18:08 | INFO | Train Loss: 0.234, tp: 24, fn: 3, fp: 1, tn: 36, Acc: 0.938, Prec: 0.960, Rec: 0.889, F1: 0.935
| 2021-07-13 19:19:21 | INFO | Validation tp: 149, fn: 217, fp: 71, tn: 564
| 2021-07-13 19:19:21 | INFO | Validation loss: 1.044, acc: 0.712, F1: 0.653
| 2021-07-13 19:19:21 | INFO | Start epoch 8:
| 2021-07-13 19:19:21 | INFO | Train Loss: 0.107, tp: 23, fn: 1, fp: 2, tn: 38, Acc: 0.953, Prec: 0.920, Rec: 0.958, F1: 0.950
| 2021-07-13 19:20:34 | INFO | Validation tp: 157, fn: 209, fp: 88, tn: 547
| 2021-07-13 19:20:34 | INFO | Validation loss: 1.018, acc: 0.703, F1: 0.650
| 2021-07-13 19:20:34 | INFO | Start epoch 9:
| 2021-07-13 19:20:34 | INFO | Train Loss: 0.102, tp: 21, fn: 1, fp: 2, tn: 40, Acc: 0.953, Prec: 0.913, Rec: 0.955, F1: 0.949
| 2021-07-13 19:21:47 | INFO | Validation tp: 164, fn: 202, fp: 87, tn: 548
| 2021-07-13 19:21:47 | INFO | Validation loss: 1.244, acc: 0.711, F1: 0.661
| 2021-07-13 19:21:47 | INFO | Start epoch 10:
| 2021-07-13 19:21:47 | INFO | Train Loss: 0.033, tp: 18, fn: 0, fp: 0, tn: 46, Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000
| 2021-07-13 19:23:00 | INFO | Validation tp: 167, fn: 199, fp: 87, tn: 548
| 2021-07-13 19:23:00 | INFO | Validation loss: 1.344, acc: 0.714, F1: 0.666
| 2021-07-13 19:23:01 | INFO | 
==============================Start training==============================
| 2021-07-13 19:23:01 | INFO | Command Line Args:   --lr 5e-5 --warmup_ratio 0.3 -c config/ende_at_least_one.conf
Config File (config/ende_at_least_one.conf):
  train_data:        wmt21_official_data/at_least_one_strategy/ende_atleastone_train.tsv
  valid_data:        wmt21_official_data/at_least_one_strategy/ende_atleastone_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
Defaults:
  --hidden_size:     256
  --ner:             False

| 2021-07-13 19:23:01 | INFO | 
lr: 5e-05

| 2021-07-13 19:23:10 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-13 19:23:10 | INFO | Start epoch 1:
| 2021-07-13 19:23:10 | INFO | Train Loss: 0.637, tp: 0, fn: 21, fp: 0, tn: 43, Acc: 0.672, Prec: 0.000, Rec: 0.000, F1: 0.402
| 2021-07-13 19:24:22 | INFO | Validation tp: 1, fn: 365, fp: 0, tn: 635
| 2021-07-13 19:24:22 | INFO | Validation loss: 0.633, acc: 0.635, F1: 0.391
| 2021-07-13 19:24:22 | INFO | Start epoch 2:
| 2021-07-13 19:24:23 | INFO | Train Loss: 0.648, tp: 3, fn: 23, fp: 2, tn: 36, Acc: 0.609, Prec: 0.600, Rec: 0.115, F1: 0.468
| 2021-07-13 19:25:35 | INFO | Validation tp: 139, fn: 227, fp: 55, tn: 580
| 2021-07-13 19:25:35 | INFO | Validation loss: 0.596, acc: 0.718, F1: 0.650
| 2021-07-13 19:25:35 | INFO | Start epoch 3:
| 2021-07-13 19:25:36 | INFO | Train Loss: 0.609, tp: 7, fn: 10, fp: 7, tn: 40, Acc: 0.734, Prec: 0.500, Rec: 0.412, F1: 0.638
| 2021-07-13 19:26:48 | INFO | Validation tp: 186, fn: 180, fp: 77, tn: 558
| 2021-07-13 19:26:48 | INFO | Validation loss: 0.557, acc: 0.743, F1: 0.702
| 2021-07-13 19:26:48 | INFO | Start epoch 4:
| 2021-07-13 19:26:49 | INFO | Train Loss: 0.513, tp: 16, fn: 9, fp: 5, tn: 34, Acc: 0.781, Prec: 0.762, Rec: 0.640, F1: 0.762
| 2021-07-13 19:28:01 | INFO | Validation tp: 163, fn: 203, fp: 56, tn: 579
| 2021-07-13 19:28:01 | INFO | Validation loss: 0.569, acc: 0.741, F1: 0.687
| 2021-07-13 19:28:01 | INFO | Start epoch 5:
| 2021-07-13 19:28:02 | INFO | Train Loss: 0.483, tp: 11, fn: 12, fp: 4, tn: 37, Acc: 0.750, Prec: 0.733, Rec: 0.478, F1: 0.701
| 2021-07-13 19:29:14 | INFO | Validation tp: 15, fn: 351, fp: 21, tn: 614
| 2021-07-13 19:29:14 | INFO | Validation loss: 0.659, acc: 0.628, F1: 0.421
| 2021-07-13 19:29:14 | INFO | Start epoch 6:
| 2021-07-13 19:29:15 | INFO | Train Loss: 0.647, tp: 4, fn: 19, fp: 2, tn: 39, Acc: 0.672, Prec: 0.667, Rec: 0.174, F1: 0.532
| 2021-07-13 19:30:27 | INFO | Validation tp: 71, fn: 295, fp: 47, tn: 588
| 2021-07-13 19:30:27 | INFO | Validation loss: 0.630, acc: 0.658, F1: 0.534
| 2021-07-13 19:30:27 | INFO | Start epoch 7:
| 2021-07-13 19:30:28 | INFO | Train Loss: 0.605, tp: 11, fn: 16, fp: 4, tn: 33, Acc: 0.688, Prec: 0.733, Rec: 0.407, F1: 0.646
| 2021-07-13 19:31:40 | INFO | Validation tp: 0, fn: 366, fp: 0, tn: 635
| 2021-07-13 19:31:40 | INFO | Validation loss: 0.657, acc: 0.634, F1: 0.388
| 2021-07-13 19:31:40 | INFO | Start epoch 8:
| 2021-07-13 19:31:40 | INFO | Train Loss: 0.653, tp: 0, fn: 24, fp: 0, tn: 40, Acc: 0.625, Prec: 0.000, Rec: 0.000, F1: 0.385
| 2021-07-13 19:32:53 | INFO | Validation tp: 0, fn: 366, fp: 0, tn: 635
| 2021-07-13 19:32:53 | INFO | Validation loss: 0.657, acc: 0.634, F1: 0.388
| 2021-07-13 19:32:53 | INFO | Start epoch 9:
| 2021-07-13 19:32:53 | INFO | Train Loss: 0.645, tp: 0, fn: 22, fp: 0, tn: 42, Acc: 0.656, Prec: 0.000, Rec: 0.000, F1: 0.396
| 2021-07-13 19:34:06 | INFO | Validation tp: 0, fn: 366, fp: 0, tn: 635
| 2021-07-13 19:34:06 | INFO | Validation loss: 0.657, acc: 0.634, F1: 0.388
| 2021-07-13 19:34:06 | INFO | Start epoch 10:
| 2021-07-13 19:34:06 | INFO | Train Loss: 0.607, tp: 0, fn: 18, fp: 0, tn: 46, Acc: 0.719, Prec: 0.000, Rec: 0.000, F1: 0.418
| 2021-07-13 19:35:19 | INFO | Validation tp: 0, fn: 366, fp: 0, tn: 635
| 2021-07-13 19:35:19 | INFO | Validation loss: 0.657, acc: 0.634, F1: 0.388
