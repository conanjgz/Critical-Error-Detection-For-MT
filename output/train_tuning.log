| 2021-07-08 17:28:59 | INFO | ==============================Start training==============================
| 2021-07-08 17:28:59 | INFO | Command Line Args:   -c config/enzh.conf
Config File (config/enzh.conf):
  train_data:        wmt21_official_data/enzh_majority_train.tsv
  valid_data:        wmt21_official_data/enzh_majority_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
  lr:                2e-5
Defaults:
  --hidden_size:     256

| 2021-07-08 17:29:11 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-08 17:29:11 | INFO | Start epoch 1:
| 2021-07-08 17:29:12 | INFO | Train Loss: 0.566, tp: 0, fn: 11, fp: 0, tn: 53, Acc: 0.828, Prec: 0.000, Rec: 0.000, F1: 0.453
| 2021-07-08 17:30:13 | INFO | Validation tp: 0, fn: 141, fp: 0, tn: 859
| 2021-07-08 17:30:13 | INFO | Validation loss: 0.608, acc: 0.859, F1: 0.462
| 2021-07-08 17:30:13 | INFO | Start epoch 2:
| 2021-07-08 17:30:13 | INFO | Train Loss: 0.459, tp: 0, fn: 11, fp: 0, tn: 53, Acc: 0.828, Prec: 0.000, Rec: 0.000, F1: 0.453
| 2021-07-08 17:31:15 | INFO | Validation tp: 0, fn: 141, fp: 0, tn: 859
| 2021-07-08 17:31:15 | INFO | Validation loss: 0.448, acc: 0.859, F1: 0.462
| 2021-07-08 17:31:15 | INFO | Start epoch 3:
| 2021-07-08 17:31:16 | INFO | Train Loss: 0.424, tp: 0, fn: 11, fp: 0, tn: 53, Acc: 0.828, Prec: 0.000, Rec: 0.000, F1: 0.453
| 2021-07-08 17:32:18 | INFO | Validation tp: 0, fn: 141, fp: 0, tn: 859
| 2021-07-08 17:32:18 | INFO | Validation loss: 0.326, acc: 0.859, F1: 0.462
| 2021-07-08 17:32:18 | INFO | Start epoch 4:
| 2021-07-08 17:32:19 | INFO | Train Loss: 0.351, tp: 0, fn: 8, fp: 1, tn: 55, Acc: 0.859, Prec: 0.000, Rec: 0.000, F1: 0.462
| 2021-07-08 17:33:21 | INFO | Validation tp: 0, fn: 141, fp: 0, tn: 859
| 2021-07-08 17:33:21 | INFO | Validation loss: 0.315, acc: 0.859, F1: 0.462
| 2021-07-08 17:33:21 | INFO | Start epoch 5:
| 2021-07-08 17:33:22 | INFO | Train Loss: 0.524, tp: 0, fn: 15, fp: 0, tn: 49, Acc: 0.766, Prec: 0.000, Rec: 0.000, F1: 0.434
| 2021-07-08 17:34:24 | INFO | Validation tp: 27, fn: 114, fp: 28, tn: 831
| 2021-07-08 17:34:24 | INFO | Validation loss: 0.145, acc: 0.858, F1: 0.598
| 2021-07-08 17:34:24 | INFO | Start epoch 6:
| 2021-07-08 17:34:24 | INFO | Train Loss: 0.450, tp: 3, fn: 11, fp: 2, tn: 48, Acc: 0.797, Prec: 0.600, Rec: 0.214, F1: 0.598
| 2021-07-08 17:35:27 | INFO | Validation tp: 35, fn: 106, fp: 51, tn: 808
| 2021-07-08 17:35:27 | INFO | Validation loss: 0.106, acc: 0.843, F1: 0.610
| 2021-07-08 17:35:27 | INFO | Start epoch 7:
| 2021-07-08 17:35:27 | INFO | Train Loss: 0.234, tp: 3, fn: 3, fp: 4, tn: 54, Acc: 0.891, Prec: 0.429, Rec: 0.500, F1: 0.700
| 2021-07-08 17:36:29 | INFO | Validation tp: 51, fn: 90, fp: 84, tn: 775
| 2021-07-08 17:36:29 | INFO | Validation loss: 0.163, acc: 0.826, F1: 0.634
| 2021-07-08 17:36:29 | INFO | Start epoch 8:
| 2021-07-08 17:36:30 | INFO | Train Loss: 0.362, tp: 6, fn: 3, fp: 6, tn: 49, Acc: 0.859, Prec: 0.500, Rec: 0.667, F1: 0.744
| 2021-07-08 17:37:32 | INFO | Validation tp: 30, fn: 111, fp: 36, tn: 823
| 2021-07-08 17:37:32 | INFO | Validation loss: 0.278, acc: 0.853, F1: 0.604
| 2021-07-08 17:37:32 | INFO | Start epoch 9:
| 2021-07-08 17:37:33 | INFO | Train Loss: 0.171, tp: 6, fn: 1, fp: 1, tn: 56, Acc: 0.969, Prec: 0.857, Rec: 0.857, F1: 0.920
| 2021-07-08 17:38:35 | INFO | Validation tp: 28, fn: 113, fp: 48, tn: 811
| 2021-07-08 17:38:35 | INFO | Validation loss: 0.153, acc: 0.839, F1: 0.584
| 2021-07-08 17:38:35 | INFO | Start epoch 10:
| 2021-07-08 17:38:36 | INFO | Train Loss: 0.121, tp: 9, fn: 2, fp: 1, tn: 52, Acc: 0.953, Prec: 0.900, Rec: 0.818, F1: 0.915
| 2021-07-08 17:39:38 | INFO | Validation tp: 33, fn: 108, fp: 57, tn: 802
| 2021-07-08 17:39:38 | INFO | Validation loss: 0.200, acc: 0.835, F1: 0.596
| 2021-07-08 17:39:40 | INFO | ==============================Start training==============================
| 2021-07-08 17:39:40 | INFO | Command Line Args:   -c config/enzh2.conf
Config File (config/enzh2.conf):
  train_data:        wmt21_official_data/enzh_majority_train.tsv
  valid_data:        wmt21_official_data/enzh_majority_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
  lr:                3e-5
Defaults:
  --hidden_size:     256

| 2021-07-08 17:39:52 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-08 17:39:52 | INFO | Start epoch 1:
| 2021-07-08 17:39:52 | INFO | Train Loss: 0.566, tp: 0, fn: 11, fp: 0, tn: 53, Acc: 0.828, Prec: 0.000, Rec: 0.000, F1: 0.453
| 2021-07-08 17:40:54 | INFO | Validation tp: 0, fn: 141, fp: 0, tn: 859
| 2021-07-08 17:40:54 | INFO | Validation loss: 0.463, acc: 0.859, F1: 0.462
| 2021-07-08 17:40:54 | INFO | Start epoch 2:
| 2021-07-08 17:40:55 | INFO | Train Loss: 0.469, tp: 0, fn: 11, fp: 0, tn: 53, Acc: 0.828, Prec: 0.000, Rec: 0.000, F1: 0.453
| 2021-07-08 17:41:57 | INFO | Validation tp: 0, fn: 141, fp: 0, tn: 859
| 2021-07-08 17:41:57 | INFO | Validation loss: 0.396, acc: 0.859, F1: 0.462
| 2021-07-08 17:41:57 | INFO | Start epoch 3:
| 2021-07-08 17:41:58 | INFO | Train Loss: 0.427, tp: 0, fn: 11, fp: 0, tn: 53, Acc: 0.828, Prec: 0.000, Rec: 0.000, F1: 0.453
| 2021-07-08 17:43:00 | INFO | Validation tp: 0, fn: 141, fp: 0, tn: 859
| 2021-07-08 17:43:00 | INFO | Validation loss: 0.294, acc: 0.859, F1: 0.462
| 2021-07-08 17:43:00 | INFO | Start epoch 4:
| 2021-07-08 17:43:01 | INFO | Train Loss: 0.343, tp: 1, fn: 7, fp: 2, tn: 54, Acc: 0.859, Prec: 0.333, Rec: 0.125, F1: 0.552
| 2021-07-08 17:44:03 | INFO | Validation tp: 0, fn: 141, fp: 0, tn: 859
| 2021-07-08 17:44:03 | INFO | Validation loss: 0.257, acc: 0.859, F1: 0.462
| 2021-07-08 17:44:03 | INFO | Start epoch 5:
| 2021-07-08 17:44:04 | INFO | Train Loss: 0.433, tp: 1, fn: 14, fp: 0, tn: 49, Acc: 0.781, Prec: 1.000, Rec: 0.067, F1: 0.500
| 2021-07-08 17:45:06 | INFO | Validation tp: 19, fn: 122, fp: 24, tn: 835
| 2021-07-08 17:45:06 | INFO | Validation loss: 0.289, acc: 0.854, F1: 0.563
| 2021-07-08 17:45:06 | INFO | Start epoch 6:
| 2021-07-08 17:45:06 | INFO | Train Loss: 0.431, tp: 4, fn: 10, fp: 2, tn: 48, Acc: 0.812, Prec: 0.667, Rec: 0.286, F1: 0.644
| 2021-07-08 17:46:09 | INFO | Validation tp: 44, fn: 97, fp: 74, tn: 785
| 2021-07-08 17:46:09 | INFO | Validation loss: 0.123, acc: 0.829, F1: 0.621
| 2021-07-08 17:46:09 | INFO | Start epoch 7:
| 2021-07-08 17:46:09 | INFO | Train Loss: 0.177, tp: 4, fn: 2, fp: 3, tn: 55, Acc: 0.922, Prec: 0.571, Rec: 0.667, F1: 0.786
| 2021-07-08 17:47:12 | INFO | Validation tp: 44, fn: 97, fp: 91, tn: 768
| 2021-07-08 17:47:12 | INFO | Validation loss: 0.192, acc: 0.812, F1: 0.605
| 2021-07-08 17:47:12 | INFO | Start epoch 8:
| 2021-07-08 17:47:12 | INFO | Train Loss: 0.176, tp: 9, fn: 0, fp: 5, tn: 50, Acc: 0.922, Prec: 0.643, Rec: 1.000, F1: 0.867
| 2021-07-08 17:48:15 | INFO | Validation tp: 25, fn: 116, fp: 50, tn: 809
| 2021-07-08 17:48:15 | INFO | Validation loss: 0.409, acc: 0.834, F1: 0.569
| 2021-07-08 17:48:15 | INFO | Start epoch 9:
| 2021-07-08 17:48:15 | INFO | Train Loss: 0.096, tp: 6, fn: 1, fp: 1, tn: 56, Acc: 0.969, Prec: 0.857, Rec: 0.857, F1: 0.920
| 2021-07-08 17:49:17 | INFO | Validation tp: 23, fn: 118, fp: 38, tn: 821
| 2021-07-08 17:49:17 | INFO | Validation loss: 0.599, acc: 0.844, F1: 0.570
| 2021-07-08 17:49:17 | INFO | Start epoch 10:
| 2021-07-08 17:49:18 | INFO | Train Loss: 0.037, tp: 11, fn: 0, fp: 0, tn: 53, Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000
| 2021-07-08 17:50:20 | INFO | Validation tp: 26, fn: 115, fp: 56, tn: 803
| 2021-07-08 17:50:20 | INFO | Validation loss: 0.634, acc: 0.829, F1: 0.568
| 2021-07-08 17:50:22 | INFO | ==============================Start training==============================
| 2021-07-08 17:50:22 | INFO | Command Line Args:   -c config/enzh3.conf
Config File (config/enzh3.conf):
  train_data:        wmt21_official_data/enzh_majority_train.tsv
  valid_data:        wmt21_official_data/enzh_majority_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
  lr:                4e-5
Defaults:
  --hidden_size:     256

| 2021-07-08 17:50:34 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-08 17:50:34 | INFO | Start epoch 1:
| 2021-07-08 17:50:34 | INFO | Train Loss: 0.566, tp: 0, fn: 11, fp: 0, tn: 53, Acc: 0.828, Prec: 0.000, Rec: 0.000, F1: 0.453
| 2021-07-08 17:51:36 | INFO | Validation tp: 0, fn: 141, fp: 0, tn: 859
| 2021-07-08 17:51:36 | INFO | Validation loss: 0.486, acc: 0.859, F1: 0.462
| 2021-07-08 17:51:36 | INFO | Start epoch 2:
| 2021-07-08 17:51:37 | INFO | Train Loss: 0.439, tp: 0, fn: 11, fp: 0, tn: 53, Acc: 0.828, Prec: 0.000, Rec: 0.000, F1: 0.453
| 2021-07-08 17:52:39 | INFO | Validation tp: 26, fn: 115, fp: 28, tn: 831
| 2021-07-08 17:52:39 | INFO | Validation loss: 0.216, acc: 0.857, F1: 0.594
| 2021-07-08 17:52:39 | INFO | Start epoch 3:
| 2021-07-08 17:52:40 | INFO | Train Loss: 0.419, tp: 0, fn: 11, fp: 1, tn: 52, Acc: 0.812, Prec: 0.000, Rec: 0.000, F1: 0.448
| 2021-07-08 17:53:42 | INFO | Validation tp: 0, fn: 141, fp: 0, tn: 859
| 2021-07-08 17:53:42 | INFO | Validation loss: 0.348, acc: 0.859, F1: 0.462
| 2021-07-08 17:53:42 | INFO | Start epoch 4:
| 2021-07-08 17:53:42 | INFO | Train Loss: 0.326, tp: 0, fn: 8, fp: 0, tn: 56, Acc: 0.875, Prec: 0.000, Rec: 0.000, F1: 0.467
| 2021-07-08 17:54:45 | INFO | Validation tp: 0, fn: 141, fp: 0, tn: 859
| 2021-07-08 17:54:45 | INFO | Validation loss: 0.243, acc: 0.859, F1: 0.462
| 2021-07-08 17:54:45 | INFO | Start epoch 5:
| 2021-07-08 17:54:45 | INFO | Train Loss: 0.484, tp: 2, fn: 13, fp: 0, tn: 49, Acc: 0.797, Prec: 1.000, Rec: 0.133, F1: 0.559
| 2021-07-08 17:55:48 | INFO | Validation tp: 9, fn: 132, fp: 15, tn: 844
| 2021-07-08 17:55:48 | INFO | Validation loss: 0.180, acc: 0.853, F1: 0.514
| 2021-07-08 17:55:48 | INFO | Start epoch 6:
| 2021-07-08 17:55:48 | INFO | Train Loss: 0.440, tp: 2, fn: 12, fp: 1, tn: 49, Acc: 0.797, Prec: 0.667, Rec: 0.143, F1: 0.559
| 2021-07-08 17:56:50 | INFO | Validation tp: 32, fn: 109, fp: 53, tn: 806
| 2021-07-08 17:56:50 | INFO | Validation loss: 0.114, acc: 0.838, F1: 0.596
| 2021-07-08 17:56:50 | INFO | Start epoch 7:
| 2021-07-08 17:56:51 | INFO | Train Loss: 0.225, tp: 3, fn: 3, fp: 2, tn: 56, Acc: 0.922, Prec: 0.600, Rec: 0.500, F1: 0.751
| 2021-07-08 17:57:53 | INFO | Validation tp: 40, fn: 101, fp: 88, tn: 771
| 2021-07-08 17:57:53 | INFO | Validation loss: 0.072, acc: 0.811, F1: 0.594
| 2021-07-08 17:57:53 | INFO | Start epoch 8:
| 2021-07-08 17:57:54 | INFO | Train Loss: 0.156, tp: 8, fn: 1, fp: 3, tn: 52, Acc: 0.938, Prec: 0.727, Rec: 0.889, F1: 0.881
| 2021-07-08 17:58:56 | INFO | Validation tp: 28, fn: 113, fp: 50, tn: 809
| 2021-07-08 17:58:56 | INFO | Validation loss: 0.158, acc: 0.837, F1: 0.582
| 2021-07-08 17:58:56 | INFO | Start epoch 9:
| 2021-07-08 17:58:57 | INFO | Train Loss: 0.138, tp: 5, fn: 2, fp: 0, tn: 57, Acc: 0.969, Prec: 1.000, Rec: 0.714, F1: 0.908
| 2021-07-08 17:59:59 | INFO | Validation tp: 20, fn: 121, fp: 47, tn: 812
| 2021-07-08 17:59:59 | INFO | Validation loss: 0.182, acc: 0.832, F1: 0.549
| 2021-07-08 17:59:59 | INFO | Start epoch 10:
| 2021-07-08 18:00:00 | INFO | Train Loss: 0.169, tp: 8, fn: 3, fp: 0, tn: 53, Acc: 0.953, Prec: 1.000, Rec: 0.727, F1: 0.907
| 2021-07-08 18:01:02 | INFO | Validation tp: 31, fn: 110, fp: 58, tn: 801
| 2021-07-08 18:01:02 | INFO | Validation loss: 0.135, acc: 0.832, F1: 0.587
| 2021-07-08 18:01:04 | INFO | ==============================Start training==============================
| 2021-07-08 18:01:04 | INFO | Command Line Args:   -c config/enzh4.conf
Config File (config/enzh4.conf):
  train_data:        wmt21_official_data/enzh_majority_train.tsv
  valid_data:        wmt21_official_data/enzh_majority_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
  lr:                5e-5
Defaults:
  --hidden_size:     256

| 2021-07-08 18:01:15 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-08 18:01:15 | INFO | Start epoch 1:
| 2021-07-08 18:01:16 | INFO | Train Loss: 0.566, tp: 0, fn: 11, fp: 0, tn: 53, Acc: 0.828, Prec: 0.000, Rec: 0.000, F1: 0.453
| 2021-07-08 18:02:18 | INFO | Validation tp: 0, fn: 141, fp: 0, tn: 859
| 2021-07-08 18:02:18 | INFO | Validation loss: 0.518, acc: 0.859, F1: 0.462
| 2021-07-08 18:02:18 | INFO | Start epoch 2:
| 2021-07-08 18:02:19 | INFO | Train Loss: 0.429, tp: 0, fn: 11, fp: 0, tn: 53, Acc: 0.828, Prec: 0.000, Rec: 0.000, F1: 0.453
| 2021-07-08 18:03:21 | INFO | Validation tp: 0, fn: 141, fp: 0, tn: 859
| 2021-07-08 18:03:21 | INFO | Validation loss: 0.305, acc: 0.859, F1: 0.462
| 2021-07-08 18:03:21 | INFO | Start epoch 3:
| 2021-07-08 18:03:22 | INFO | Train Loss: 0.410, tp: 0, fn: 11, fp: 0, tn: 53, Acc: 0.828, Prec: 0.000, Rec: 0.000, F1: 0.453
| 2021-07-08 18:04:24 | INFO | Validation tp: 0, fn: 141, fp: 0, tn: 859
| 2021-07-08 18:04:24 | INFO | Validation loss: 0.342, acc: 0.859, F1: 0.462
| 2021-07-08 18:04:24 | INFO | Start epoch 4:
| 2021-07-08 18:04:25 | INFO | Train Loss: 0.345, tp: 0, fn: 8, fp: 0, tn: 56, Acc: 0.875, Prec: 0.000, Rec: 0.000, F1: 0.467
| 2021-07-08 18:05:27 | INFO | Validation tp: 0, fn: 141, fp: 0, tn: 859
| 2021-07-08 18:05:27 | INFO | Validation loss: 0.303, acc: 0.859, F1: 0.462
| 2021-07-08 18:05:27 | INFO | Start epoch 5:
| 2021-07-08 18:05:28 | INFO | Train Loss: 0.452, tp: 0, fn: 15, fp: 0, tn: 49, Acc: 0.766, Prec: 0.000, Rec: 0.000, F1: 0.434
| 2021-07-08 18:06:30 | INFO | Validation tp: 9, fn: 132, fp: 12, tn: 847
| 2021-07-08 18:06:30 | INFO | Validation loss: 0.188, acc: 0.856, F1: 0.516
| 2021-07-08 18:06:30 | INFO | Start epoch 6:
| 2021-07-08 18:06:30 | INFO | Train Loss: 0.332, tp: 3, fn: 11, fp: 0, tn: 50, Acc: 0.828, Prec: 1.000, Rec: 0.214, F1: 0.627
| 2021-07-08 18:07:33 | INFO | Validation tp: 33, fn: 108, fp: 45, tn: 814
| 2021-07-08 18:07:33 | INFO | Validation loss: 0.460, acc: 0.847, F1: 0.608
| 2021-07-08 18:07:33 | INFO | Start epoch 7:
| 2021-07-08 18:07:33 | INFO | Train Loss: 0.188, tp: 4, fn: 2, fp: 2, tn: 56, Acc: 0.938, Prec: 0.667, Rec: 0.667, F1: 0.816
| 2021-07-08 18:08:35 | INFO | Validation tp: 45, fn: 96, fp: 71, tn: 788
| 2021-07-08 18:08:35 | INFO | Validation loss: 0.108, acc: 0.833, F1: 0.627
| 2021-07-08 18:08:35 | INFO | Start epoch 8:
| 2021-07-08 18:08:36 | INFO | Train Loss: 0.254, tp: 8, fn: 1, fp: 6, tn: 49, Acc: 0.891, Prec: 0.571, Rec: 0.889, F1: 0.814
| 2021-07-08 18:09:38 | INFO | Validation tp: 34, fn: 107, fp: 42, tn: 817
| 2021-07-08 18:09:38 | INFO | Validation loss: 0.501, acc: 0.851, F1: 0.615
| 2021-07-08 18:09:38 | INFO | Start epoch 9:
| 2021-07-08 18:09:39 | INFO | Train Loss: 0.049, tp: 6, fn: 1, fp: 1, tn: 56, Acc: 0.969, Prec: 0.857, Rec: 0.857, F1: 0.920
| 2021-07-08 18:10:41 | INFO | Validation tp: 25, fn: 116, fp: 39, tn: 820
| 2021-07-08 18:10:41 | INFO | Validation loss: 0.499, acc: 0.845, F1: 0.579
| 2021-07-08 18:10:41 | INFO | Start epoch 10:
| 2021-07-08 18:10:42 | INFO | Train Loss: 0.166, tp: 8, fn: 3, fp: 1, tn: 52, Acc: 0.938, Prec: 0.889, Rec: 0.727, F1: 0.881
| 2021-07-08 18:11:44 | INFO | Validation tp: 26, fn: 115, fp: 41, tn: 818
| 2021-07-08 18:11:44 | INFO | Validation loss: 0.440, acc: 0.844, F1: 0.581
| 2021-07-08 18:11:46 | INFO | ==============================Start training==============================
| 2021-07-08 18:11:46 | INFO | Command Line Args:   -c config/enja.conf
Config File (config/enja.conf):
  train_data:        wmt21_official_data/enja_majority_train.tsv
  valid_data:        wmt21_official_data/enja_majority_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
  lr:                2e-5
Defaults:
  --hidden_size:     256

| 2021-07-08 18:11:58 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-08 18:11:58 | INFO | Start epoch 1:
| 2021-07-08 18:11:58 | INFO | Train Loss: 0.602, tp: 0, fn: 13, fp: 0, tn: 51, Acc: 0.797, Prec: 0.000, Rec: 0.000, F1: 0.443
| 2021-07-08 18:13:07 | INFO | Validation tp: 0, fn: 96, fp: 0, tn: 904
| 2021-07-08 18:13:07 | INFO | Validation loss: 0.562, acc: 0.904, F1: 0.475
| 2021-07-08 18:13:07 | INFO | Start epoch 2:
| 2021-07-08 18:13:08 | INFO | Train Loss: 0.221, tp: 0, fn: 3, fp: 0, tn: 61, Acc: 0.953, Prec: 0.000, Rec: 0.000, F1: 0.488
| 2021-07-08 18:14:17 | INFO | Validation tp: 0, fn: 96, fp: 0, tn: 904
| 2021-07-08 18:14:17 | INFO | Validation loss: 0.722, acc: 0.904, F1: 0.475
| 2021-07-08 18:14:17 | INFO | Start epoch 3:
| 2021-07-08 18:14:18 | INFO | Train Loss: 0.294, tp: 0, fn: 5, fp: 0, tn: 59, Acc: 0.922, Prec: 0.000, Rec: 0.000, F1: 0.480
| 2021-07-08 18:15:28 | INFO | Validation tp: 0, fn: 96, fp: 1, tn: 903
| 2021-07-08 18:15:28 | INFO | Validation loss: 0.397, acc: 0.903, F1: 0.475
| 2021-07-08 18:15:28 | INFO | Start epoch 4:
| 2021-07-08 18:15:28 | INFO | Train Loss: 0.516, tp: 0, fn: 12, fp: 0, tn: 52, Acc: 0.812, Prec: 0.000, Rec: 0.000, F1: 0.448
| 2021-07-08 18:16:38 | INFO | Validation tp: 0, fn: 96, fp: 0, tn: 904
| 2021-07-08 18:16:38 | INFO | Validation loss: 0.431, acc: 0.904, F1: 0.475
| 2021-07-08 18:16:38 | INFO | Start epoch 5:
| 2021-07-08 18:16:38 | INFO | Train Loss: 0.214, tp: 0, fn: 4, fp: 0, tn: 60, Acc: 0.938, Prec: 0.000, Rec: 0.000, F1: 0.484
| 2021-07-08 18:17:48 | INFO | Validation tp: 0, fn: 96, fp: 0, tn: 904
| 2021-07-08 18:17:48 | INFO | Validation loss: 0.418, acc: 0.904, F1: 0.475
| 2021-07-08 18:17:48 | INFO | Start epoch 6:
| 2021-07-08 18:17:48 | INFO | Train Loss: 0.149, tp: 0, fn: 1, fp: 0, tn: 63, Acc: 0.984, Prec: 0.000, Rec: 0.000, F1: 0.496
| 2021-07-08 18:18:58 | INFO | Validation tp: 6, fn: 90, fp: 5, tn: 899
| 2021-07-08 18:18:58 | INFO | Validation loss: 0.366, acc: 0.905, F1: 0.531
| 2021-07-08 18:18:58 | INFO | Start epoch 7:
| 2021-07-08 18:18:58 | INFO | Train Loss: 0.164, tp: 2, fn: 2, fp: 1, tn: 59, Acc: 0.953, Prec: 0.667, Rec: 0.500, F1: 0.773
| 2021-07-08 18:20:08 | INFO | Validation tp: 10, fn: 86, fp: 16, tn: 888
| 2021-07-08 18:20:08 | INFO | Validation loss: 0.411, acc: 0.898, F1: 0.555
| 2021-07-08 18:20:08 | INFO | Start epoch 8:
| 2021-07-08 18:20:08 | INFO | Train Loss: 0.259, tp: 4, fn: 6, fp: 2, tn: 52, Acc: 0.875, Prec: 0.667, Rec: 0.400, F1: 0.714
| 2021-07-08 18:21:18 | INFO | Validation tp: 7, fn: 89, fp: 6, tn: 898
| 2021-07-08 18:21:18 | INFO | Validation loss: 0.433, acc: 0.905, F1: 0.539
| 2021-07-08 18:21:18 | INFO | Start epoch 9:
| 2021-07-08 18:21:18 | INFO | Train Loss: 0.132, tp: 1, fn: 2, fp: 0, tn: 61, Acc: 0.969, Prec: 1.000, Rec: 0.333, F1: 0.742
| 2021-07-08 18:22:28 | INFO | Validation tp: 11, fn: 85, fp: 33, tn: 871
| 2021-07-08 18:22:28 | INFO | Validation loss: 0.478, acc: 0.882, F1: 0.547
| 2021-07-08 18:22:28 | INFO | Start epoch 10:
| 2021-07-08 18:22:29 | INFO | Train Loss: 0.070, tp: 5, fn: 1, fp: 0, tn: 58, Acc: 0.984, Prec: 1.000, Rec: 0.833, F1: 0.950
| 2021-07-08 18:23:38 | INFO | Validation tp: 11, fn: 85, fp: 26, tn: 878
| 2021-07-08 18:23:38 | INFO | Validation loss: 0.501, acc: 0.889, F1: 0.553
| 2021-07-08 18:23:40 | INFO | ==============================Start training==============================
| 2021-07-08 18:23:40 | INFO | Command Line Args:   -c config/enja2.conf
Config File (config/enja2.conf):
  train_data:        wmt21_official_data/enja_majority_train.tsv
  valid_data:        wmt21_official_data/enja_majority_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
  lr:                3e-5
Defaults:
  --hidden_size:     256

| 2021-07-08 18:23:52 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-08 18:23:52 | INFO | Start epoch 1:
| 2021-07-08 18:23:52 | INFO | Train Loss: 0.602, tp: 0, fn: 13, fp: 0, tn: 51, Acc: 0.797, Prec: 0.000, Rec: 0.000, F1: 0.443
| 2021-07-08 18:25:01 | INFO | Validation tp: 0, fn: 96, fp: 0, tn: 904
| 2021-07-08 18:25:01 | INFO | Validation loss: 0.598, acc: 0.904, F1: 0.475
| 2021-07-08 18:25:01 | INFO | Start epoch 2:
| 2021-07-08 18:25:02 | INFO | Train Loss: 0.191, tp: 0, fn: 3, fp: 0, tn: 61, Acc: 0.953, Prec: 0.000, Rec: 0.000, F1: 0.488
| 2021-07-08 18:26:12 | INFO | Validation tp: 0, fn: 96, fp: 0, tn: 904
| 2021-07-08 18:26:12 | INFO | Validation loss: 0.688, acc: 0.904, F1: 0.475
| 2021-07-08 18:26:12 | INFO | Start epoch 3:
| 2021-07-08 18:26:12 | INFO | Train Loss: 0.298, tp: 0, fn: 5, fp: 0, tn: 59, Acc: 0.922, Prec: 0.000, Rec: 0.000, F1: 0.480
| 2021-07-08 18:27:22 | INFO | Validation tp: 0, fn: 96, fp: 0, tn: 904
| 2021-07-08 18:27:22 | INFO | Validation loss: 0.584, acc: 0.904, F1: 0.475
| 2021-07-08 18:27:22 | INFO | Start epoch 4:
| 2021-07-08 18:27:22 | INFO | Train Loss: 0.491, tp: 0, fn: 12, fp: 0, tn: 52, Acc: 0.812, Prec: 0.000, Rec: 0.000, F1: 0.448
| 2021-07-08 18:28:32 | INFO | Validation tp: 0, fn: 96, fp: 0, tn: 904
| 2021-07-08 18:28:32 | INFO | Validation loss: 0.471, acc: 0.904, F1: 0.475
| 2021-07-08 18:28:32 | INFO | Start epoch 5:
| 2021-07-08 18:28:32 | INFO | Train Loss: 0.238, tp: 0, fn: 4, fp: 0, tn: 60, Acc: 0.938, Prec: 0.000, Rec: 0.000, F1: 0.484
| 2021-07-08 18:29:42 | INFO | Validation tp: 0, fn: 96, fp: 0, tn: 904
| 2021-07-08 18:29:42 | INFO | Validation loss: 0.433, acc: 0.904, F1: 0.475
| 2021-07-08 18:29:42 | INFO | Start epoch 6:
| 2021-07-08 18:29:42 | INFO | Train Loss: 0.135, tp: 0, fn: 1, fp: 0, tn: 63, Acc: 0.984, Prec: 0.000, Rec: 0.000, F1: 0.496
| 2021-07-08 18:30:52 | INFO | Validation tp: 0, fn: 96, fp: 0, tn: 904
| 2021-07-08 18:30:52 | INFO | Validation loss: 0.336, acc: 0.904, F1: 0.475
| 2021-07-08 18:30:52 | INFO | Start epoch 7:
| 2021-07-08 18:30:52 | INFO | Train Loss: 0.174, tp: 0, fn: 4, fp: 0, tn: 60, Acc: 0.938, Prec: 0.000, Rec: 0.000, F1: 0.484
| 2021-07-08 18:32:02 | INFO | Validation tp: 8, fn: 88, fp: 7, tn: 897
| 2021-07-08 18:32:02 | INFO | Validation loss: 0.318, acc: 0.905, F1: 0.547
| 2021-07-08 18:32:02 | INFO | Start epoch 8:
| 2021-07-08 18:32:03 | INFO | Train Loss: 0.254, tp: 3, fn: 7, fp: 0, tn: 54, Acc: 0.891, Prec: 1.000, Rec: 0.300, F1: 0.700
| 2021-07-08 18:33:12 | INFO | Validation tp: 18, fn: 78, fp: 39, tn: 865
| 2021-07-08 18:33:12 | INFO | Validation loss: 0.182, acc: 0.883, F1: 0.586
| 2021-07-08 18:33:12 | INFO | Start epoch 9:
| 2021-07-08 18:33:13 | INFO | Train Loss: 0.070, tp: 3, fn: 0, fp: 0, tn: 61, Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000
| 2021-07-08 18:34:22 | INFO | Validation tp: 19, fn: 77, fp: 44, tn: 860
| 2021-07-08 18:34:22 | INFO | Validation loss: 0.220, acc: 0.879, F1: 0.587
| 2021-07-08 18:34:22 | INFO | Start epoch 10:
| 2021-07-08 18:34:23 | INFO | Train Loss: 0.120, tp: 4, fn: 2, fp: 1, tn: 57, Acc: 0.953, Prec: 0.800, Rec: 0.667, F1: 0.851
| 2021-07-08 18:35:33 | INFO | Validation tp: 19, fn: 77, fp: 59, tn: 845
| 2021-07-08 18:35:33 | INFO | Validation loss: 0.235, acc: 0.864, F1: 0.572
| 2021-07-08 18:35:34 | INFO | ==============================Start training==============================
| 2021-07-08 18:35:34 | INFO | Command Line Args:   -c config/enja3.conf
Config File (config/enja3.conf):
  train_data:        wmt21_official_data/enja_majority_train.tsv
  valid_data:        wmt21_official_data/enja_majority_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
  lr:                4e-5
Defaults:
  --hidden_size:     256

| 2021-07-08 18:35:46 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-08 18:35:46 | INFO | Start epoch 1:
| 2021-07-08 18:35:47 | INFO | Train Loss: 0.602, tp: 0, fn: 13, fp: 0, tn: 51, Acc: 0.797, Prec: 0.000, Rec: 0.000, F1: 0.443
| 2021-07-08 18:36:56 | INFO | Validation tp: 0, fn: 96, fp: 0, tn: 904
| 2021-07-08 18:36:56 | INFO | Validation loss: 0.586, acc: 0.904, F1: 0.475
| 2021-07-08 18:36:56 | INFO | Start epoch 2:
| 2021-07-08 18:36:56 | INFO | Train Loss: 0.187, tp: 0, fn: 3, fp: 0, tn: 61, Acc: 0.953, Prec: 0.000, Rec: 0.000, F1: 0.488
| 2021-07-08 18:38:06 | INFO | Validation tp: 0, fn: 96, fp: 0, tn: 904
| 2021-07-08 18:38:06 | INFO | Validation loss: 0.497, acc: 0.904, F1: 0.475
| 2021-07-08 18:38:06 | INFO | Start epoch 3:
| 2021-07-08 18:38:07 | INFO | Train Loss: 0.267, tp: 0, fn: 5, fp: 0, tn: 59, Acc: 0.922, Prec: 0.000, Rec: 0.000, F1: 0.480
| 2021-07-08 18:39:16 | INFO | Validation tp: 0, fn: 96, fp: 0, tn: 904
| 2021-07-08 18:39:16 | INFO | Validation loss: 0.400, acc: 0.904, F1: 0.475
| 2021-07-08 18:39:16 | INFO | Start epoch 4:
| 2021-07-08 18:39:17 | INFO | Train Loss: 0.426, tp: 0, fn: 12, fp: 0, tn: 52, Acc: 0.812, Prec: 0.000, Rec: 0.000, F1: 0.448
| 2021-07-08 18:40:26 | INFO | Validation tp: 0, fn: 96, fp: 0, tn: 904
| 2021-07-08 18:40:26 | INFO | Validation loss: 0.369, acc: 0.904, F1: 0.475
| 2021-07-08 18:40:26 | INFO | Start epoch 5:
| 2021-07-08 18:40:27 | INFO | Train Loss: 0.218, tp: 0, fn: 4, fp: 0, tn: 60, Acc: 0.938, Prec: 0.000, Rec: 0.000, F1: 0.484
| 2021-07-08 18:41:36 | INFO | Validation tp: 0, fn: 96, fp: 0, tn: 904
| 2021-07-08 18:41:36 | INFO | Validation loss: 0.345, acc: 0.904, F1: 0.475
| 2021-07-08 18:41:36 | INFO | Start epoch 6:
| 2021-07-08 18:41:37 | INFO | Train Loss: 0.112, tp: 0, fn: 1, fp: 0, tn: 63, Acc: 0.984, Prec: 0.000, Rec: 0.000, F1: 0.496
| 2021-07-08 18:42:46 | INFO | Validation tp: 4, fn: 92, fp: 4, tn: 900
| 2021-07-08 18:42:46 | INFO | Validation loss: 0.380, acc: 0.904, F1: 0.513
| 2021-07-08 18:42:46 | INFO | Start epoch 7:
| 2021-07-08 18:42:47 | INFO | Train Loss: 0.103, tp: 1, fn: 3, fp: 0, tn: 60, Acc: 0.953, Prec: 1.000, Rec: 0.250, F1: 0.688
| 2021-07-08 18:43:56 | INFO | Validation tp: 6, fn: 90, fp: 10, tn: 894
| 2021-07-08 18:43:56 | INFO | Validation loss: 0.229, acc: 0.900, F1: 0.527
| 2021-07-08 18:43:56 | INFO | Start epoch 8:
| 2021-07-08 18:43:57 | INFO | Train Loss: 0.102, tp: 7, fn: 3, fp: 0, tn: 54, Acc: 0.953, Prec: 1.000, Rec: 0.700, F1: 0.898
| 2021-07-08 18:45:06 | INFO | Validation tp: 18, fn: 78, fp: 50, tn: 854
| 2021-07-08 18:45:06 | INFO | Validation loss: 0.088, acc: 0.872, F1: 0.575
| 2021-07-08 18:45:06 | INFO | Start epoch 9:
| 2021-07-08 18:45:07 | INFO | Train Loss: 0.034, tp: 3, fn: 0, fp: 0, tn: 61, Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000
| 2021-07-08 18:46:16 | INFO | Validation tp: 21, fn: 75, fp: 55, tn: 849
| 2021-07-08 18:46:16 | INFO | Validation loss: 0.115, acc: 0.870, F1: 0.587
| 2021-07-08 18:46:16 | INFO | Start epoch 10:
| 2021-07-08 18:46:17 | INFO | Train Loss: 0.029, tp: 6, fn: 0, fp: 1, tn: 57, Acc: 0.984, Prec: 0.857, Rec: 1.000, F1: 0.957
| 2021-07-08 18:47:27 | INFO | Validation tp: 14, fn: 82, fp: 37, tn: 867
| 2021-07-08 18:47:27 | INFO | Validation loss: 0.220, acc: 0.881, F1: 0.563
| 2021-07-08 18:47:29 | INFO | ==============================Start training==============================
| 2021-07-08 18:47:29 | INFO | Command Line Args:   -c config/enja4.conf
Config File (config/enja4.conf):
  train_data:        wmt21_official_data/enja_majority_train.tsv
  valid_data:        wmt21_official_data/enja_majority_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
  lr:                5e-5
Defaults:
  --hidden_size:     256

| 2021-07-08 18:47:40 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-08 18:47:40 | INFO | Start epoch 1:
| 2021-07-08 18:47:41 | INFO | Train Loss: 0.602, tp: 0, fn: 13, fp: 0, tn: 51, Acc: 0.797, Prec: 0.000, Rec: 0.000, F1: 0.443
| 2021-07-08 18:48:50 | INFO | Validation tp: 0, fn: 96, fp: 0, tn: 904
| 2021-07-08 18:48:50 | INFO | Validation loss: 0.594, acc: 0.904, F1: 0.475
| 2021-07-08 18:48:50 | INFO | Start epoch 2:
| 2021-07-08 18:48:51 | INFO | Train Loss: 0.198, tp: 0, fn: 3, fp: 0, tn: 61, Acc: 0.953, Prec: 0.000, Rec: 0.000, F1: 0.488
| 2021-07-08 18:50:00 | INFO | Validation tp: 0, fn: 96, fp: 0, tn: 904
| 2021-07-08 18:50:00 | INFO | Validation loss: 0.590, acc: 0.904, F1: 0.475
| 2021-07-08 18:50:00 | INFO | Start epoch 3:
| 2021-07-08 18:50:01 | INFO | Train Loss: 0.260, tp: 0, fn: 5, fp: 0, tn: 59, Acc: 0.922, Prec: 0.000, Rec: 0.000, F1: 0.480
| 2021-07-08 18:51:10 | INFO | Validation tp: 0, fn: 96, fp: 0, tn: 904
| 2021-07-08 18:51:10 | INFO | Validation loss: 0.693, acc: 0.904, F1: 0.475
| 2021-07-08 18:51:10 | INFO | Start epoch 4:
| 2021-07-08 18:51:11 | INFO | Train Loss: 0.541, tp: 0, fn: 12, fp: 0, tn: 52, Acc: 0.812, Prec: 0.000, Rec: 0.000, F1: 0.448
| 2021-07-08 18:52:20 | INFO | Validation tp: 0, fn: 96, fp: 0, tn: 904
| 2021-07-08 18:52:20 | INFO | Validation loss: 0.756, acc: 0.904, F1: 0.475
| 2021-07-08 18:52:20 | INFO | Start epoch 5:
| 2021-07-08 18:52:21 | INFO | Train Loss: 0.231, tp: 0, fn: 4, fp: 0, tn: 60, Acc: 0.938, Prec: 0.000, Rec: 0.000, F1: 0.484
| 2021-07-08 18:53:30 | INFO | Validation tp: 0, fn: 96, fp: 0, tn: 904
| 2021-07-08 18:53:30 | INFO | Validation loss: 0.702, acc: 0.904, F1: 0.475
| 2021-07-08 18:53:30 | INFO | Start epoch 6:
| 2021-07-08 18:53:31 | INFO | Train Loss: 0.118, tp: 0, fn: 1, fp: 0, tn: 63, Acc: 0.984, Prec: 0.000, Rec: 0.000, F1: 0.496
| 2021-07-08 18:54:40 | INFO | Validation tp: 0, fn: 96, fp: 0, tn: 904
| 2021-07-08 18:54:40 | INFO | Validation loss: 0.643, acc: 0.904, F1: 0.475
| 2021-07-08 18:54:40 | INFO | Start epoch 7:
| 2021-07-08 18:54:41 | INFO | Train Loss: 0.257, tp: 0, fn: 4, fp: 0, tn: 60, Acc: 0.938, Prec: 0.000, Rec: 0.000, F1: 0.484
| 2021-07-08 18:55:50 | INFO | Validation tp: 0, fn: 96, fp: 0, tn: 904
| 2021-07-08 18:55:50 | INFO | Validation loss: 0.674, acc: 0.904, F1: 0.475
| 2021-07-08 18:55:50 | INFO | Start epoch 8:
| 2021-07-08 18:55:51 | INFO | Train Loss: 0.452, tp: 0, fn: 10, fp: 0, tn: 54, Acc: 0.844, Prec: 0.000, Rec: 0.000, F1: 0.458
| 2021-07-08 18:57:00 | INFO | Validation tp: 0, fn: 96, fp: 0, tn: 904
| 2021-07-08 18:57:00 | INFO | Validation loss: 0.675, acc: 0.904, F1: 0.475
| 2021-07-08 18:57:00 | INFO | Start epoch 9:
| 2021-07-08 18:57:01 | INFO | Train Loss: 0.206, tp: 0, fn: 3, fp: 0, tn: 61, Acc: 0.953, Prec: 0.000, Rec: 0.000, F1: 0.488
| 2021-07-08 18:58:10 | INFO | Validation tp: 0, fn: 96, fp: 0, tn: 904
| 2021-07-08 18:58:10 | INFO | Validation loss: 0.663, acc: 0.904, F1: 0.475
| 2021-07-08 18:58:10 | INFO | Start epoch 10:
| 2021-07-08 18:58:11 | INFO | Train Loss: 0.308, tp: 0, fn: 6, fp: 0, tn: 58, Acc: 0.906, Prec: 0.000, Rec: 0.000, F1: 0.475
| 2021-07-08 18:59:20 | INFO | Validation tp: 0, fn: 96, fp: 0, tn: 904
| 2021-07-08 18:59:20 | INFO | Validation loss: 0.669, acc: 0.904, F1: 0.475
| 2021-07-08 18:59:22 | INFO | ==============================Start training==============================
| 2021-07-08 18:59:22 | INFO | Command Line Args:   -c config/encs.conf
Config File (config/encs.conf):
  train_data:        wmt21_official_data/encs_majority_train.tsv
  valid_data:        wmt21_official_data/encs_majority_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
  lr:                2e-5
Defaults:
  --hidden_size:     256

| 2021-07-08 18:59:34 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-08 18:59:34 | INFO | Start epoch 1:
| 2021-07-08 18:59:34 | INFO | Train Loss: 0.608, tp: 0, fn: 17, fp: 0, tn: 47, Acc: 0.734, Prec: 0.000, Rec: 0.000, F1: 0.423
| 2021-07-08 19:00:41 | INFO | Validation tp: 0, fn: 160, fp: 0, tn: 840
| 2021-07-08 19:00:41 | INFO | Validation loss: 0.165, acc: 0.840, F1: 0.457
| 2021-07-08 19:00:41 | INFO | Start epoch 2:
| 2021-07-08 19:00:42 | INFO | Train Loss: 0.412, tp: 0, fn: 9, fp: 0, tn: 55, Acc: 0.859, Prec: 0.000, Rec: 0.000, F1: 0.462
| 2021-07-08 19:01:49 | INFO | Validation tp: 32, fn: 128, fp: 17, tn: 823
| 2021-07-08 19:01:49 | INFO | Validation loss: 0.178, acc: 0.855, F1: 0.613
| 2021-07-08 19:01:49 | INFO | Start epoch 3:
| 2021-07-08 19:01:50 | INFO | Train Loss: 0.431, tp: 3, fn: 8, fp: 1, tn: 52, Acc: 0.859, Prec: 0.750, Rec: 0.273, F1: 0.660
| 2021-07-08 19:02:58 | INFO | Validation tp: 12, fn: 148, fp: 3, tn: 837
| 2021-07-08 19:02:58 | INFO | Validation loss: 0.196, acc: 0.849, F1: 0.527
| 2021-07-08 19:02:58 | INFO | Start epoch 4:
| 2021-07-08 19:02:58 | INFO | Train Loss: 0.309, tp: 0, fn: 7, fp: 0, tn: 57, Acc: 0.891, Prec: 0.000, Rec: 0.000, F1: 0.471
| 2021-07-08 19:04:06 | INFO | Validation tp: 47, fn: 113, fp: 32, tn: 808
| 2021-07-08 19:04:06 | INFO | Validation loss: 0.228, acc: 0.855, F1: 0.655
| 2021-07-08 19:04:06 | INFO | Start epoch 5:
| 2021-07-08 19:04:06 | INFO | Train Loss: 0.356, tp: 3, fn: 8, fp: 2, tn: 51, Acc: 0.844, Prec: 0.600, Rec: 0.273, F1: 0.643
| 2021-07-08 19:05:14 | INFO | Validation tp: 61, fn: 99, fp: 56, tn: 784
| 2021-07-08 19:05:14 | INFO | Validation loss: 0.199, acc: 0.845, F1: 0.675
| 2021-07-08 19:05:14 | INFO | Start epoch 6:
| 2021-07-08 19:05:14 | INFO | Train Loss: 0.188, tp: 3, fn: 2, fp: 1, tn: 58, Acc: 0.953, Prec: 0.750, Rec: 0.600, F1: 0.821
| 2021-07-08 19:06:22 | INFO | Validation tp: 42, fn: 118, fp: 47, tn: 793
| 2021-07-08 19:06:22 | INFO | Validation loss: 0.163, acc: 0.835, F1: 0.622
| 2021-07-08 19:06:22 | INFO | Start epoch 7:
| 2021-07-08 19:06:22 | INFO | Train Loss: 0.226, tp: 8, fn: 5, fp: 2, tn: 49, Acc: 0.891, Prec: 0.800, Rec: 0.615, F1: 0.814
| 2021-07-08 19:07:30 | INFO | Validation tp: 36, fn: 124, fp: 39, tn: 801
| 2021-07-08 19:07:30 | INFO | Validation loss: 0.127, acc: 0.837, F1: 0.607
| 2021-07-08 19:07:30 | INFO | Start epoch 8:
| 2021-07-08 19:07:30 | INFO | Train Loss: 0.177, tp: 8, fn: 4, fp: 1, tn: 51, Acc: 0.922, Prec: 0.889, Rec: 0.667, F1: 0.858
| 2021-07-08 19:08:38 | INFO | Validation tp: 54, fn: 106, fp: 52, tn: 788
| 2021-07-08 19:08:38 | INFO | Validation loss: 0.210, acc: 0.842, F1: 0.657
| 2021-07-08 19:08:38 | INFO | Start epoch 9:
| 2021-07-08 19:08:38 | INFO | Train Loss: 0.208, tp: 13, fn: 3, fp: 1, tn: 47, Acc: 0.938, Prec: 0.929, Rec: 0.812, F1: 0.913
| 2021-07-08 19:09:46 | INFO | Validation tp: 55, fn: 105, fp: 64, tn: 776
| 2021-07-08 19:09:46 | INFO | Validation loss: 0.178, acc: 0.831, F1: 0.648
| 2021-07-08 19:09:46 | INFO | Start epoch 10:
| 2021-07-08 19:09:46 | INFO | Train Loss: 0.063, tp: 10, fn: 1, fp: 0, tn: 53, Acc: 0.984, Prec: 1.000, Rec: 0.909, F1: 0.972
| 2021-07-08 19:10:54 | INFO | Validation tp: 48, fn: 112, fp: 51, tn: 789
| 2021-07-08 19:10:54 | INFO | Validation loss: 0.165, acc: 0.837, F1: 0.639
| 2021-07-08 19:10:55 | INFO | ==============================Start training==============================
| 2021-07-08 19:10:55 | INFO | Command Line Args:   -c config/encs2.conf
Config File (config/encs2.conf):
  train_data:        wmt21_official_data/encs_majority_train.tsv
  valid_data:        wmt21_official_data/encs_majority_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
  lr:                3e-5
Defaults:
  --hidden_size:     256

| 2021-07-08 19:11:07 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-08 19:11:07 | INFO | Start epoch 1:
| 2021-07-08 19:11:08 | INFO | Train Loss: 0.608, tp: 0, fn: 17, fp: 0, tn: 47, Acc: 0.734, Prec: 0.000, Rec: 0.000, F1: 0.423
| 2021-07-08 19:12:15 | INFO | Validation tp: 0, fn: 160, fp: 0, tn: 840
| 2021-07-08 19:12:15 | INFO | Validation loss: 0.141, acc: 0.840, F1: 0.457
| 2021-07-08 19:12:15 | INFO | Start epoch 2:
| 2021-07-08 19:12:15 | INFO | Train Loss: 0.413, tp: 0, fn: 9, fp: 0, tn: 55, Acc: 0.859, Prec: 0.000, Rec: 0.000, F1: 0.462
| 2021-07-08 19:13:23 | INFO | Validation tp: 3, fn: 157, fp: 1, tn: 839
| 2021-07-08 19:13:23 | INFO | Validation loss: 0.148, acc: 0.842, F1: 0.475
| 2021-07-08 19:13:23 | INFO | Start epoch 3:
| 2021-07-08 19:13:23 | INFO | Train Loss: 0.419, tp: 0, fn: 11, fp: 1, tn: 52, Acc: 0.812, Prec: 0.000, Rec: 0.000, F1: 0.448
| 2021-07-08 19:14:31 | INFO | Validation tp: 6, fn: 154, fp: 1, tn: 839
| 2021-07-08 19:14:31 | INFO | Validation loss: 0.159, acc: 0.845, F1: 0.494
| 2021-07-08 19:14:31 | INFO | Start epoch 4:
| 2021-07-08 19:14:32 | INFO | Train Loss: 0.288, tp: 0, fn: 7, fp: 0, tn: 57, Acc: 0.891, Prec: 0.000, Rec: 0.000, F1: 0.471
| 2021-07-08 19:15:39 | INFO | Validation tp: 37, fn: 123, fp: 18, tn: 822
| 2021-07-08 19:15:39 | INFO | Validation loss: 0.205, acc: 0.859, F1: 0.633
| 2021-07-08 19:15:39 | INFO | Start epoch 5:
| 2021-07-08 19:15:40 | INFO | Train Loss: 0.354, tp: 2, fn: 9, fp: 0, tn: 53, Acc: 0.859, Prec: 1.000, Rec: 0.182, F1: 0.615
| 2021-07-08 19:16:47 | INFO | Validation tp: 70, fn: 90, fp: 65, tn: 775
| 2021-07-08 19:16:47 | INFO | Validation loss: 0.368, acc: 0.845, F1: 0.692
| 2021-07-08 19:16:47 | INFO | Start epoch 6:
| 2021-07-08 19:16:48 | INFO | Train Loss: 0.205, tp: 4, fn: 1, fp: 2, tn: 57, Acc: 0.953, Prec: 0.667, Rec: 0.800, F1: 0.851
| 2021-07-08 19:17:55 | INFO | Validation tp: 45, fn: 115, fp: 43, tn: 797
| 2021-07-08 19:17:55 | INFO | Validation loss: 0.210, acc: 0.842, F1: 0.636
| 2021-07-08 19:17:55 | INFO | Start epoch 7:
| 2021-07-08 19:17:56 | INFO | Train Loss: 0.155, tp: 12, fn: 1, fp: 0, tn: 51, Acc: 0.984, Prec: 1.000, Rec: 0.923, F1: 0.975
| 2021-07-08 19:19:03 | INFO | Validation tp: 40, fn: 120, fp: 36, tn: 804
| 2021-07-08 19:19:03 | INFO | Validation loss: 0.352, acc: 0.844, F1: 0.625
| 2021-07-08 19:19:03 | INFO | Start epoch 8:
| 2021-07-08 19:19:04 | INFO | Train Loss: 0.070, tp: 10, fn: 2, fp: 0, tn: 52, Acc: 0.969, Prec: 1.000, Rec: 0.833, F1: 0.945
| 2021-07-08 19:20:11 | INFO | Validation tp: 49, fn: 111, fp: 48, tn: 792
| 2021-07-08 19:20:11 | INFO | Validation loss: 0.441, acc: 0.841, F1: 0.645
| 2021-07-08 19:20:11 | INFO | Start epoch 9:
| 2021-07-08 19:20:12 | INFO | Train Loss: 0.099, tp: 14, fn: 2, fp: 0, tn: 48, Acc: 0.969, Prec: 1.000, Rec: 0.875, F1: 0.956
| 2021-07-08 19:21:19 | INFO | Validation tp: 56, fn: 104, fp: 52, tn: 788
| 2021-07-08 19:21:19 | INFO | Validation loss: 0.340, acc: 0.844, F1: 0.664
| 2021-07-08 19:21:19 | INFO | Start epoch 10:
| 2021-07-08 19:21:20 | INFO | Train Loss: 0.017, tp: 11, fn: 0, fp: 0, tn: 53, Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000
| 2021-07-08 19:22:27 | INFO | Validation tp: 55, fn: 105, fp: 50, tn: 790
| 2021-07-08 19:22:27 | INFO | Validation loss: 0.397, acc: 0.845, F1: 0.663
| 2021-07-08 19:22:29 | INFO | ==============================Start training==============================
| 2021-07-08 19:22:29 | INFO | Command Line Args:   -c config/encs3.conf
Config File (config/encs3.conf):
  train_data:        wmt21_official_data/encs_majority_train.tsv
  valid_data:        wmt21_official_data/encs_majority_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
  lr:                4e-5
Defaults:
  --hidden_size:     256

| 2021-07-08 19:22:41 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-08 19:22:41 | INFO | Start epoch 1:
| 2021-07-08 19:22:41 | INFO | Train Loss: 0.608, tp: 0, fn: 17, fp: 0, tn: 47, Acc: 0.734, Prec: 0.000, Rec: 0.000, F1: 0.423
| 2021-07-08 19:23:49 | INFO | Validation tp: 0, fn: 160, fp: 0, tn: 840
| 2021-07-08 19:23:49 | INFO | Validation loss: 0.227, acc: 0.840, F1: 0.457
| 2021-07-08 19:23:49 | INFO | Start epoch 2:
| 2021-07-08 19:23:49 | INFO | Train Loss: 0.442, tp: 0, fn: 9, fp: 0, tn: 55, Acc: 0.859, Prec: 0.000, Rec: 0.000, F1: 0.462
| 2021-07-08 19:24:57 | INFO | Validation tp: 35, fn: 125, fp: 24, tn: 816
| 2021-07-08 19:24:57 | INFO | Validation loss: 0.199, acc: 0.851, F1: 0.618
| 2021-07-08 19:24:57 | INFO | Start epoch 3:
| 2021-07-08 19:24:57 | INFO | Train Loss: 0.433, tp: 3, fn: 8, fp: 2, tn: 51, Acc: 0.844, Prec: 0.600, Rec: 0.273, F1: 0.643
| 2021-07-08 19:26:05 | INFO | Validation tp: 1, fn: 159, fp: 0, tn: 840
| 2021-07-08 19:26:05 | INFO | Validation loss: 0.079, acc: 0.841, F1: 0.463
| 2021-07-08 19:26:05 | INFO | Start epoch 4:
| 2021-07-08 19:26:05 | INFO | Train Loss: 0.265, tp: 0, fn: 7, fp: 0, tn: 57, Acc: 0.891, Prec: 0.000, Rec: 0.000, F1: 0.471
| 2021-07-08 19:27:13 | INFO | Validation tp: 35, fn: 125, fp: 24, tn: 816
| 2021-07-08 19:27:13 | INFO | Validation loss: 0.150, acc: 0.851, F1: 0.618
| 2021-07-08 19:27:13 | INFO | Start epoch 5:
| 2021-07-08 19:27:14 | INFO | Train Loss: 0.341, tp: 1, fn: 10, fp: 0, tn: 53, Acc: 0.844, Prec: 1.000, Rec: 0.091, F1: 0.540
| 2021-07-08 19:28:21 | INFO | Validation tp: 56, fn: 104, fp: 52, tn: 788
| 2021-07-08 19:28:21 | INFO | Validation loss: 0.208, acc: 0.844, F1: 0.664
| 2021-07-08 19:28:21 | INFO | Start epoch 6:
| 2021-07-08 19:28:21 | INFO | Train Loss: 0.194, tp: 2, fn: 3, fp: 3, tn: 56, Acc: 0.906, Prec: 0.400, Rec: 0.400, F1: 0.675
| 2021-07-08 19:29:29 | INFO | Validation tp: 58, fn: 102, fp: 63, tn: 777
| 2021-07-08 19:29:29 | INFO | Validation loss: 0.361, acc: 0.835, F1: 0.658
| 2021-07-08 19:29:29 | INFO | Start epoch 7:
| 2021-07-08 19:29:30 | INFO | Train Loss: 0.232, tp: 11, fn: 2, fp: 4, tn: 47, Acc: 0.906, Prec: 0.733, Rec: 0.846, F1: 0.863
| 2021-07-08 19:30:37 | INFO | Validation tp: 35, fn: 125, fp: 25, tn: 815
| 2021-07-08 19:30:37 | INFO | Validation loss: 0.152, acc: 0.850, F1: 0.617
| 2021-07-08 19:30:37 | INFO | Start epoch 8:
| 2021-07-08 19:30:38 | INFO | Train Loss: 0.124, tp: 8, fn: 4, fp: 0, tn: 52, Acc: 0.938, Prec: 1.000, Rec: 0.667, F1: 0.881
| 2021-07-08 19:31:45 | INFO | Validation tp: 55, fn: 105, fp: 52, tn: 788
| 2021-07-08 19:31:45 | INFO | Validation loss: 0.502, acc: 0.843, F1: 0.661
| 2021-07-08 19:31:45 | INFO | Start epoch 9:
| 2021-07-08 19:31:46 | INFO | Train Loss: 0.133, tp: 14, fn: 2, fp: 0, tn: 48, Acc: 0.969, Prec: 1.000, Rec: 0.875, F1: 0.956
| 2021-07-08 19:32:53 | INFO | Validation tp: 58, fn: 102, fp: 59, tn: 781
| 2021-07-08 19:32:53 | INFO | Validation loss: 0.602, acc: 0.839, F1: 0.663
| 2021-07-08 19:32:53 | INFO | Start epoch 10:
| 2021-07-08 19:32:54 | INFO | Train Loss: 0.016, tp: 11, fn: 0, fp: 0, tn: 53, Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000
| 2021-07-08 19:34:01 | INFO | Validation tp: 56, fn: 104, fp: 51, tn: 789
| 2021-07-08 19:34:01 | INFO | Validation loss: 0.592, acc: 0.845, F1: 0.665
| 2021-07-08 19:34:03 | INFO | ==============================Start training==============================
| 2021-07-08 19:34:03 | INFO | Command Line Args:   -c config/encs4.conf
Config File (config/encs4.conf):
  train_data:        wmt21_official_data/encs_majority_train.tsv
  valid_data:        wmt21_official_data/encs_majority_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
  lr:                5e-5
Defaults:
  --hidden_size:     256

| 2021-07-08 19:34:15 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-08 19:34:15 | INFO | Start epoch 1:
| 2021-07-08 19:34:15 | INFO | Train Loss: 0.608, tp: 0, fn: 17, fp: 0, tn: 47, Acc: 0.734, Prec: 0.000, Rec: 0.000, F1: 0.423
| 2021-07-08 19:35:23 | INFO | Validation tp: 0, fn: 160, fp: 0, tn: 840
| 2021-07-08 19:35:23 | INFO | Validation loss: 0.133, acc: 0.840, F1: 0.457
| 2021-07-08 19:35:23 | INFO | Start epoch 2:
| 2021-07-08 19:35:24 | INFO | Train Loss: 0.400, tp: 0, fn: 9, fp: 0, tn: 55, Acc: 0.859, Prec: 0.000, Rec: 0.000, F1: 0.462
| 2021-07-08 19:36:31 | INFO | Validation tp: 13, fn: 147, fp: 4, tn: 836
| 2021-07-08 19:36:31 | INFO | Validation loss: 0.137, acc: 0.849, F1: 0.532
| 2021-07-08 19:36:31 | INFO | Start epoch 3:
| 2021-07-08 19:36:32 | INFO | Train Loss: 0.431, tp: 0, fn: 11, fp: 1, tn: 52, Acc: 0.812, Prec: 0.000, Rec: 0.000, F1: 0.448
| 2021-07-08 19:37:39 | INFO | Validation tp: 23, fn: 137, fp: 11, tn: 829
| 2021-07-08 19:37:39 | INFO | Validation loss: 0.074, acc: 0.852, F1: 0.578
| 2021-07-08 19:37:39 | INFO | Start epoch 4:
| 2021-07-08 19:37:40 | INFO | Train Loss: 0.234, tp: 1, fn: 6, fp: 0, tn: 57, Acc: 0.906, Prec: 1.000, Rec: 0.143, F1: 0.600
| 2021-07-08 19:38:47 | INFO | Validation tp: 48, fn: 112, fp: 42, tn: 798
| 2021-07-08 19:38:47 | INFO | Validation loss: 0.259, acc: 0.846, F1: 0.648
| 2021-07-08 19:38:47 | INFO | Start epoch 5:
| 2021-07-08 19:38:48 | INFO | Train Loss: 0.320, tp: 5, fn: 6, fp: 0, tn: 53, Acc: 0.906, Prec: 1.000, Rec: 0.455, F1: 0.786
| 2021-07-08 19:39:55 | INFO | Validation tp: 70, fn: 90, fp: 89, tn: 751
| 2021-07-08 19:39:55 | INFO | Validation loss: 0.379, acc: 0.821, F1: 0.666
| 2021-07-08 19:39:55 | INFO | Start epoch 6:
| 2021-07-08 19:39:56 | INFO | Train Loss: 0.174, tp: 4, fn: 1, fp: 3, tn: 56, Acc: 0.938, Prec: 0.571, Rec: 0.800, F1: 0.816
| 2021-07-08 19:41:03 | INFO | Validation tp: 63, fn: 97, fp: 64, tn: 776
| 2021-07-08 19:41:03 | INFO | Validation loss: 0.243, acc: 0.839, F1: 0.673
| 2021-07-08 19:41:03 | INFO | Start epoch 7:
| 2021-07-08 19:41:04 | INFO | Train Loss: 0.126, tp: 12, fn: 1, fp: 1, tn: 50, Acc: 0.969, Prec: 0.923, Rec: 0.923, F1: 0.952
| 2021-07-08 19:42:11 | INFO | Validation tp: 38, fn: 122, fp: 30, tn: 810
| 2021-07-08 19:42:11 | INFO | Validation loss: 0.051, acc: 0.848, F1: 0.624
| 2021-07-08 19:42:11 | INFO | Start epoch 8:
| 2021-07-08 19:42:12 | INFO | Train Loss: 0.068, tp: 10, fn: 2, fp: 0, tn: 52, Acc: 0.969, Prec: 1.000, Rec: 0.833, F1: 0.945
| 2021-07-08 19:43:19 | INFO | Validation tp: 68, fn: 92, fp: 85, tn: 755
| 2021-07-08 19:43:19 | INFO | Validation loss: 0.098, acc: 0.823, F1: 0.665
| 2021-07-08 19:43:19 | INFO | Start epoch 9:
| 2021-07-08 19:43:20 | INFO | Train Loss: 0.074, tp: 16, fn: 0, fp: 1, tn: 47, Acc: 0.984, Prec: 0.941, Rec: 1.000, F1: 0.980
| 2021-07-08 19:44:28 | INFO | Validation tp: 58, fn: 102, fp: 64, tn: 776
| 2021-07-08 19:44:28 | INFO | Validation loss: 0.085, acc: 0.834, F1: 0.657
| 2021-07-08 19:44:28 | INFO | Start epoch 10:
| 2021-07-08 19:44:28 | INFO | Train Loss: 0.035, tp: 10, fn: 1, fp: 0, tn: 53, Acc: 0.984, Prec: 1.000, Rec: 0.909, F1: 0.972
| 2021-07-08 19:45:36 | INFO | Validation tp: 56, fn: 104, fp: 58, tn: 782
| 2021-07-08 19:45:36 | INFO | Validation loss: 0.062, acc: 0.838, F1: 0.657
| 2021-07-08 19:45:38 | INFO | ==============================Start training==============================
| 2021-07-08 19:45:38 | INFO | Command Line Args:   -c config/ende.conf
Config File (config/ende.conf):
  train_data:        wmt21_official_data/ende_majority_train.tsv
  valid_data:        wmt21_official_data/ende_majority_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
  lr:                2e-5
Defaults:
  --hidden_size:     256

| 2021-07-08 19:45:49 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-08 19:45:49 | INFO | Start epoch 1:
| 2021-07-08 19:45:50 | INFO | Train Loss: 0.659, tp: 0, fn: 22, fp: 0, tn: 42, Acc: 0.656, Prec: 0.000, Rec: 0.000, F1: 0.396
| 2021-07-08 19:47:01 | INFO | Validation tp: 6, fn: 275, fp: 2, tn: 717
| 2021-07-08 19:47:01 | INFO | Validation loss: 0.487, acc: 0.723, F1: 0.440
| 2021-07-08 19:47:01 | INFO | Start epoch 2:
| 2021-07-08 19:47:01 | INFO | Train Loss: 0.617, tp: 3, fn: 19, fp: 0, tn: 42, Acc: 0.703, Prec: 1.000, Rec: 0.136, F1: 0.528
| 2021-07-08 19:48:12 | INFO | Validation tp: 8, fn: 273, fp: 0, tn: 719
| 2021-07-08 19:48:12 | INFO | Validation loss: 0.461, acc: 0.727, F1: 0.448
| 2021-07-08 19:48:12 | INFO | Start epoch 3:
| 2021-07-08 19:48:13 | INFO | Train Loss: 0.507, tp: 1, fn: 17, fp: 0, tn: 46, Acc: 0.734, Prec: 1.000, Rec: 0.056, F1: 0.475
| 2021-07-08 19:49:24 | INFO | Validation tp: 72, fn: 209, fp: 23, tn: 696
| 2021-07-08 19:49:24 | INFO | Validation loss: 0.423, acc: 0.768, F1: 0.620
| 2021-07-08 19:49:24 | INFO | Start epoch 4:
| 2021-07-08 19:49:24 | INFO | Train Loss: 0.510, tp: 2, fn: 13, fp: 2, tn: 47, Acc: 0.766, Prec: 0.500, Rec: 0.133, F1: 0.536
| 2021-07-08 19:50:35 | INFO | Validation tp: 107, fn: 174, fp: 47, tn: 672
| 2021-07-08 19:50:35 | INFO | Validation loss: 0.443, acc: 0.779, F1: 0.675
| 2021-07-08 19:50:35 | INFO | Start epoch 5:
| 2021-07-08 19:50:36 | INFO | Train Loss: 0.324, tp: 7, fn: 5, fp: 3, tn: 49, Acc: 0.875, Prec: 0.700, Rec: 0.583, F1: 0.780
| 2021-07-08 19:51:47 | INFO | Validation tp: 90, fn: 191, fp: 34, tn: 685
| 2021-07-08 19:51:47 | INFO | Validation loss: 0.509, acc: 0.775, F1: 0.652
| 2021-07-08 19:51:47 | INFO | Start epoch 6:
| 2021-07-08 19:51:47 | INFO | Train Loss: 0.263, tp: 8, fn: 5, fp: 0, tn: 51, Acc: 0.922, Prec: 1.000, Rec: 0.615, F1: 0.858
| 2021-07-08 19:52:58 | INFO | Validation tp: 131, fn: 150, fp: 60, tn: 659
| 2021-07-08 19:52:58 | INFO | Validation loss: 0.259, acc: 0.790, F1: 0.709
| 2021-07-08 19:52:58 | INFO | Start epoch 7:
| 2021-07-08 19:52:59 | INFO | Train Loss: 0.269, tp: 10, fn: 3, fp: 3, tn: 48, Acc: 0.906, Prec: 0.769, Rec: 0.769, F1: 0.855
| 2021-07-08 19:54:10 | INFO | Validation tp: 97, fn: 184, fp: 37, tn: 682
| 2021-07-08 19:54:10 | INFO | Validation loss: 0.670, acc: 0.779, F1: 0.664
| 2021-07-08 19:54:10 | INFO | Start epoch 8:
| 2021-07-08 19:54:11 | INFO | Train Loss: 0.131, tp: 13, fn: 4, fp: 0, tn: 47, Acc: 0.938, Prec: 1.000, Rec: 0.765, F1: 0.913
| 2021-07-08 19:55:22 | INFO | Validation tp: 118, fn: 163, fp: 59, tn: 660
| 2021-07-08 19:55:22 | INFO | Validation loss: 0.724, acc: 0.778, F1: 0.686
| 2021-07-08 19:55:22 | INFO | Start epoch 9:
| 2021-07-08 19:55:22 | INFO | Train Loss: 0.101, tp: 19, fn: 1, fp: 1, tn: 43, Acc: 0.969, Prec: 0.950, Rec: 0.950, F1: 0.964
| 2021-07-08 19:56:33 | INFO | Validation tp: 126, fn: 155, fp: 62, tn: 657
| 2021-07-08 19:56:33 | INFO | Validation loss: 0.764, acc: 0.783, F1: 0.698
| 2021-07-08 19:56:33 | INFO | Start epoch 10:
| 2021-07-08 19:56:34 | INFO | Train Loss: 0.035, tp: 16, fn: 0, fp: 0, tn: 48, Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000
| 2021-07-08 19:57:45 | INFO | Validation tp: 129, fn: 152, fp: 64, tn: 655
| 2021-07-08 19:57:45 | INFO | Validation loss: 0.771, acc: 0.784, F1: 0.701
| 2021-07-08 19:57:47 | INFO | ==============================Start training==============================
| 2021-07-08 19:57:47 | INFO | Command Line Args:   -c config/ende2.conf
Config File (config/ende2.conf):
  train_data:        wmt21_official_data/ende_majority_train.tsv
  valid_data:        wmt21_official_data/ende_majority_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
  lr:                3e-5
Defaults:
  --hidden_size:     256

| 2021-07-08 19:57:58 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-08 19:57:58 | INFO | Start epoch 1:
| 2021-07-08 19:57:59 | INFO | Train Loss: 0.659, tp: 0, fn: 22, fp: 0, tn: 42, Acc: 0.656, Prec: 0.000, Rec: 0.000, F1: 0.396
| 2021-07-08 19:59:10 | INFO | Validation tp: 5, fn: 276, fp: 1, tn: 718
| 2021-07-08 19:59:10 | INFO | Validation loss: 0.525, acc: 0.723, F1: 0.437
| 2021-07-08 19:59:10 | INFO | Start epoch 2:
| 2021-07-08 19:59:10 | INFO | Train Loss: 0.635, tp: 2, fn: 20, fp: 2, tn: 40, Acc: 0.656, Prec: 0.500, Rec: 0.091, F1: 0.469
| 2021-07-08 20:00:22 | INFO | Validation tp: 79, fn: 202, fp: 34, tn: 685
| 2021-07-08 20:00:22 | INFO | Validation loss: 0.377, acc: 0.764, F1: 0.627
| 2021-07-08 20:00:22 | INFO | Start epoch 3:
| 2021-07-08 20:00:22 | INFO | Train Loss: 0.445, tp: 7, fn: 11, fp: 0, tn: 46, Acc: 0.828, Prec: 1.000, Rec: 0.389, F1: 0.727
| 2021-07-08 20:01:33 | INFO | Validation tp: 83, fn: 198, fp: 26, tn: 693
| 2021-07-08 20:01:33 | INFO | Validation loss: 0.519, acc: 0.776, F1: 0.643
| 2021-07-08 20:01:33 | INFO | Start epoch 4:
| 2021-07-08 20:01:34 | INFO | Train Loss: 0.490, tp: 3, fn: 12, fp: 2, tn: 47, Acc: 0.781, Prec: 0.600, Rec: 0.200, F1: 0.585
| 2021-07-08 20:02:45 | INFO | Validation tp: 104, fn: 177, fp: 43, tn: 676
| 2021-07-08 20:02:45 | INFO | Validation loss: 0.398, acc: 0.780, F1: 0.673
| 2021-07-08 20:02:45 | INFO | Start epoch 5:
| 2021-07-08 20:02:45 | INFO | Train Loss: 0.327, tp: 7, fn: 5, fp: 3, tn: 49, Acc: 0.875, Prec: 0.700, Rec: 0.583, F1: 0.780
| 2021-07-08 20:03:57 | INFO | Validation tp: 100, fn: 181, fp: 37, tn: 682
| 2021-07-08 20:03:57 | INFO | Validation loss: 0.418, acc: 0.782, F1: 0.670
| 2021-07-08 20:03:57 | INFO | Start epoch 6:
| 2021-07-08 20:03:57 | INFO | Train Loss: 0.267, tp: 9, fn: 4, fp: 1, tn: 50, Acc: 0.922, Prec: 0.900, Rec: 0.692, F1: 0.867
| 2021-07-08 20:05:08 | INFO | Validation tp: 125, fn: 156, fp: 75, tn: 644
| 2021-07-08 20:05:08 | INFO | Validation loss: 0.429, acc: 0.769, F1: 0.684
| 2021-07-08 20:05:08 | INFO | Start epoch 7:
| 2021-07-08 20:05:09 | INFO | Train Loss: 0.253, tp: 11, fn: 2, fp: 3, tn: 48, Acc: 0.922, Prec: 0.786, Rec: 0.846, F1: 0.883
| 2021-07-08 20:06:20 | INFO | Validation tp: 118, fn: 163, fp: 62, tn: 657
| 2021-07-08 20:06:20 | INFO | Validation loss: 0.364, acc: 0.775, F1: 0.683
| 2021-07-08 20:06:20 | INFO | Start epoch 8:
| 2021-07-08 20:06:21 | INFO | Train Loss: 0.099, tp: 16, fn: 1, fp: 2, tn: 45, Acc: 0.953, Prec: 0.889, Rec: 0.941, F1: 0.941
| 2021-07-08 20:07:32 | INFO | Validation tp: 118, fn: 163, fp: 75, tn: 644
| 2021-07-08 20:07:32 | INFO | Validation loss: 0.390, acc: 0.762, F1: 0.671
| 2021-07-08 20:07:32 | INFO | Start epoch 9:
| 2021-07-08 20:07:32 | INFO | Train Loss: 0.074, tp: 19, fn: 1, fp: 1, tn: 43, Acc: 0.969, Prec: 0.950, Rec: 0.950, F1: 0.964
| 2021-07-08 20:08:44 | INFO | Validation tp: 115, fn: 166, fp: 66, tn: 653
| 2021-07-08 20:08:44 | INFO | Validation loss: 0.758, acc: 0.768, F1: 0.673
| 2021-07-08 20:08:44 | INFO | Start epoch 10:
| 2021-07-08 20:08:44 | INFO | Train Loss: 0.087, tp: 14, fn: 2, fp: 0, tn: 48, Acc: 0.969, Prec: 1.000, Rec: 0.875, F1: 0.956
| 2021-07-08 20:09:55 | INFO | Validation tp: 123, fn: 158, fp: 74, tn: 645
| 2021-07-08 20:09:55 | INFO | Validation loss: 0.754, acc: 0.768, F1: 0.681
| 2021-07-08 20:09:57 | INFO | ==============================Start training==============================
| 2021-07-08 20:09:57 | INFO | Command Line Args:   -c config/ende3.conf
Config File (config/ende3.conf):
  train_data:        wmt21_official_data/ende_majority_train.tsv
  valid_data:        wmt21_official_data/ende_majority_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
  lr:                4e-5
Defaults:
  --hidden_size:     256

| 2021-07-08 20:10:09 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-08 20:10:09 | INFO | Start epoch 1:
| 2021-07-08 20:10:09 | INFO | Train Loss: 0.659, tp: 0, fn: 22, fp: 0, tn: 42, Acc: 0.656, Prec: 0.000, Rec: 0.000, F1: 0.396
| 2021-07-08 20:11:20 | INFO | Validation tp: 60, fn: 221, fp: 24, tn: 695
| 2021-07-08 20:11:20 | INFO | Validation loss: 0.393, acc: 0.755, F1: 0.589
| 2021-07-08 20:11:20 | INFO | Start epoch 2:
| 2021-07-08 20:11:21 | INFO | Train Loss: 0.614, tp: 5, fn: 17, fp: 3, tn: 39, Acc: 0.688, Prec: 0.625, Rec: 0.227, F1: 0.565
| 2021-07-08 20:12:32 | INFO | Validation tp: 78, fn: 203, fp: 29, tn: 690
| 2021-07-08 20:12:32 | INFO | Validation loss: 0.378, acc: 0.768, F1: 0.629
| 2021-07-08 20:12:32 | INFO | Start epoch 3:
| 2021-07-08 20:12:32 | INFO | Train Loss: 0.435, tp: 7, fn: 11, fp: 0, tn: 46, Acc: 0.828, Prec: 1.000, Rec: 0.389, F1: 0.727
| 2021-07-08 20:13:43 | INFO | Validation tp: 93, fn: 188, fp: 30, tn: 689
| 2021-07-08 20:13:43 | INFO | Validation loss: 0.418, acc: 0.782, F1: 0.662
| 2021-07-08 20:13:43 | INFO | Start epoch 4:
| 2021-07-08 20:13:44 | INFO | Train Loss: 0.518, tp: 2, fn: 13, fp: 4, tn: 45, Acc: 0.734, Prec: 0.333, Rec: 0.133, F1: 0.516
| 2021-07-08 20:14:55 | INFO | Validation tp: 5, fn: 276, fp: 0, tn: 719
| 2021-07-08 20:14:55 | INFO | Validation loss: 0.564, acc: 0.724, F1: 0.437
| 2021-07-08 20:14:55 | INFO | Start epoch 5:
| 2021-07-08 20:14:55 | INFO | Train Loss: 0.471, tp: 1, fn: 11, fp: 0, tn: 52, Acc: 0.828, Prec: 1.000, Rec: 0.083, F1: 0.529
| 2021-07-08 20:16:06 | INFO | Validation tp: 0, fn: 281, fp: 0, tn: 719
| 2021-07-08 20:16:06 | INFO | Validation loss: 0.563, acc: 0.719, F1: 0.418
| 2021-07-08 20:16:06 | INFO | Start epoch 6:
| 2021-07-08 20:16:07 | INFO | Train Loss: 0.541, tp: 0, fn: 13, fp: 0, tn: 51, Acc: 0.797, Prec: 0.000, Rec: 0.000, F1: 0.443
| 2021-07-08 20:17:18 | INFO | Validation tp: 0, fn: 281, fp: 0, tn: 719
| 2021-07-08 20:17:18 | INFO | Validation loss: 0.564, acc: 0.719, F1: 0.418
| 2021-07-08 20:17:18 | INFO | Start epoch 7:
| 2021-07-08 20:17:18 | INFO | Train Loss: 0.522, tp: 0, fn: 13, fp: 0, tn: 51, Acc: 0.797, Prec: 0.000, Rec: 0.000, F1: 0.443
| 2021-07-08 20:18:30 | INFO | Validation tp: 0, fn: 281, fp: 0, tn: 719
| 2021-07-08 20:18:30 | INFO | Validation loss: 0.568, acc: 0.719, F1: 0.418
| 2021-07-08 20:18:30 | INFO | Start epoch 8:
| 2021-07-08 20:18:30 | INFO | Train Loss: 0.577, tp: 0, fn: 17, fp: 0, tn: 47, Acc: 0.734, Prec: 0.000, Rec: 0.000, F1: 0.423
| 2021-07-08 20:19:41 | INFO | Validation tp: 0, fn: 281, fp: 0, tn: 719
| 2021-07-08 20:19:41 | INFO | Validation loss: 0.563, acc: 0.719, F1: 0.418
| 2021-07-08 20:19:41 | INFO | Start epoch 9:
| 2021-07-08 20:19:42 | INFO | Train Loss: 0.636, tp: 0, fn: 20, fp: 0, tn: 44, Acc: 0.688, Prec: 0.000, Rec: 0.000, F1: 0.407
| 2021-07-08 20:20:53 | INFO | Validation tp: 0, fn: 281, fp: 0, tn: 719
| 2021-07-08 20:20:53 | INFO | Validation loss: 0.563, acc: 0.719, F1: 0.418
| 2021-07-08 20:20:53 | INFO | Start epoch 10:
| 2021-07-08 20:20:53 | INFO | Train Loss: 0.568, tp: 0, fn: 16, fp: 0, tn: 48, Acc: 0.750, Prec: 0.000, Rec: 0.000, F1: 0.429
| 2021-07-08 20:22:04 | INFO | Validation tp: 0, fn: 281, fp: 0, tn: 719
| 2021-07-08 20:22:04 | INFO | Validation loss: 0.564, acc: 0.719, F1: 0.418
| 2021-07-08 20:22:06 | INFO | ==============================Start training==============================
| 2021-07-08 20:22:06 | INFO | Command Line Args:   -c config/ende4.conf
Config File (config/ende4.conf):
  train_data:        wmt21_official_data/ende_majority_train.tsv
  valid_data:        wmt21_official_data/ende_majority_dev.tsv
  output_dir:        output/
  huggingface_model: xlm-roberta-base
  max_sequence_length:100
  dropout:           0.1
  num_epochs:        10
  train_batch_size:  64
  valid_batch_size:  16
  lr:                5e-5
Defaults:
  --hidden_size:     256

| 2021-07-08 20:22:18 | INFO | MonoTransQuestModel(
  (model): XLMRobertaForSequenceClassification(
    (roberta): RobertaModel(
      (embeddings): RobertaEmbeddings(
        (word_embeddings): Embedding(250002, 768, padding_idx=1)
        (position_embeddings): Embedding(514, 768, padding_idx=1)
        (token_type_embeddings): Embedding(1, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): RobertaEncoder(
        (layer): ModuleList(
          (0): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): RobertaLayer(
            (attention): RobertaAttention(
              (self): RobertaSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): RobertaSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): RobertaIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): RobertaOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (classifier): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.1, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
| 2021-07-08 20:22:18 | INFO | Start epoch 1:
| 2021-07-08 20:22:18 | INFO | Train Loss: 0.659, tp: 0, fn: 22, fp: 0, tn: 42, Acc: 0.656, Prec: 0.000, Rec: 0.000, F1: 0.396
| 2021-07-08 20:23:29 | INFO | Validation tp: 36, fn: 245, fp: 19, tn: 700
| 2021-07-08 20:23:29 | INFO | Validation loss: 0.490, acc: 0.736, F1: 0.528
| 2021-07-08 20:23:29 | INFO | Start epoch 2:
| 2021-07-08 20:23:30 | INFO | Train Loss: 0.605, tp: 3, fn: 19, fp: 1, tn: 41, Acc: 0.688, Prec: 0.750, Rec: 0.136, F1: 0.517
| 2021-07-08 20:24:41 | INFO | Validation tp: 124, fn: 157, fp: 57, tn: 662
| 2021-07-08 20:24:41 | INFO | Validation loss: 0.413, acc: 0.786, F1: 0.699
| 2021-07-08 20:24:41 | INFO | Start epoch 3:
| 2021-07-08 20:24:42 | INFO | Train Loss: 0.437, tp: 10, fn: 8, fp: 1, tn: 45, Acc: 0.859, Prec: 0.909, Rec: 0.556, F1: 0.799
| 2021-07-08 20:25:53 | INFO | Validation tp: 109, fn: 172, fp: 39, tn: 680
| 2021-07-08 20:25:53 | INFO | Validation loss: 0.439, acc: 0.789, F1: 0.687
| 2021-07-08 20:25:53 | INFO | Start epoch 4:
| 2021-07-08 20:25:53 | INFO | Train Loss: 0.423, tp: 4, fn: 11, fp: 3, tn: 46, Acc: 0.781, Prec: 0.571, Rec: 0.267, F1: 0.616
| 2021-07-08 20:27:04 | INFO | Validation tp: 107, fn: 174, fp: 43, tn: 676
| 2021-07-08 20:27:04 | INFO | Validation loss: 0.476, acc: 0.783, F1: 0.679
| 2021-07-08 20:27:04 | INFO | Start epoch 5:
| 2021-07-08 20:27:05 | INFO | Train Loss: 0.213, tp: 10, fn: 2, fp: 1, tn: 51, Acc: 0.953, Prec: 0.909, Rec: 0.833, F1: 0.920
| 2021-07-08 20:28:16 | INFO | Validation tp: 114, fn: 167, fp: 57, tn: 662
| 2021-07-08 20:28:16 | INFO | Validation loss: 0.782, acc: 0.776, F1: 0.680
| 2021-07-08 20:28:16 | INFO | Start epoch 6:
| 2021-07-08 20:28:16 | INFO | Train Loss: 0.163, tp: 11, fn: 2, fp: 0, tn: 51, Acc: 0.969, Prec: 1.000, Rec: 0.846, F1: 0.949
| 2021-07-08 20:29:27 | INFO | Validation tp: 129, fn: 152, fp: 70, tn: 649
| 2021-07-08 20:29:27 | INFO | Validation loss: 1.007, acc: 0.778, F1: 0.696
| 2021-07-08 20:29:27 | INFO | Start epoch 7:
| 2021-07-08 20:29:28 | INFO | Train Loss: 0.170, tp: 12, fn: 1, fp: 3, tn: 48, Acc: 0.938, Prec: 0.800, Rec: 0.923, F1: 0.909
| 2021-07-08 20:30:39 | INFO | Validation tp: 129, fn: 152, fp: 74, tn: 645
| 2021-07-08 20:30:39 | INFO | Validation loss: 0.907, acc: 0.774, F1: 0.692
| 2021-07-08 20:30:39 | INFO | Start epoch 8:
| 2021-07-08 20:30:40 | INFO | Train Loss: 0.058, tp: 16, fn: 1, fp: 1, tn: 46, Acc: 0.969, Prec: 0.941, Rec: 0.941, F1: 0.960
| 2021-07-08 20:31:51 | INFO | Validation tp: 124, fn: 157, fp: 70, tn: 649
| 2021-07-08 20:31:51 | INFO | Validation loss: 1.534, acc: 0.773, F1: 0.687
| 2021-07-08 20:31:51 | INFO | Start epoch 9:
| 2021-07-08 20:31:51 | INFO | Train Loss: 0.061, tp: 19, fn: 1, fp: 1, tn: 43, Acc: 0.969, Prec: 0.950, Rec: 0.950, F1: 0.964
| 2021-07-08 20:33:02 | INFO | Validation tp: 121, fn: 160, fp: 55, tn: 664
| 2021-07-08 20:33:02 | INFO | Validation loss: 1.536, acc: 0.785, F1: 0.695
| 2021-07-08 20:33:02 | INFO | Start epoch 10:
| 2021-07-08 20:33:03 | INFO | Train Loss: 0.006, tp: 16, fn: 0, fp: 0, tn: 48, Acc: 1.000, Prec: 1.000, Rec: 1.000, F1: 1.000
| 2021-07-08 20:34:14 | INFO | Validation tp: 116, fn: 165, fp: 53, tn: 666
| 2021-07-08 20:34:14 | INFO | Validation loss: 1.597, acc: 0.782, F1: 0.687
